2022-05-10 21:34:52 - utils.py[line:263] - INFO: distributed init (rank 0): env://
2022-05-10 21:34:52 - utils.py[line:269] - INFO: Start init
2022-05-10 21:34:52 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-05-10 21:34:52 - utils.py[line:279] - INFO: initialized host heming-ng1 as rank 0
single-machine distributed training is initialized.
2022-05-10 21:34:55 - train.py[line:78] - INFO: nvidia-smi stats: {'gpu_0_mem_used_gb': 0.8349609375, 'gpu_1_mem_used_gb': 16.5830078125, 'gpu_2_mem_used_gb': 0.0, 'gpu_3_mem_used_gb': 3.7705078125}
2022-05-10 21:34:55 - train.py[line:81] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None, 'is_moe': False}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 8, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 2000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 8, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 20, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [4], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './moe_stage1_checkpoints/20_0.06_2500', 'restore_file': './moe_stage1_checkpoints/2_0.06_2500/dum.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 5000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'cider', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '-rank-0', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807, 'stats_path': None, 'max_valid_steps': None}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_moe_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=16384, alternate_ffn_embed_dim=0, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='ofa_moe_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=8, batch_size_valid=8, best_checkpoint_metric='cider', bf16=False, block_wise=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_moe_cross_entropy', cross_self_attention=False, curriculum=0, data='../../dataset/caption_data/caption_stage1_train.tsv,../../dataset/caption_data/caption_val.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_moe_freq=1, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, drop_worst_after=2500, drop_worst_ratio=0.2, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_moe_freq=1, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":1,"max_len_b":16,"no_repeat_ngram_size":3}', eval_bleu=False, eval_cider=True, eval_cider_cached_tokens='../../dataset/caption_data/cider_cached_tokens/coco-valid-words.p', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, log_nvidia_smi=False, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=20, max_source_positions=1024, max_src_length=80, max_target_positions=1024, max_tgt_length=20, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, moe_eval_capacity_token_fraction=0.25, moe_expert_count=4, moe_expert_ffn_dim=0, moe_freq=1, moe_gate_loss_combine_method='average', moe_gate_loss_transform='none', moe_gate_loss_wt=1.0, moe_gating_use_fp32=True, moe_normalize_expert_grad='', moe_normalize_gate_prob_before_dropping=True, moe_second_expert_policy='all', moe_top1_expert=True, no_best_checkpoints=False, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_save_optimizer_state_on_training_finished=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_bins=1000, num_shards=1, num_workers=0, num_workers_valid=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='./moe_stage1_checkpoints/2_0.06_2500/dum.pt', s3_upload_path=None, sample_patch_num=196, save_dir='./moe_stage1_checkpoints/20_0.06_2500', save_interval=1, save_interval_updates=5000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', scst=False, scst_args='{}', seed=1, selected_cols='0,4,2', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, symlink_best_and_last_checkpoints=False, sync_bn=False, task='caption', tensorboard_logdir=None, threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[4], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_moe_pad_mask=True, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=2000, wandb_project=None, warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'caption', 'data': '../../dataset/caption_data/caption_stage1_train.tsv,../../dataset/caption_data/caption_val.tsv', 'selected_cols': '0,4,2', 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 80, 'max_tgt_length': 20, 'code_dict_size': 8192, 'patch_image_size': 480, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_bleu': False, 'eval_cider': True, 'eval_args': '{"beam":1,"max_len_b":16,"no_repeat_ngram_size":3}', 'eval_print_samples': False, 'eval_cider_cached_tokens': '../../dataset/caption_data/cider_cached_tokens/coco-valid-words.p', 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'adjust_label_smoothed_moe_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.2, 'drop_worst_after': 2500, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None, 'moe_gate_loss_wt': 1.0, 'moe_gate_loss_combine_method': 'average', 'moe_gate_loss_transform': 'none'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [1e-05], 'block_wise': False}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [1e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-05-10 21:34:55 - ofa_task.py[line:103] - INFO: source dictionary: 59457 types
2022-05-10 21:34:55 - ofa_task.py[line:104] - INFO: target dictionary: 59457 types
2022-05-10 21:34:56 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-05-10 21:34:56 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:3 to store for rank: 0
2022-05-10 21:34:56 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:4 to store for rank: 0
2022-05-10 21:35:02 - train.py[line:119] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-05-10 21:35:02 - train.py[line:120] - INFO: task: CaptionTask
2022-05-10 21:35:02 - train.py[line:121] - INFO: model: OFAModel
2022-05-10 21:35:02 - train.py[line:122] - INFO: criterion: AdjustLabelSmoothedMOECrossEntropyCriterion
2022-05-10 21:35:02 - train.py[line:123] - INFO: num. shared model params: 125,606,216 (num. trained: 79,943,240)
2022-05-10 21:35:02 - train.py[line:130] - INFO: num. expert model params: 226676736 (num. trained: 226676736)
local datafile ../../dataset/caption_data/caption_val.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/caption_data/caption_val.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/caption_data/caption_val.tsv slice_id 0 row count 5000 total row count 5000
/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.layers.0.moe_layer.gate.wg.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.layers.1.moe_layer.gate.wg.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.layers.2.moe_layer.gate.wg.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.layers.3.moe_layer.gate.wg.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.layers.4.moe_layer.gate.wg.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.layers.5.moe_layer.gate.wg.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.layers.0.moe_layer.gate.wg.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.layers.1.moe_layer.gate.wg.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.layers.2.moe_layer.gate.wg.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.layers.3.moe_layer.gate.wg.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.layers.4.moe_layer.gate.wg.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.layers.5.moe_layer.gate.wg.bias
2022-05-10 21:35:03 - trainer.py[line:129] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-05-10 21:35:03 - utils.py[line:779] - INFO: ***********************CUDA enviroments for all 1 workers***********************
2022-05-10 21:35:03 - utils.py[line:781] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2022-05-10 21:35:03 - utils.py[line:787] - INFO: ***********************CUDA enviroments for all 1 workers***********************
2022-05-10 21:35:03 - train.py[line:161] - INFO: training on 1 devices (GPUs/TPUs)
2022-05-10 21:35:03 - train.py[line:166] - INFO: max tokens per device = None and max sentences per device = 8
2022-05-10 21:35:03 - train.py[line:172] - INFO: nvidia-smi stats: {'gpu_0_mem_used_gb': 1.5810546875, 'gpu_1_mem_used_gb': 16.5830078125, 'gpu_2_mem_used_gb': 0.0, 'gpu_3_mem_used_gb': 3.7705078125}
2022-05-10 21:35:03 - trainer.py[line:728] - INFO: No existing checkpoint found ./moe_stage1_checkpoints/2_0.06_2500/dum-rank-0.pt
2022-05-10 21:35:03 - trainer.py[line:743] - INFO: loading train data for epoch 1
local datafile ../../dataset/caption_data/caption_stage1_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/caption_data/caption_stage1_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/caption_data/caption_stage1_train.tsv slice_id 0 row count 566747 total row count 566747
/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
slice_id 0 seek offset 0
2022-05-10 21:35:29 - adam.py[line:70] - INFO: using FusedAdam
Total steps 354220, warmup steps 21253, warmup_factor 4.7052180868583256e-05
2022-05-10 21:35:29 - trainer.py[line:807] - INFO: begin training epoch 1
2022-05-10 21:35:29 - train.py[line:315] - INFO: Start iterating over samples
2022-05-10 21:36:03 - progress_bar.py[line:272] - INFO: epoch 001:     10 / 17711 loss=12.419, loss_v1=0, loss_v2=0, nll_loss=11.24, ntokens=383.7, nsentences=32, sample_size=383.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.18821, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.419, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.294, expert1_balance_top=66.881, expert1_balance_bottom=2.13, unused_expert1_count=0.283, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=2419.02, wps=153.4, ups=0.4, wpb=383.7, bsz=32, num_updates=10, lr=4.70522e-09, gnorm=18.353, loss_scale=128, train_wall=32, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=61
2022-05-10 21:36:23 - progress_bar.py[line:272] - INFO: epoch 001:     20 / 17711 loss=12.411, loss_v1=0, loss_v2=0, nll_loss=11.224, ntokens=381.9, nsentences=32, sample_size=381.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.19452, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.411, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.294, expert1_balance_top=66.981, expert1_balance_bottom=2.217, unused_expert1_count=0.275, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=2392.36, wps=197.7, ups=0.52, wpb=381.9, bsz=32, num_updates=20, lr=9.41044e-09, gnorm=18.349, loss_scale=128, train_wall=18, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=80
2022-05-10 21:36:40 - progress_bar.py[line:272] - INFO: epoch 001:     30 / 17711 loss=12.409, loss_v1=0, loss_v2=0, nll_loss=11.226, ntokens=379.6, nsentences=32, sample_size=379.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.19071, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.409, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.294, expert1_balance_top=67.215, expert1_balance_bottom=2.303, unused_expert1_count=0.287, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=2395.75, wps=220.9, ups=0.58, wpb=379.6, bsz=32, num_updates=30, lr=1.41157e-08, gnorm=18.371, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=97
2022-05-10 21:36:57 - progress_bar.py[line:272] - INFO: epoch 001:     40 / 17711 loss=12.407, loss_v1=0, loss_v2=0, nll_loss=11.231, ntokens=377.9, nsentences=32, sample_size=377.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.18431, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.407, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.295, expert1_balance_top=66.633, expert1_balance_bottom=2.268, unused_expert1_count=0.285, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=2403.59, wps=217.7, ups=0.58, wpb=377.9, bsz=32, num_updates=40, lr=1.88209e-08, gnorm=18.047, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=115
2022-05-10 21:37:15 - progress_bar.py[line:272] - INFO: epoch 001:     50 / 17711 loss=12.42, loss_v1=0, loss_v2=0, nll_loss=11.221, ntokens=383, nsentences=32, sample_size=383, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.20631, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.42, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.294, expert1_balance_top=67.265, expert1_balance_bottom=2.239, unused_expert1_count=0.304, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=2387.35, wps=220.3, ups=0.58, wpb=383, bsz=32, num_updates=50, lr=2.35261e-08, gnorm=18.376, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=132
2022-05-10 21:37:33 - progress_bar.py[line:272] - INFO: epoch 001:     60 / 17711 loss=12.38, loss_v1=0, loss_v2=0, nll_loss=11.211, ntokens=385.8, nsentences=32, sample_size=385.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.1758, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.38, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.295, expert1_balance_top=65.89, expert1_balance_bottom=2.357, unused_expert1_count=0.287, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=2370.22, wps=210.1, ups=0.54, wpb=385.8, bsz=32, num_updates=60, lr=2.82313e-08, gnorm=18.317, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=150
2022-05-10 21:37:51 - progress_bar.py[line:272] - INFO: epoch 001:     70 / 17711 loss=12.401, loss_v1=0, loss_v2=0, nll_loss=11.216, ntokens=376.4, nsentences=32, sample_size=376.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.19122, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.401, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.294, expert1_balance_top=66.751, expert1_balance_bottom=2.269, unused_expert1_count=0.283, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=2379.46, wps=215.4, ups=0.57, wpb=376.4, bsz=32, num_updates=70, lr=3.29365e-08, gnorm=18.051, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=168
2022-05-10 21:38:09 - progress_bar.py[line:272] - INFO: epoch 001:     80 / 17711 loss=12.396, loss_v1=0, loss_v2=0, nll_loss=11.209, ntokens=376.8, nsentences=32, sample_size=376.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.19224, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.396, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.295, expert1_balance_top=66.378, expert1_balance_bottom=2.339, unused_expert1_count=0.279, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=2368.05, wps=206, ups=0.55, wpb=376.8, bsz=32, num_updates=80, lr=3.76417e-08, gnorm=18.348, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=186
2022-05-10 21:38:28 - progress_bar.py[line:272] - INFO: epoch 001:     90 / 17711 loss=12.394, loss_v1=0, loss_v2=0, nll_loss=11.212, ntokens=390.5, nsentences=32, sample_size=390.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.18894, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.394, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.294, expert1_balance_top=66.666, expert1_balance_bottom=2.377, unused_expert1_count=0.281, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=2371.8, wps=206.3, ups=0.53, wpb=390.5, bsz=32, num_updates=90, lr=4.2347e-08, gnorm=18.072, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=205
2022-05-10 21:38:45 - progress_bar.py[line:272] - INFO: epoch 001:    100 / 17711 loss=12.379, loss_v1=0, loss_v2=0, nll_loss=11.214, ntokens=392.4, nsentences=32, sample_size=392.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.17148, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.379, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.296, expert1_balance_top=65.46, expert1_balance_bottom=2.346, unused_expert1_count=0.279, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=2375.85, wps=224.6, ups=0.57, wpb=392.4, bsz=32, num_updates=100, lr=4.70522e-08, gnorm=18.598, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=222
2022-05-10 21:39:03 - progress_bar.py[line:272] - INFO: epoch 001:    110 / 17711 loss=12.394, loss_v1=0, loss_v2=0, nll_loss=11.218, ntokens=389, nsentences=32, sample_size=389, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.18295, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.394, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.296, expert1_balance_top=65.03, expert1_balance_bottom=2.434, unused_expert1_count=0.256, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=2382.17, wps=217.9, ups=0.56, wpb=389, bsz=32, num_updates=110, lr=5.17574e-08, gnorm=18.583, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=240
2022-05-10 21:39:21 - progress_bar.py[line:272] - INFO: epoch 001:    120 / 17711 loss=12.347, loss_v1=0, loss_v2=0, nll_loss=11.187, ntokens=378.8, nsentences=32, sample_size=378.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.16471, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.347, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.297, expert1_balance_top=64.592, expert1_balance_bottom=2.379, unused_expert1_count=0.288, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=2330.83, wps=216.5, ups=0.57, wpb=378.8, bsz=32, num_updates=120, lr=5.64626e-08, gnorm=17.744, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=258
2022-05-10 21:39:38 - progress_bar.py[line:272] - INFO: epoch 001:    130 / 17711 loss=12.373, loss_v1=0, loss_v2=0, nll_loss=11.199, ntokens=379.7, nsentences=32, sample_size=379.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.17908, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.373, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.298, expert1_balance_top=64.745, expert1_balance_bottom=2.418, unused_expert1_count=0.242, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=2351.16, wps=218.3, ups=0.57, wpb=379.7, bsz=32, num_updates=130, lr=6.11678e-08, gnorm=17.547, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=275
2022-05-10 21:39:56 - progress_bar.py[line:272] - INFO: epoch 001:    140 / 17711 loss=12.318, loss_v1=0, loss_v2=0, nll_loss=11.171, ntokens=379.5, nsentences=32, sample_size=379.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.14939, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.318, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.302, expert1_balance_top=62.007, expert1_balance_bottom=2.802, unused_expert1_count=0.242, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=2306.13, wps=214.9, ups=0.57, wpb=379.5, bsz=32, num_updates=140, lr=6.58731e-08, gnorm=18.18, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=293
2022-05-10 21:40:13 - progress_bar.py[line:272] - INFO: epoch 001:    150 / 17711 loss=12.259, loss_v1=0, loss_v2=0, nll_loss=11.12, ntokens=379.2, nsentences=32, sample_size=379.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.13627, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.259, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.303, expert1_balance_top=60.713, expert1_balance_bottom=2.829, unused_expert1_count=0.24, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=2226.32, wps=219, ups=0.58, wpb=379.2, bsz=32, num_updates=150, lr=7.05783e-08, gnorm=17.917, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=310
2022-05-10 21:40:31 - progress_bar.py[line:272] - INFO: epoch 001:    160 / 17711 loss=12.249, loss_v1=0, loss_v2=0, nll_loss=11.115, ntokens=381.5, nsentences=32, sample_size=381.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.13062, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.249, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.304, expert1_balance_top=60.154, expert1_balance_bottom=3.028, unused_expert1_count=0.238, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=2218.12, wps=214.2, ups=0.56, wpb=381.5, bsz=32, num_updates=160, lr=7.52835e-08, gnorm=17.079, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=328
2022-05-10 21:40:49 - progress_bar.py[line:272] - INFO: epoch 001:    170 / 17711 loss=12.263, loss_v1=0, loss_v2=0, nll_loss=11.134, ntokens=386.3, nsentences=32, sample_size=386.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.12741, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.263, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.305, expert1_balance_top=59.065, expert1_balance_bottom=3.082, unused_expert1_count=0.24, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=2247.81, wps=206.8, ups=0.54, wpb=386.3, bsz=32, num_updates=170, lr=7.99887e-08, gnorm=16.998, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=347
2022-05-10 21:41:07 - progress_bar.py[line:272] - INFO: epoch 001:    180 / 17711 loss=12.215, loss_v1=0, loss_v2=0, nll_loss=11.088, ntokens=377.5, nsentences=32, sample_size=377.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.12124, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.215, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.305, expert1_balance_top=59.742, expert1_balance_bottom=3.08, unused_expert1_count=0.227, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=2176.13, wps=216.5, ups=0.57, wpb=377.5, bsz=32, num_updates=180, lr=8.46939e-08, gnorm=17.193, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=364
2022-05-10 21:41:25 - progress_bar.py[line:272] - INFO: epoch 001:    190 / 17711 loss=12.151, loss_v1=0, loss_v2=0, nll_loss=11.035, ntokens=385.6, nsentences=32, sample_size=385.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.10518, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.151, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.309, expert1_balance_top=58.357, expert1_balance_bottom=3.568, unused_expert1_count=0.202, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=2097.58, wps=209, ups=0.54, wpb=385.6, bsz=32, num_updates=190, lr=8.93991e-08, gnorm=17.109, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=383
2022-05-10 21:41:43 - progress_bar.py[line:272] - INFO: epoch 001:    200 / 17711 loss=12.044, loss_v1=0, loss_v2=0, nll_loss=10.952, ntokens=382.7, nsentences=32, sample_size=382.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.07259, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.044, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.313, expert1_balance_top=54.129, expert1_balance_bottom=4.024, unused_expert1_count=0.217, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1981.25, wps=218.3, ups=0.57, wpb=382.7, bsz=32, num_updates=200, lr=9.41044e-08, gnorm=15.782, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=400
2022-05-10 21:42:00 - progress_bar.py[line:272] - INFO: epoch 001:    210 / 17711 loss=12.028, loss_v1=0, loss_v2=0, nll_loss=10.943, ntokens=381.6, nsentences=32, sample_size=381.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.06433, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.028, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.314, expert1_balance_top=52.784, expert1_balance_bottom=4.228, unused_expert1_count=0.188, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1968.78, wps=218.7, ups=0.57, wpb=381.6, bsz=32, num_updates=210, lr=9.88096e-08, gnorm=16.323, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=417
2022-05-10 21:42:18 - progress_bar.py[line:272] - INFO: epoch 001:    220 / 17711 loss=12.027, loss_v1=0, loss_v2=0, nll_loss=10.941, ntokens=375.7, nsentences=32, sample_size=375.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.06588, inner_loss_v1=0, inner_loss_v2=0, inner_loss=12.027, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.315, expert1_balance_top=51.515, expert1_balance_bottom=4.264, unused_expert1_count=0.194, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1965.27, wps=207.9, ups=0.55, wpb=375.7, bsz=32, num_updates=220, lr=1.03515e-07, gnorm=16.052, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=436
2022-05-10 21:42:36 - progress_bar.py[line:272] - INFO: epoch 001:    230 / 17711 loss=11.969, loss_v1=0, loss_v2=0, nll_loss=10.884, ntokens=377.6, nsentences=32, sample_size=377.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.05895, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.969, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.316, expert1_balance_top=51.428, expert1_balance_bottom=4.567, unused_expert1_count=0.185, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1889.45, wps=215.6, ups=0.57, wpb=377.6, bsz=32, num_updates=230, lr=1.0822e-07, gnorm=16.086, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=453
2022-05-10 21:42:55 - progress_bar.py[line:272] - INFO: epoch 001:    240 / 17711 loss=11.95, loss_v1=0, loss_v2=0, nll_loss=10.885, ntokens=380.5, nsentences=32, sample_size=380.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.03932, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.95, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.317, expert1_balance_top=51.026, expert1_balance_bottom=4.99, unused_expert1_count=0.171, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1890.79, wps=204.4, ups=0.54, wpb=380.5, bsz=32, num_updates=240, lr=1.12925e-07, gnorm=15.682, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=472
2022-05-10 21:43:12 - progress_bar.py[line:272] - INFO: epoch 001:    250 / 17711 loss=11.903, loss_v1=0, loss_v2=0, nll_loss=10.84, ntokens=387.4, nsentences=32, sample_size=387.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.03203, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.903, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.319, expert1_balance_top=49.805, expert1_balance_bottom=5.214, unused_expert1_count=0.175, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1833.08, wps=222.7, ups=0.57, wpb=387.4, bsz=32, num_updates=250, lr=1.1763e-07, gnorm=15.135, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=489
2022-05-10 21:43:29 - progress_bar.py[line:272] - INFO: epoch 001:    260 / 17711 loss=11.844, loss_v1=0, loss_v2=0, nll_loss=10.777, ntokens=385.8, nsentences=32, sample_size=385.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.03042, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.844, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.32, expert1_balance_top=50.091, expert1_balance_bottom=5.528, unused_expert1_count=0.152, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1754.27, wps=222.2, ups=0.58, wpb=385.8, bsz=32, num_updates=260, lr=1.22336e-07, gnorm=15.563, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=506
2022-05-10 21:43:46 - progress_bar.py[line:272] - INFO: epoch 001:    270 / 17711 loss=11.83, loss_v1=0, loss_v2=0, nll_loss=10.771, ntokens=384.1, nsentences=32, sample_size=384.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.02142, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.83, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.321, expert1_balance_top=49.566, expert1_balance_bottom=5.862, unused_expert1_count=0.152, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1747.49, wps=223.3, ups=0.58, wpb=384.1, bsz=32, num_updates=270, lr=1.27041e-07, gnorm=15.274, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=524
2022-05-10 21:44:04 - progress_bar.py[line:272] - INFO: epoch 001:    280 / 17711 loss=11.785, loss_v1=0, loss_v2=0, nll_loss=10.699, ntokens=381.7, nsentences=32, sample_size=381.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.04077, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.785, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.322, expert1_balance_top=48.523, expert1_balance_bottom=5.94, unused_expert1_count=0.138, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1662.36, wps=218.6, ups=0.57, wpb=381.7, bsz=32, num_updates=280, lr=1.31746e-07, gnorm=16.221, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=541
2022-05-10 21:44:21 - progress_bar.py[line:272] - INFO: epoch 001:    290 / 17711 loss=11.69, loss_v1=0, loss_v2=0, nll_loss=10.617, ntokens=379.3, nsentences=32, sample_size=379.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.02025, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.69, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.324, expert1_balance_top=47.637, expert1_balance_bottom=6.686, unused_expert1_count=0.133, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1570.2, wps=217.3, ups=0.57, wpb=379.3, bsz=32, num_updates=290, lr=1.36451e-07, gnorm=16.021, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=559
2022-05-10 21:44:39 - progress_bar.py[line:272] - INFO: epoch 001:    300 / 17711 loss=11.67, loss_v1=0, loss_v2=0, nll_loss=10.592, ntokens=375.4, nsentences=32, sample_size=375.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.02217, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.67, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.325, expert1_balance_top=46.717, expert1_balance_bottom=6.467, unused_expert1_count=0.108, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1543.35, wps=210.6, ups=0.56, wpb=375.4, bsz=32, num_updates=300, lr=1.41157e-07, gnorm=15.053, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=576
2022-05-10 21:44:58 - progress_bar.py[line:272] - INFO: epoch 001:    310 / 17711 loss=11.649, loss_v1=0, loss_v2=0, nll_loss=10.585, ntokens=385.6, nsentences=32, sample_size=385.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.00771, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.649, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.325, expert1_balance_top=46.198, expert1_balance_bottom=6.372, unused_expert1_count=0.123, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1535.84, wps=205.7, ups=0.53, wpb=385.6, bsz=32, num_updates=310, lr=1.45862e-07, gnorm=15.17, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=595
2022-05-10 21:45:15 - progress_bar.py[line:272] - INFO: epoch 001:    320 / 17711 loss=11.607, loss_v1=0, loss_v2=0, nll_loss=10.548, ntokens=383.4, nsentences=32, sample_size=383.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.999289, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.607, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.327, expert1_balance_top=45.928, expert1_balance_bottom=6.655, unused_expert1_count=0.113, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1496.83, wps=223.2, ups=0.58, wpb=383.4, bsz=32, num_updates=320, lr=1.50567e-07, gnorm=14.667, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=612
2022-05-10 21:45:33 - progress_bar.py[line:272] - INFO: epoch 001:    330 / 17711 loss=11.512, loss_v1=0, loss_v2=0, nll_loss=10.444, ntokens=385.4, nsentences=32, sample_size=385.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.997406, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.512, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.328, expert1_balance_top=44.871, expert1_balance_bottom=7.18, unused_expert1_count=0.11, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1392.69, wps=219.6, ups=0.57, wpb=385.4, bsz=32, num_updates=330, lr=1.55272e-07, gnorm=15.402, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=630
2022-05-10 21:45:50 - progress_bar.py[line:272] - INFO: epoch 001:    340 / 17711 loss=11.516, loss_v1=0, loss_v2=0, nll_loss=10.441, ntokens=380.4, nsentences=32, sample_size=380.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.00429, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.516, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.329, expert1_balance_top=44.061, expert1_balance_bottom=7.391, unused_expert1_count=0.119, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1390.19, wps=217.4, ups=0.57, wpb=380.4, bsz=32, num_updates=340, lr=1.59977e-07, gnorm=14.766, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=647
2022-05-10 21:46:08 - progress_bar.py[line:272] - INFO: epoch 001:    350 / 17711 loss=11.449, loss_v1=0, loss_v2=0, nll_loss=10.37, ntokens=380.7, nsentences=32, sample_size=380.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=1.00099, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.449, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.33, expert1_balance_top=43.17, expert1_balance_bottom=7.623, unused_expert1_count=0.106, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1323.76, wps=216.9, ups=0.57, wpb=380.7, bsz=32, num_updates=350, lr=1.64683e-07, gnorm=14.959, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=665
2022-05-10 21:46:25 - progress_bar.py[line:272] - INFO: epoch 001:    360 / 17711 loss=11.418, loss_v1=0, loss_v2=0, nll_loss=10.337, ntokens=382, nsentences=32, sample_size=382, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.999607, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.418, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.331, expert1_balance_top=42.627, expert1_balance_bottom=7.945, unused_expert1_count=0.115, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1293.46, wps=223.4, ups=0.58, wpb=382, bsz=32, num_updates=360, lr=1.69388e-07, gnorm=14.686, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=682
2022-05-10 21:46:42 - progress_bar.py[line:272] - INFO: epoch 001:    370 / 17711 loss=11.346, loss_v1=0, loss_v2=0, nll_loss=10.277, ntokens=388, nsentences=32, sample_size=388, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.981459, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.346, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.332, expert1_balance_top=42.258, expert1_balance_bottom=7.966, unused_expert1_count=0.106, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1240.87, wps=225.7, ups=0.58, wpb=388, bsz=32, num_updates=370, lr=1.74093e-07, gnorm=14.802, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=699
2022-05-10 21:46:59 - progress_bar.py[line:272] - INFO: epoch 001:    380 / 17711 loss=11.316, loss_v1=0, loss_v2=0, nll_loss=10.239, ntokens=391.1, nsentences=32, sample_size=391.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.985757, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.316, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.333, expert1_balance_top=41.666, expert1_balance_bottom=8.164, unused_expert1_count=0.1, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1208.17, wps=226.4, ups=0.58, wpb=391.1, bsz=32, num_updates=380, lr=1.78798e-07, gnorm=14.253, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=716
2022-05-10 21:47:16 - progress_bar.py[line:272] - INFO: epoch 001:    390 / 17711 loss=11.254, loss_v1=0, loss_v2=0, nll_loss=10.191, ntokens=389.6, nsentences=32, sample_size=389.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.967044, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.254, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.334, expert1_balance_top=41.512, expert1_balance_bottom=8.048, unused_expert1_count=0.102, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1168.57, wps=226.8, ups=0.58, wpb=389.6, bsz=32, num_updates=390, lr=1.83504e-07, gnorm=14.472, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=734
2022-05-10 21:47:34 - progress_bar.py[line:272] - INFO: epoch 001:    400 / 17711 loss=11.202, loss_v1=0, loss_v2=0, nll_loss=10.14, ntokens=387.5, nsentences=32, sample_size=387.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.960409, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.202, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.334, expert1_balance_top=41.241, expert1_balance_bottom=8.186, unused_expert1_count=0.1, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1128.33, wps=224, ups=0.58, wpb=387.5, bsz=32, num_updates=400, lr=1.88209e-07, gnorm=14.287, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=751
2022-05-10 21:47:51 - progress_bar.py[line:272] - INFO: epoch 001:    410 / 17711 loss=11.146, loss_v1=0, loss_v2=0, nll_loss=10.08, ntokens=384.5, nsentences=32, sample_size=384.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.958453, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.146, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.335, expert1_balance_top=41.192, expert1_balance_bottom=8.043, unused_expert1_count=0.102, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1082.52, wps=220.4, ups=0.57, wpb=384.5, bsz=32, num_updates=410, lr=1.92914e-07, gnorm=14.295, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=768
2022-05-10 21:48:09 - progress_bar.py[line:272] - INFO: epoch 001:    420 / 17711 loss=11.105, loss_v1=0, loss_v2=0, nll_loss=10.034, ntokens=376.8, nsentences=32, sample_size=376.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.959631, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.105, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.336, expert1_balance_top=40.652, expert1_balance_bottom=8.07, unused_expert1_count=0.098, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1048.18, wps=216.5, ups=0.57, wpb=376.8, bsz=32, num_updates=420, lr=1.97619e-07, gnorm=13.827, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=786
2022-05-10 21:48:26 - progress_bar.py[line:272] - INFO: epoch 001:    430 / 17711 loss=11.134, loss_v1=0, loss_v2=0, nll_loss=10.069, ntokens=384.2, nsentences=32, sample_size=384.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.956625, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.134, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.338, expert1_balance_top=40.151, expert1_balance_bottom=8.594, unused_expert1_count=0.085, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=1074.08, wps=224.7, ups=0.58, wpb=384.2, bsz=32, num_updates=430, lr=2.02324e-07, gnorm=13.387, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=803
2022-05-10 21:48:43 - progress_bar.py[line:272] - INFO: epoch 001:    440 / 17711 loss=11.022, loss_v1=0, loss_v2=0, nll_loss=9.941, ntokens=378.1, nsentences=32, sample_size=378.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.959542, inner_loss_v1=0, inner_loss_v2=0, inner_loss=11.022, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.339, expert1_balance_top=39.684, expert1_balance_bottom=8.932, unused_expert1_count=0.085, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=982.84, wps=215.6, ups=0.57, wpb=378.1, bsz=32, num_updates=440, lr=2.0703e-07, gnorm=12.858, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=820
2022-05-10 21:49:01 - progress_bar.py[line:272] - INFO: epoch 001:    450 / 17711 loss=10.984, loss_v1=0, loss_v2=0, nll_loss=9.914, ntokens=378, nsentences=32, sample_size=378, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.946309, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.984, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.339, expert1_balance_top=39.221, expert1_balance_bottom=8.966, unused_expert1_count=0.075, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=964.48, wps=213.8, ups=0.57, wpb=378, bsz=32, num_updates=450, lr=2.11735e-07, gnorm=13.498, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=838
2022-05-10 21:49:18 - progress_bar.py[line:272] - INFO: epoch 001:    460 / 17711 loss=10.942, loss_v1=0, loss_v2=0, nll_loss=9.867, ntokens=378.6, nsentences=32, sample_size=378.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.945622, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.942, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.34, expert1_balance_top=38.185, expert1_balance_bottom=9.567, unused_expert1_count=0.081, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=934.02, wps=215.9, ups=0.57, wpb=378.6, bsz=32, num_updates=460, lr=2.1644e-07, gnorm=12.717, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=856
2022-05-10 21:49:36 - progress_bar.py[line:272] - INFO: epoch 001:    470 / 17711 loss=10.874, loss_v1=0, loss_v2=0, nll_loss=9.776, ntokens=381.5, nsentences=32, sample_size=381.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.959406, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.874, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.341, expert1_balance_top=38.401, expert1_balance_bottom=9.39, unused_expert1_count=0.071, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=876.66, wps=220.7, ups=0.58, wpb=381.5, bsz=32, num_updates=470, lr=2.21145e-07, gnorm=12.347, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=873
2022-05-10 21:49:53 - progress_bar.py[line:272] - INFO: epoch 001:    480 / 17711 loss=10.843, loss_v1=0, loss_v2=0, nll_loss=9.756, ntokens=373, nsentences=32, sample_size=373, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.946538, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.843, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.342, expert1_balance_top=38.095, expert1_balance_bottom=9.856, unused_expert1_count=0.067, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=864.4, wps=216, ups=0.58, wpb=373, bsz=32, num_updates=480, lr=2.2585e-07, gnorm=12.217, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=890
2022-05-10 21:50:10 - progress_bar.py[line:272] - INFO: epoch 001:    490 / 17711 loss=10.813, loss_v1=0, loss_v2=0, nll_loss=9.723, ntokens=384.8, nsentences=32, sample_size=384.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.946048, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.813, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.343, expert1_balance_top=37.291, expert1_balance_bottom=10.124, unused_expert1_count=0.054, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=845.04, wps=222.1, ups=0.58, wpb=384.8, bsz=32, num_updates=490, lr=2.30556e-07, gnorm=11.824, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=908
2022-05-10 21:50:27 - progress_bar.py[line:272] - INFO: epoch 001:    500 / 17711 loss=10.763, loss_v1=0, loss_v2=0, nll_loss=9.675, ntokens=385.8, nsentences=32, sample_size=385.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.938546, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.763, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.343, expert1_balance_top=36.802, expert1_balance_bottom=10.762, unused_expert1_count=0.035, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=817.34, wps=228.1, ups=0.59, wpb=385.8, bsz=32, num_updates=500, lr=2.35261e-07, gnorm=11.541, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=924
2022-05-10 21:50:45 - progress_bar.py[line:272] - INFO: epoch 001:    510 / 17711 loss=10.753, loss_v1=0, loss_v2=0, nll_loss=9.668, ntokens=382, nsentences=32, sample_size=382, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.934968, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.753, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.345, expert1_balance_top=36.579, expert1_balance_bottom=11.167, unused_expert1_count=0.008, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=813.5, wps=220.1, ups=0.58, wpb=382, bsz=32, num_updates=510, lr=2.39966e-07, gnorm=11.842, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=942
2022-05-10 21:51:00 - trainer.py[line:1047] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2022-05-10 21:51:04 - progress_bar.py[line:272] - INFO: epoch 001:    521 / 17711 loss=10.734, loss_v1=0, loss_v2=0, nll_loss=9.649, ntokens=383.7, nsentences=32, sample_size=383.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.933332, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.734, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.345, expert1_balance_top=36.436, expert1_balance_bottom=11.184, unused_expert1_count=0.004, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=802.64, wps=200.4, ups=0.52, wpb=383.7, bsz=32, num_updates=520, lr=2.44671e-07, gnorm=11.33, loss_scale=128, train_wall=18, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=961
2022-05-10 21:51:22 - progress_bar.py[line:272] - INFO: epoch 001:    531 / 17711 loss=10.715, loss_v1=0, loss_v2=0, nll_loss=9.633, ntokens=383.9, nsentences=32, sample_size=383.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.927869, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.715, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.345, expert1_balance_top=36.264, expert1_balance_bottom=11.781, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=794.12, wps=216.7, ups=0.56, wpb=383.9, bsz=32, num_updates=530, lr=2.49377e-07, gnorm=11.21, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=979
2022-05-10 21:51:39 - progress_bar.py[line:272] - INFO: epoch 001:    541 / 17711 loss=10.621, loss_v1=0, loss_v2=0, nll_loss=9.537, ntokens=374.8, nsentences=32, sample_size=374.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.919893, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.621, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.347, expert1_balance_top=35.458, expert1_balance_bottom=12.233, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=742.77, wps=215.4, ups=0.57, wpb=374.8, bsz=32, num_updates=540, lr=2.54082e-07, gnorm=11.747, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=996
2022-05-10 21:51:56 - progress_bar.py[line:272] - INFO: epoch 001:    551 / 17711 loss=10.625, loss_v1=0, loss_v2=0, nll_loss=9.535, ntokens=388.2, nsentences=32, sample_size=388.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.925839, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.625, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.348, expert1_balance_top=35.394, expert1_balance_bottom=12.64, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=741.7, wps=222.6, ups=0.57, wpb=388.2, bsz=32, num_updates=550, lr=2.58787e-07, gnorm=10.953, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1014
2022-05-10 21:52:14 - progress_bar.py[line:272] - INFO: epoch 001:    561 / 17711 loss=10.615, loss_v1=0, loss_v2=0, nll_loss=9.527, ntokens=390.9, nsentences=32, sample_size=390.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.922477, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.615, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.348, expert1_balance_top=35.277, expert1_balance_bottom=12.87, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=737.84, wps=220.1, ups=0.56, wpb=390.9, bsz=32, num_updates=560, lr=2.63492e-07, gnorm=10.632, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1031
2022-05-10 21:52:31 - progress_bar.py[line:272] - INFO: epoch 001:    571 / 17711 loss=10.564, loss_v1=0, loss_v2=0, nll_loss=9.48, ntokens=384.5, nsentences=32, sample_size=384.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.91338, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.564, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.349, expert1_balance_top=35.318, expert1_balance_bottom=13.111, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=713.89, wps=222.5, ups=0.58, wpb=384.5, bsz=32, num_updates=570, lr=2.68197e-07, gnorm=10.77, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1049
2022-05-10 21:52:49 - progress_bar.py[line:272] - INFO: epoch 001:    581 / 17711 loss=10.556, loss_v1=0, loss_v2=0, nll_loss=9.466, ntokens=385.6, nsentences=32, sample_size=385.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.918042, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.556, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.349, expert1_balance_top=34.731, expert1_balance_bottom=13.496, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=706.99, wps=220.6, ups=0.57, wpb=385.6, bsz=32, num_updates=580, lr=2.72903e-07, gnorm=9.781, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1066
2022-05-10 21:53:07 - progress_bar.py[line:272] - INFO: epoch 001:    591 / 17711 loss=10.523, loss_v1=0, loss_v2=0, nll_loss=9.455, ntokens=383.6, nsentences=32, sample_size=383.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.894938, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.523, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.351, expert1_balance_top=34.393, expert1_balance_bottom=13.945, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=701.61, wps=216.2, ups=0.56, wpb=383.6, bsz=32, num_updates=590, lr=2.77608e-07, gnorm=9.947, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1084
2022-05-10 21:53:24 - progress_bar.py[line:272] - INFO: epoch 001:    601 / 17711 loss=10.547, loss_v1=0, loss_v2=0, nll_loss=9.469, ntokens=385.7, nsentences=32, sample_size=385.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.906115, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.547, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.351, expert1_balance_top=34.195, expert1_balance_bottom=14.243, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=708.49, wps=220.3, ups=0.57, wpb=385.7, bsz=32, num_updates=600, lr=2.82313e-07, gnorm=9.965, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1101
2022-05-10 21:53:42 - progress_bar.py[line:272] - INFO: epoch 001:    611 / 17711 loss=10.478, loss_v1=0, loss_v2=0, nll_loss=9.39, ntokens=379, nsentences=32, sample_size=379, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.908106, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.478, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.351, expert1_balance_top=34.215, expert1_balance_bottom=14.234, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=670.96, wps=215.7, ups=0.57, wpb=379, bsz=32, num_updates=610, lr=2.87018e-07, gnorm=10.08, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1119
2022-05-10 21:53:59 - progress_bar.py[line:272] - INFO: epoch 001:    621 / 17711 loss=10.492, loss_v1=0, loss_v2=0, nll_loss=9.402, ntokens=381.1, nsentences=32, sample_size=381.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.910554, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.492, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.351, expert1_balance_top=33.789, expert1_balance_bottom=14.927, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=676.75, wps=215.9, ups=0.57, wpb=381.1, bsz=32, num_updates=620, lr=2.91724e-07, gnorm=10.065, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1137
2022-05-10 21:54:17 - progress_bar.py[line:272] - INFO: epoch 001:    631 / 17711 loss=10.412, loss_v1=0, loss_v2=0, nll_loss=9.327, ntokens=380.9, nsentences=32, sample_size=380.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.898471, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.412, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.352, expert1_balance_top=33.227, expert1_balance_bottom=15.456, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=642.16, wps=214.7, ups=0.56, wpb=380.9, bsz=32, num_updates=630, lr=2.96429e-07, gnorm=9.772, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1154
2022-05-10 21:54:35 - progress_bar.py[line:272] - INFO: epoch 001:    641 / 17711 loss=10.401, loss_v1=0, loss_v2=0, nll_loss=9.32, ntokens=380.5, nsentences=32, sample_size=380.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.892736, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.401, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.352, expert1_balance_top=33.16, expert1_balance_bottom=15.975, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=639.31, wps=217.3, ups=0.57, wpb=380.5, bsz=32, num_updates=640, lr=3.01134e-07, gnorm=9.734, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1172
2022-05-10 21:54:52 - progress_bar.py[line:272] - INFO: epoch 001:    651 / 17711 loss=10.378, loss_v1=0, loss_v2=0, nll_loss=9.291, ntokens=385.5, nsentences=32, sample_size=385.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.895141, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.378, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.352, expert1_balance_top=33.429, expert1_balance_bottom=16.026, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=626.59, wps=217.9, ups=0.57, wpb=385.5, bsz=32, num_updates=650, lr=3.05839e-07, gnorm=9.646, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1189
2022-05-10 21:55:10 - progress_bar.py[line:272] - INFO: epoch 001:    661 / 17711 loss=10.414, loss_v1=0, loss_v2=0, nll_loss=9.33, ntokens=387.1, nsentences=32, sample_size=387.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.896511, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.414, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.353, expert1_balance_top=32.811, expert1_balance_bottom=16.716, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=643.68, wps=216.4, ups=0.56, wpb=387.1, bsz=32, num_updates=660, lr=3.10544e-07, gnorm=9.106, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1207
2022-05-10 21:55:28 - progress_bar.py[line:272] - INFO: epoch 001:    671 / 17711 loss=10.342, loss_v1=0, loss_v2=0, nll_loss=9.246, ntokens=385.8, nsentences=32, sample_size=385.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.900297, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.342, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.353, expert1_balance_top=33.058, expert1_balance_bottom=16.747, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=606.99, wps=215.7, ups=0.56, wpb=385.8, bsz=32, num_updates=670, lr=3.1525e-07, gnorm=9.701, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1225
2022-05-10 21:55:46 - progress_bar.py[line:272] - INFO: epoch 001:    681 / 17711 loss=10.312, loss_v1=0, loss_v2=0, nll_loss=9.231, ntokens=392.1, nsentences=32, sample_size=392.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.883865, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.312, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.353, expert1_balance_top=33.12, expert1_balance_bottom=17.103, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=600.8, wps=219.8, ups=0.56, wpb=392.1, bsz=32, num_updates=680, lr=3.19955e-07, gnorm=8.577, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1243
2022-05-10 21:56:04 - progress_bar.py[line:272] - INFO: epoch 001:    691 / 17711 loss=10.322, loss_v1=0, loss_v2=0, nll_loss=9.238, ntokens=382.5, nsentences=32, sample_size=382.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.886901, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.322, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.353, expert1_balance_top=32.51, expert1_balance_bottom=17.407, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=603.82, wps=211.3, ups=0.55, wpb=382.5, bsz=32, num_updates=690, lr=3.2466e-07, gnorm=9.558, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1261
2022-05-10 21:56:22 - progress_bar.py[line:272] - INFO: epoch 001:    701 / 17711 loss=10.3, loss_v1=0, loss_v2=0, nll_loss=9.211, ntokens=385.9, nsentences=32, sample_size=385.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.888473, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.3, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.353, expert1_balance_top=32.229, expert1_balance_bottom=17.856, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=592.75, wps=213.7, ups=0.55, wpb=385.9, bsz=32, num_updates=700, lr=3.29365e-07, gnorm=9.022, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1279
2022-05-10 21:56:40 - progress_bar.py[line:272] - INFO: epoch 001:    711 / 17711 loss=10.335, loss_v1=0, loss_v2=0, nll_loss=9.247, ntokens=386.4, nsentences=32, sample_size=386.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.89096, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.335, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=32.18, expert1_balance_bottom=18.144, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=607.82, wps=219.1, ups=0.57, wpb=386.4, bsz=32, num_updates=710, lr=3.3407e-07, gnorm=9.074, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1297
2022-05-10 21:56:57 - progress_bar.py[line:272] - INFO: epoch 001:    721 / 17711 loss=10.321, loss_v1=0, loss_v2=0, nll_loss=9.222, ntokens=381.8, nsentences=32, sample_size=381.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.899561, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.321, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=31.914, expert1_balance_bottom=18.345, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=597.18, wps=217.8, ups=0.57, wpb=381.8, bsz=32, num_updates=720, lr=3.38776e-07, gnorm=9.312, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1314
2022-05-10 21:57:15 - progress_bar.py[line:272] - INFO: epoch 001:    731 / 17711 loss=10.337, loss_v1=0, loss_v2=0, nll_loss=9.252, ntokens=385, nsentences=32, sample_size=385, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.888936, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.337, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.353, expert1_balance_top=32.294, expert1_balance_bottom=18.459, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=609.72, wps=218.5, ups=0.57, wpb=385, bsz=32, num_updates=730, lr=3.43481e-07, gnorm=8.953, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1332
2022-05-10 21:57:33 - progress_bar.py[line:272] - INFO: epoch 001:    741 / 17711 loss=10.264, loss_v1=0, loss_v2=0, nll_loss=9.155, ntokens=377.2, nsentences=32, sample_size=377.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.902979, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.264, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=32.525, expert1_balance_bottom=18.178, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=569.88, wps=207.3, ups=0.55, wpb=377.2, bsz=32, num_updates=740, lr=3.48186e-07, gnorm=8.879, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1350
2022-05-10 21:57:54 - progress_bar.py[line:272] - INFO: epoch 001:    751 / 17711 loss=10.336, loss_v1=0, loss_v2=0, nll_loss=9.262, ntokens=380.8, nsentences=32, sample_size=380.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.879471, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.336, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=32.127, expert1_balance_bottom=18.397, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=613.81, wps=184.2, ups=0.48, wpb=380.8, bsz=32, num_updates=750, lr=3.52891e-07, gnorm=8.983, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1371
2022-05-10 21:58:12 - progress_bar.py[line:272] - INFO: epoch 001:    761 / 17711 loss=10.246, loss_v1=0, loss_v2=0, nll_loss=9.135, ntokens=377.9, nsentences=32, sample_size=377.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.902097, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.246, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=32.36, expert1_balance_bottom=18.483, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=562.39, wps=211.1, ups=0.56, wpb=377.9, bsz=32, num_updates=760, lr=3.57597e-07, gnorm=8.753, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1389
2022-05-10 21:58:29 - progress_bar.py[line:272] - INFO: epoch 001:    771 / 17711 loss=10.245, loss_v1=0, loss_v2=0, nll_loss=9.148, ntokens=383.6, nsentences=32, sample_size=383.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.889707, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.245, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=31.736, expert1_balance_bottom=19.113, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=567.31, wps=221.2, ups=0.58, wpb=383.6, bsz=32, num_updates=770, lr=3.62302e-07, gnorm=8.764, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1406
2022-05-10 21:58:47 - progress_bar.py[line:272] - INFO: epoch 001:    781 / 17711 loss=10.248, loss_v1=0, loss_v2=0, nll_loss=9.156, ntokens=395.6, nsentences=32, sample_size=395.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.885877, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.248, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=32.19, expert1_balance_bottom=18.877, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=570.35, wps=222.5, ups=0.56, wpb=395.6, bsz=32, num_updates=780, lr=3.67007e-07, gnorm=8.618, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1424
2022-05-10 21:59:06 - progress_bar.py[line:272] - INFO: epoch 001:    791 / 17711 loss=10.19, loss_v1=0, loss_v2=0, nll_loss=9.085, ntokens=385.1, nsentences=32, sample_size=385.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.891902, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.19, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=32.064, expert1_balance_bottom=18.864, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=542.99, wps=198.5, ups=0.52, wpb=385.1, bsz=32, num_updates=790, lr=3.71712e-07, gnorm=8.638, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1443
2022-05-10 21:59:23 - progress_bar.py[line:272] - INFO: epoch 001:    801 / 17711 loss=10.232, loss_v1=0, loss_v2=0, nll_loss=9.137, ntokens=382.8, nsentences=32, sample_size=382.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.886455, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.232, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=31.992, expert1_balance_bottom=18.918, unused_expert1_count=0.002, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=562.96, wps=221.4, ups=0.58, wpb=382.8, bsz=32, num_updates=800, lr=3.76417e-07, gnorm=8.917, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1461
2022-05-10 21:59:41 - progress_bar.py[line:272] - INFO: epoch 001:    811 / 17711 loss=10.167, loss_v1=0, loss_v2=0, nll_loss=9.049, ntokens=380.7, nsentences=32, sample_size=380.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.900515, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.167, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=31.486, expert1_balance_bottom=19.153, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=529.64, wps=218.2, ups=0.57, wpb=380.7, bsz=32, num_updates=810, lr=3.81123e-07, gnorm=8.874, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1478
2022-05-10 21:59:58 - progress_bar.py[line:272] - INFO: epoch 001:    821 / 17711 loss=10.25, loss_v1=0, loss_v2=0, nll_loss=9.14, ntokens=376.9, nsentences=32, sample_size=376.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.901735, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.25, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=31.738, expert1_balance_bottom=18.989, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=564.05, wps=215.2, ups=0.57, wpb=376.9, bsz=32, num_updates=820, lr=3.85828e-07, gnorm=8.332, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1496
2022-05-10 22:00:16 - progress_bar.py[line:272] - INFO: epoch 001:    831 / 17711 loss=10.149, loss_v1=0, loss_v2=0, nll_loss=9.038, ntokens=382, nsentences=32, sample_size=382, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.892601, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.149, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=31.821, expert1_balance_bottom=18.926, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=525.63, wps=217.5, ups=0.57, wpb=382, bsz=32, num_updates=830, lr=3.90533e-07, gnorm=8.472, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1513
2022-05-10 22:00:34 - progress_bar.py[line:272] - INFO: epoch 001:    841 / 17711 loss=10.178, loss_v1=0, loss_v2=0, nll_loss=9.072, ntokens=379.7, nsentences=32, sample_size=379.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.890065, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.178, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=31.547, expert1_balance_bottom=19.159, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=538.38, wps=211.2, ups=0.56, wpb=379.7, bsz=32, num_updates=840, lr=3.95238e-07, gnorm=8.635, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1531
2022-05-10 22:00:51 - progress_bar.py[line:272] - INFO: epoch 001:    851 / 17711 loss=10.206, loss_v1=0, loss_v2=0, nll_loss=9.104, ntokens=390.2, nsentences=32, sample_size=390.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.889045, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.206, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.701, expert1_balance_bottom=19.032, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=550.32, wps=223.5, ups=0.57, wpb=390.2, bsz=32, num_updates=850, lr=3.99944e-07, gnorm=9.133, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1549
2022-05-10 22:01:09 - progress_bar.py[line:272] - INFO: epoch 001:    861 / 17711 loss=10.099, loss_v1=0, loss_v2=0, nll_loss=8.989, ntokens=373.3, nsentences=32, sample_size=373.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.886067, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.099, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=31.385, expert1_balance_bottom=19.145, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=508.14, wps=211.8, ups=0.57, wpb=373.3, bsz=32, num_updates=860, lr=4.04649e-07, gnorm=8.421, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1566
2022-05-10 22:01:26 - progress_bar.py[line:272] - INFO: epoch 001:    871 / 17711 loss=10.145, loss_v1=0, loss_v2=0, nll_loss=9.031, ntokens=379, nsentences=32, sample_size=379, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.893845, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.145, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=31.732, expert1_balance_bottom=19.146, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=523.28, wps=218.1, ups=0.58, wpb=379, bsz=32, num_updates=870, lr=4.09354e-07, gnorm=8.796, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1584
2022-05-10 22:01:44 - progress_bar.py[line:272] - INFO: epoch 001:    881 / 17711 loss=10.156, loss_v1=0, loss_v2=0, nll_loss=9.04, ntokens=388.9, nsentences=32, sample_size=388.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.896396, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.156, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.821, expert1_balance_bottom=19.226, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=526.48, wps=215.8, ups=0.55, wpb=388.9, bsz=32, num_updates=880, lr=4.14059e-07, gnorm=8.97, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1602
2022-05-10 22:02:02 - progress_bar.py[line:272] - INFO: epoch 001:    891 / 17711 loss=10.092, loss_v1=0, loss_v2=0, nll_loss=8.971, ntokens=376.7, nsentences=32, sample_size=376.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.895508, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.092, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=31.735, expert1_balance_bottom=19.212, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=501.71, wps=213.4, ups=0.57, wpb=376.7, bsz=32, num_updates=890, lr=4.18764e-07, gnorm=8.062, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1619
2022-05-10 22:02:20 - progress_bar.py[line:272] - INFO: epoch 001:    901 / 17711 loss=10.078, loss_v1=0, loss_v2=0, nll_loss=8.951, ntokens=375.2, nsentences=32, sample_size=375.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.898768, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.078, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.502, expert1_balance_bottom=19.163, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=494.93, wps=213.2, ups=0.57, wpb=375.2, bsz=32, num_updates=900, lr=4.2347e-07, gnorm=8.74, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1637
2022-05-10 22:02:38 - progress_bar.py[line:272] - INFO: epoch 001:    911 / 17711 loss=10.057, loss_v1=0, loss_v2=0, nll_loss=8.937, ntokens=388.8, nsentences=32, sample_size=388.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.889735, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.057, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.781, expert1_balance_bottom=19.219, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=490.2, wps=216.8, ups=0.56, wpb=388.8, bsz=32, num_updates=910, lr=4.28175e-07, gnorm=8.594, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1655
2022-05-10 22:02:55 - progress_bar.py[line:272] - INFO: epoch 001:    921 / 17711 loss=10.16, loss_v1=0, loss_v2=0, nll_loss=9.055, ntokens=390.3, nsentences=32, sample_size=390.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.887465, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.16, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.889, expert1_balance_bottom=18.946, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=531.76, wps=223.2, ups=0.57, wpb=390.3, bsz=32, num_updates=920, lr=4.3288e-07, gnorm=8.271, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1672
2022-05-10 22:03:13 - progress_bar.py[line:272] - INFO: epoch 001:    931 / 17711 loss=10.082, loss_v1=0, loss_v2=0, nll_loss=8.972, ntokens=381.3, nsentences=32, sample_size=381.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.884461, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.082, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.47, expert1_balance_bottom=19.343, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=502.04, wps=219, ups=0.57, wpb=381.3, bsz=32, num_updates=930, lr=4.37585e-07, gnorm=8.219, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1690
2022-05-10 22:03:30 - progress_bar.py[line:272] - INFO: epoch 001:    941 / 17711 loss=10.123, loss_v1=0, loss_v2=0, nll_loss=9.002, ntokens=383.1, nsentences=32, sample_size=383.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.897763, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.123, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.922, expert1_balance_bottom=19.005, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=512.81, wps=218.6, ups=0.57, wpb=383.1, bsz=32, num_updates=940, lr=4.42291e-07, gnorm=7.975, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1707
2022-05-10 22:03:48 - progress_bar.py[line:272] - INFO: epoch 001:    951 / 17711 loss=10.069, loss_v1=0, loss_v2=0, nll_loss=8.945, ntokens=387.9, nsentences=32, sample_size=387.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.895291, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.069, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.859, expert1_balance_bottom=18.889, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=492.99, wps=212.9, ups=0.55, wpb=387.9, bsz=32, num_updates=950, lr=4.46996e-07, gnorm=8.253, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1725
2022-05-10 22:04:06 - progress_bar.py[line:272] - INFO: epoch 001:    961 / 17711 loss=10.14, loss_v1=0, loss_v2=0, nll_loss=9.027, ntokens=377.1, nsentences=32, sample_size=377.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.892826, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.14, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.354, expert1_balance_bottom=19.432, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=521.7, wps=213.2, ups=0.57, wpb=377.1, bsz=32, num_updates=960, lr=4.51701e-07, gnorm=8.266, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1743
2022-05-10 22:04:24 - progress_bar.py[line:272] - INFO: epoch 001:    971 / 17711 loss=10.035, loss_v1=0, loss_v2=0, nll_loss=8.907, ntokens=381.7, nsentences=32, sample_size=381.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.895754, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.035, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.523, expert1_balance_bottom=19.178, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=479.99, wps=215.5, ups=0.56, wpb=381.7, bsz=32, num_updates=970, lr=4.56406e-07, gnorm=8.154, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1761
2022-05-10 22:04:41 - progress_bar.py[line:272] - INFO: epoch 001:    981 / 17711 loss=10.169, loss_v1=0, loss_v2=0, nll_loss=9.062, ntokens=379.2, nsentences=32, sample_size=379.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.889936, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.169, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.344, expert1_balance_bottom=19.335, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=534.41, wps=214.5, ups=0.57, wpb=379.2, bsz=32, num_updates=980, lr=4.61111e-07, gnorm=8.365, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1779
2022-05-10 22:04:59 - progress_bar.py[line:272] - INFO: epoch 001:    991 / 17711 loss=10.19, loss_v1=0, loss_v2=0, nll_loss=9.095, ntokens=398.2, nsentences=32, sample_size=398.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.881334, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.19, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.34, expert1_balance_bottom=19.327, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=546.86, wps=227.1, ups=0.57, wpb=398.2, bsz=32, num_updates=990, lr=4.65817e-07, gnorm=7.825, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1796
2022-05-10 22:05:16 - progress_bar.py[line:272] - INFO: epoch 001:   1001 / 17711 loss=10.07, loss_v1=0, loss_v2=0, nll_loss=8.952, ntokens=388, nsentences=32, sample_size=388, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.889937, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.07, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.735, expert1_balance_bottom=19.212, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=495.33, wps=220.5, ups=0.57, wpb=388, bsz=32, num_updates=1000, lr=4.70522e-07, gnorm=7.857, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1814
2022-05-10 22:05:34 - progress_bar.py[line:272] - INFO: epoch 001:   1011 / 17711 loss=10.013, loss_v1=0, loss_v2=0, nll_loss=8.884, ntokens=383.8, nsentences=32, sample_size=383.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.893894, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.013, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=32.009, expert1_balance_bottom=19.1, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=472.4, wps=221.1, ups=0.58, wpb=383.8, bsz=32, num_updates=1010, lr=4.75227e-07, gnorm=8.049, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1831
2022-05-10 22:05:51 - progress_bar.py[line:272] - INFO: epoch 001:   1021 / 17711 loss=10.071, loss_v1=0, loss_v2=0, nll_loss=8.949, ntokens=388.5, nsentences=32, sample_size=388.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.893433, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.071, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=32.03, expert1_balance_bottom=19.193, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=494.2, wps=223, ups=0.57, wpb=388.5, bsz=32, num_updates=1020, lr=4.79932e-07, gnorm=8.382, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1848
2022-05-10 22:06:09 - progress_bar.py[line:272] - INFO: epoch 001:   1031 / 17711 loss=10.057, loss_v1=0, loss_v2=0, nll_loss=8.94, ntokens=385.6, nsentences=32, sample_size=385.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.887982, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.057, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.915, expert1_balance_bottom=19.021, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=491.16, wps=214, ups=0.55, wpb=385.6, bsz=32, num_updates=1030, lr=4.84637e-07, gnorm=8.165, loss_scale=256, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1866
2022-05-10 22:06:28 - progress_bar.py[line:272] - INFO: epoch 001:   1041 / 17711 loss=10.036, loss_v1=0, loss_v2=0, nll_loss=8.904, ntokens=376.1, nsentences=32, sample_size=376.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.898003, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.036, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.258, expert1_balance_bottom=19.27, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=479.2, wps=204.3, ups=0.54, wpb=376.1, bsz=32, num_updates=1040, lr=4.89343e-07, gnorm=8.027, loss_scale=256, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1885
2022-05-10 22:06:46 - progress_bar.py[line:272] - INFO: epoch 001:   1051 / 17711 loss=10.029, loss_v1=0, loss_v2=0, nll_loss=8.903, ntokens=372.6, nsentences=32, sample_size=372.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.892832, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.029, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.382, expert1_balance_bottom=19.417, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=478.62, wps=208.4, ups=0.56, wpb=372.6, bsz=32, num_updates=1050, lr=4.94048e-07, gnorm=7.675, loss_scale=256, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1903
2022-05-10 22:07:03 - progress_bar.py[line:272] - INFO: epoch 001:   1061 / 17711 loss=9.951, loss_v1=0, loss_v2=0, nll_loss=8.825, ntokens=376.7, nsentences=32, sample_size=376.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.8854, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.951, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.757, expert1_balance_bottom=19.128, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=453.49, wps=216.3, ups=0.57, wpb=376.7, bsz=32, num_updates=1060, lr=4.98753e-07, gnorm=8.017, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1920
2022-05-10 22:07:21 - progress_bar.py[line:272] - INFO: epoch 001:   1071 / 17711 loss=10.025, loss_v1=0, loss_v2=0, nll_loss=8.887, ntokens=378.9, nsentences=32, sample_size=378.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.903743, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.025, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.483, expert1_balance_bottom=19.198, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=473.37, wps=211, ups=0.56, wpb=378.9, bsz=32, num_updates=1070, lr=5.03458e-07, gnorm=8.425, loss_scale=256, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1938
2022-05-10 22:07:39 - progress_bar.py[line:272] - INFO: epoch 001:   1081 / 17711 loss=10.025, loss_v1=0, loss_v2=0, nll_loss=8.888, ntokens=379.7, nsentences=32, sample_size=379.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.901497, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.025, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.411, expert1_balance_bottom=19.489, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=473.87, wps=212.7, ups=0.56, wpb=379.7, bsz=32, num_updates=1080, lr=5.08164e-07, gnorm=7.912, loss_scale=256, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1956
2022-05-10 22:07:57 - progress_bar.py[line:272] - INFO: epoch 001:   1091 / 17711 loss=9.952, loss_v1=0, loss_v2=0, nll_loss=8.812, ntokens=383.8, nsentences=32, sample_size=383.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.896764, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.952, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.94, expert1_balance_bottom=19.152, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=449.58, wps=216.6, ups=0.56, wpb=383.8, bsz=32, num_updates=1090, lr=5.12869e-07, gnorm=7.547, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1974
2022-05-10 22:08:14 - progress_bar.py[line:272] - INFO: epoch 001:   1101 / 17711 loss=10.023, loss_v1=0, loss_v2=0, nll_loss=8.904, ntokens=382, nsentences=32, sample_size=382, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.885543, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.023, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.617, expert1_balance_bottom=19.233, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=479.07, wps=221.1, ups=0.58, wpb=382, bsz=32, num_updates=1100, lr=5.17574e-07, gnorm=7.991, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=1991
2022-05-10 22:08:31 - progress_bar.py[line:272] - INFO: epoch 001:   1111 / 17711 loss=10.059, loss_v1=0, loss_v2=0, nll_loss=8.946, ntokens=384.3, nsentences=32, sample_size=384.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.884584, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.059, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.584, expert1_balance_bottom=19.58, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=493.04, wps=220.2, ups=0.57, wpb=384.3, bsz=32, num_updates=1110, lr=5.22279e-07, gnorm=7.712, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2008
2022-05-10 22:08:49 - progress_bar.py[line:272] - INFO: epoch 001:   1121 / 17711 loss=9.981, loss_v1=0, loss_v2=0, nll_loss=8.858, ntokens=380.5, nsentences=32, sample_size=380.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.885672, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.981, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.571, expert1_balance_bottom=19.227, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=463.85, wps=214.6, ups=0.56, wpb=380.5, bsz=32, num_updates=1120, lr=5.26984e-07, gnorm=7.846, loss_scale=256, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2026
2022-05-10 22:09:07 - trainer.py[line:1047] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2022-05-10 22:09:08 - progress_bar.py[line:272] - INFO: epoch 001:   1132 / 17711 loss=9.945, loss_v1=0, loss_v2=0, nll_loss=8.796, ntokens=378.4, nsentences=32, sample_size=378.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.904824, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.945, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.481, expert1_balance_bottom=19.128, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=444.44, wps=196.3, ups=0.52, wpb=378.4, bsz=32, num_updates=1130, lr=5.3169e-07, gnorm=8.011, loss_scale=128, train_wall=18, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2045
2022-05-10 22:09:26 - progress_bar.py[line:272] - INFO: epoch 001:   1142 / 17711 loss=10.046, loss_v1=0, loss_v2=0, nll_loss=8.918, ntokens=392, nsentences=32, sample_size=392, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.896419, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.046, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.293, expert1_balance_bottom=19.349, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=483.74, wps=226, ups=0.58, wpb=392, bsz=32, num_updates=1140, lr=5.36395e-07, gnorm=8.039, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2063
2022-05-10 22:09:43 - progress_bar.py[line:272] - INFO: epoch 001:   1152 / 17711 loss=9.971, loss_v1=0, loss_v2=0, nll_loss=8.843, ntokens=385.8, nsentences=32, sample_size=385.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.888984, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.971, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.586, expert1_balance_bottom=19.353, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=459.1, wps=217.8, ups=0.56, wpb=385.8, bsz=32, num_updates=1150, lr=5.411e-07, gnorm=7.682, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2080
2022-05-10 22:10:01 - progress_bar.py[line:272] - INFO: epoch 001:   1162 / 17711 loss=9.953, loss_v1=0, loss_v2=0, nll_loss=8.837, ntokens=393.7, nsentences=32, sample_size=393.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.87556, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.953, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.482, expert1_balance_bottom=19.389, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=457.32, wps=225.7, ups=0.57, wpb=393.7, bsz=32, num_updates=1160, lr=5.45805e-07, gnorm=7.881, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2098
2022-05-10 22:10:18 - progress_bar.py[line:272] - INFO: epoch 001:   1172 / 17711 loss=9.912, loss_v1=0, loss_v2=0, nll_loss=8.773, ntokens=381.7, nsentences=32, sample_size=381.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.892336, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.912, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.391, expert1_balance_bottom=19.112, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=437.49, wps=219.1, ups=0.57, wpb=381.7, bsz=32, num_updates=1170, lr=5.50511e-07, gnorm=7.742, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2115
2022-05-10 22:10:36 - progress_bar.py[line:272] - INFO: epoch 001:   1182 / 17711 loss=9.988, loss_v1=0, loss_v2=0, nll_loss=8.864, ntokens=387.6, nsentences=32, sample_size=387.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.886432, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.988, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.432, expert1_balance_bottom=19.323, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=465.9, wps=219.1, ups=0.57, wpb=387.6, bsz=32, num_updates=1180, lr=5.55216e-07, gnorm=8.188, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2133
2022-05-10 22:10:54 - progress_bar.py[line:272] - INFO: epoch 001:   1192 / 17711 loss=9.968, loss_v1=0, loss_v2=0, nll_loss=8.833, ntokens=387.6, nsentences=32, sample_size=387.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.8946, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.968, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.521, expert1_balance_bottom=19.12, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=455.97, wps=217.2, ups=0.56, wpb=387.6, bsz=32, num_updates=1190, lr=5.59921e-07, gnorm=8.071, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2151
2022-05-10 22:11:11 - progress_bar.py[line:272] - INFO: epoch 001:   1202 / 17711 loss=9.962, loss_v1=0, loss_v2=0, nll_loss=8.832, ntokens=387.1, nsentences=32, sample_size=387.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.889719, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.962, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.803, expert1_balance_bottom=19.16, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=455.61, wps=221.5, ups=0.57, wpb=387.1, bsz=32, num_updates=1200, lr=5.64626e-07, gnorm=7.94, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2168
2022-05-10 22:11:29 - progress_bar.py[line:272] - INFO: epoch 001:   1212 / 17711 loss=10.022, loss_v1=0, loss_v2=0, nll_loss=8.901, ntokens=381.5, nsentences=32, sample_size=381.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.887149, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.022, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.235, expert1_balance_bottom=19.328, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=478.03, wps=217.6, ups=0.57, wpb=381.5, bsz=32, num_updates=1210, lr=5.69331e-07, gnorm=7.783, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2186
2022-05-10 22:11:46 - progress_bar.py[line:272] - INFO: epoch 001:   1222 / 17711 loss=9.923, loss_v1=0, loss_v2=0, nll_loss=8.798, ntokens=384.5, nsentences=32, sample_size=384.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.881737, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.923, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.621, expert1_balance_bottom=19.165, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=444.96, wps=216.9, ups=0.56, wpb=384.5, bsz=32, num_updates=1220, lr=5.74037e-07, gnorm=7.818, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2204
2022-05-10 22:12:04 - progress_bar.py[line:272] - INFO: epoch 001:   1232 / 17711 loss=9.99, loss_v1=0, loss_v2=0, nll_loss=8.839, ntokens=371.1, nsentences=32, sample_size=371.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.911197, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.99, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.297, expert1_balance_bottom=19.39, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=458.02, wps=212.6, ups=0.57, wpb=371.1, bsz=32, num_updates=1230, lr=5.78742e-07, gnorm=7.903, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2221
2022-05-10 22:12:21 - progress_bar.py[line:272] - INFO: epoch 001:   1242 / 17711 loss=9.962, loss_v1=0, loss_v2=0, nll_loss=8.833, ntokens=382.8, nsentences=32, sample_size=382.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.889431, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.962, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.774, expert1_balance_bottom=19.072, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=455.9, wps=217.7, ups=0.57, wpb=382.8, bsz=32, num_updates=1240, lr=5.83447e-07, gnorm=7.891, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2239
2022-05-10 22:12:39 - progress_bar.py[line:272] - INFO: epoch 001:   1252 / 17711 loss=10.021, loss_v1=0, loss_v2=0, nll_loss=8.896, ntokens=383.5, nsentences=32, sample_size=383.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.891421, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.021, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.611, expert1_balance_bottom=19.262, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=476.35, wps=220.2, ups=0.57, wpb=383.5, bsz=32, num_updates=1250, lr=5.88152e-07, gnorm=7.918, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2256
2022-05-10 22:12:57 - progress_bar.py[line:272] - INFO: epoch 001:   1262 / 17711 loss=10.007, loss_v1=0, loss_v2=0, nll_loss=8.884, ntokens=382.6, nsentences=32, sample_size=382.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.888064, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.007, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.338, expert1_balance_bottom=19.202, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=472.53, wps=214.4, ups=0.56, wpb=382.6, bsz=32, num_updates=1260, lr=5.92857e-07, gnorm=7.535, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2274
2022-05-10 22:13:14 - progress_bar.py[line:272] - INFO: epoch 001:   1272 / 17711 loss=9.957, loss_v1=0, loss_v2=0, nll_loss=8.821, ntokens=400.4, nsentences=32, sample_size=400.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.894041, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.957, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.516, expert1_balance_bottom=19.398, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=452.36, wps=226.1, ups=0.56, wpb=400.4, bsz=32, num_updates=1270, lr=5.97563e-07, gnorm=7.514, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2292
2022-05-10 22:13:32 - progress_bar.py[line:272] - INFO: epoch 001:   1282 / 17711 loss=9.981, loss_v1=0, loss_v2=0, nll_loss=8.851, ntokens=378.6, nsentences=32, sample_size=378.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.890859, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.981, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.666, expert1_balance_bottom=19.39, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=461.79, wps=210.5, ups=0.56, wpb=378.6, bsz=32, num_updates=1280, lr=6.02268e-07, gnorm=7.853, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2310
2022-05-10 22:13:50 - progress_bar.py[line:272] - INFO: epoch 001:   1292 / 17711 loss=9.928, loss_v1=0, loss_v2=0, nll_loss=8.788, ntokens=383.2, nsentences=32, sample_size=383.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.895381, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.928, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.311, expert1_balance_bottom=19.218, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=441.98, wps=218.1, ups=0.57, wpb=383.2, bsz=32, num_updates=1290, lr=6.06973e-07, gnorm=7.474, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2327
2022-05-10 22:14:07 - progress_bar.py[line:272] - INFO: epoch 001:   1302 / 17711 loss=9.844, loss_v1=0, loss_v2=0, nll_loss=8.695, ntokens=382.6, nsentences=32, sample_size=382.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.894339, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.844, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.541, expert1_balance_bottom=19.499, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=414.51, wps=223.7, ups=0.58, wpb=382.6, bsz=32, num_updates=1300, lr=6.11678e-07, gnorm=7.506, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2344
2022-05-10 22:14:25 - progress_bar.py[line:272] - INFO: epoch 001:   1312 / 17711 loss=9.916, loss_v1=0, loss_v2=0, nll_loss=8.771, ntokens=376.3, nsentences=32, sample_size=376.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.898676, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.916, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.49, expert1_balance_bottom=19.343, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=436.74, wps=209.5, ups=0.56, wpb=376.3, bsz=32, num_updates=1310, lr=6.16384e-07, gnorm=7.13, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2362
2022-05-10 22:14:43 - progress_bar.py[line:272] - INFO: epoch 001:   1322 / 17711 loss=9.896, loss_v1=0, loss_v2=0, nll_loss=8.762, ntokens=382.7, nsentences=32, sample_size=382.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.886404, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.896, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.557, expert1_balance_bottom=19.213, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=434.03, wps=213.3, ups=0.56, wpb=382.7, bsz=32, num_updates=1320, lr=6.21089e-07, gnorm=7.233, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2380
2022-05-10 22:15:01 - progress_bar.py[line:272] - INFO: epoch 001:   1332 / 17711 loss=9.961, loss_v1=0, loss_v2=0, nll_loss=8.817, ntokens=386.3, nsentences=32, sample_size=386.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.901689, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.961, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.412, expert1_balance_bottom=19.331, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=451.01, wps=215.6, ups=0.56, wpb=386.3, bsz=32, num_updates=1330, lr=6.25794e-07, gnorm=7.45, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2398
2022-05-10 22:15:19 - progress_bar.py[line:272] - INFO: epoch 001:   1342 / 17711 loss=9.945, loss_v1=0, loss_v2=0, nll_loss=8.824, ntokens=382.9, nsentences=32, sample_size=382.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.879389, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.945, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.421, expert1_balance_bottom=19.389, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=453.21, wps=217.5, ups=0.57, wpb=382.9, bsz=32, num_updates=1340, lr=6.30499e-07, gnorm=7.697, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2416
2022-05-10 22:15:36 - progress_bar.py[line:272] - INFO: epoch 001:   1352 / 17711 loss=9.905, loss_v1=0, loss_v2=0, nll_loss=8.774, ntokens=385.6, nsentences=32, sample_size=385.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.884347, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.905, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.213, expert1_balance_bottom=19.471, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=437.89, wps=222.8, ups=0.58, wpb=385.6, bsz=32, num_updates=1350, lr=6.35204e-07, gnorm=7.443, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2433
2022-05-10 22:15:53 - progress_bar.py[line:272] - INFO: epoch 001:   1362 / 17711 loss=9.918, loss_v1=0, loss_v2=0, nll_loss=8.773, ntokens=383.4, nsentences=32, sample_size=383.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.897948, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.918, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.285, expert1_balance_bottom=19.295, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=437.48, wps=218.3, ups=0.57, wpb=383.4, bsz=32, num_updates=1360, lr=6.3991e-07, gnorm=7.379, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2451
2022-05-10 22:16:11 - progress_bar.py[line:272] - INFO: epoch 001:   1372 / 17711 loss=10.023, loss_v1=0, loss_v2=0, nll_loss=8.901, ntokens=385.8, nsentences=32, sample_size=385.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.888382, inner_loss_v1=0, inner_loss_v2=0, inner_loss=10.023, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.902, expert1_balance_bottom=19.257, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=477.88, wps=218.6, ups=0.57, wpb=385.8, bsz=32, num_updates=1370, lr=6.44615e-07, gnorm=7.251, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2468
2022-05-10 22:16:29 - progress_bar.py[line:272] - INFO: epoch 001:   1382 / 17711 loss=9.904, loss_v1=0, loss_v2=0, nll_loss=8.775, ntokens=382, nsentences=32, sample_size=382, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.883411, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.904, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=32.017, expert1_balance_bottom=19.236, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=437.94, wps=216.7, ups=0.57, wpb=382, bsz=32, num_updates=1380, lr=6.4932e-07, gnorm=7.418, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2486
2022-05-10 22:16:46 - progress_bar.py[line:272] - INFO: epoch 001:   1392 / 17711 loss=9.902, loss_v1=0, loss_v2=0, nll_loss=8.766, ntokens=387.9, nsentences=32, sample_size=387.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.888383, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.902, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.475, expert1_balance_bottom=19.333, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=435.47, wps=218.6, ups=0.56, wpb=387.9, bsz=32, num_updates=1390, lr=6.54025e-07, gnorm=7.252, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2504
2022-05-10 22:17:04 - progress_bar.py[line:272] - INFO: epoch 001:   1402 / 17711 loss=9.911, loss_v1=0, loss_v2=0, nll_loss=8.763, ntokens=375.6, nsentences=32, sample_size=375.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.900201, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.911, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.202, expert1_balance_bottom=19.425, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=434.34, wps=210.2, ups=0.56, wpb=375.6, bsz=32, num_updates=1400, lr=6.58731e-07, gnorm=6.925, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2521
2022-05-10 22:17:22 - progress_bar.py[line:272] - INFO: epoch 001:   1412 / 17711 loss=9.822, loss_v1=0, loss_v2=0, nll_loss=8.674, ntokens=382.8, nsentences=32, sample_size=382.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.891722, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.822, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.791, expert1_balance_bottom=19.192, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=408.43, wps=214.4, ups=0.56, wpb=382.8, bsz=32, num_updates=1410, lr=6.63436e-07, gnorm=7.449, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2539
2022-05-10 22:17:40 - progress_bar.py[line:272] - INFO: epoch 001:   1422 / 17711 loss=9.916, loss_v1=0, loss_v2=0, nll_loss=8.778, ntokens=386.4, nsentences=32, sample_size=386.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.891873, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.916, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.662, expert1_balance_bottom=19.048, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=439.06, wps=212.8, ups=0.55, wpb=386.4, bsz=32, num_updates=1420, lr=6.68141e-07, gnorm=7.584, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2557
2022-05-10 22:17:58 - progress_bar.py[line:272] - INFO: epoch 001:   1432 / 17711 loss=9.891, loss_v1=0, loss_v2=0, nll_loss=8.746, ntokens=386.6, nsentences=32, sample_size=386.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.89598, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.891, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.449, expert1_balance_bottom=19.255, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=429.2, wps=214.6, ups=0.56, wpb=386.6, bsz=32, num_updates=1430, lr=6.72846e-07, gnorm=7.157, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2576
2022-05-10 22:18:16 - progress_bar.py[line:272] - INFO: epoch 001:   1442 / 17711 loss=9.884, loss_v1=0, loss_v2=0, nll_loss=8.726, ntokens=384.6, nsentences=32, sample_size=384.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.906086, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.884, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.308, expert1_balance_bottom=19.545, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=423.53, wps=219.7, ups=0.57, wpb=384.6, bsz=32, num_updates=1440, lr=6.77551e-07, gnorm=7.419, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2593
2022-05-10 22:18:33 - progress_bar.py[line:272] - INFO: epoch 001:   1452 / 17711 loss=9.875, loss_v1=0, loss_v2=0, nll_loss=8.735, ntokens=383.2, nsentences=32, sample_size=383.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.889599, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.875, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.168, expert1_balance_bottom=19.53, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=425.97, wps=219.5, ups=0.57, wpb=383.2, bsz=32, num_updates=1450, lr=6.82257e-07, gnorm=7.022, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2610
2022-05-10 22:18:51 - progress_bar.py[line:272] - INFO: epoch 001:   1462 / 17711 loss=9.943, loss_v1=0, loss_v2=0, nll_loss=8.822, ntokens=388.8, nsentences=32, sample_size=388.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.878766, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.943, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.433, expert1_balance_bottom=19.208, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=452.71, wps=222.9, ups=0.57, wpb=388.8, bsz=32, num_updates=1460, lr=6.86962e-07, gnorm=7.021, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2628
2022-05-10 22:19:09 - progress_bar.py[line:272] - INFO: epoch 001:   1472 / 17711 loss=9.884, loss_v1=0, loss_v2=0, nll_loss=8.749, ntokens=380.5, nsentences=32, sample_size=380.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.886203, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.884, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.094, expert1_balance_bottom=19.481, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=430.18, wps=213.3, ups=0.56, wpb=380.5, bsz=32, num_updates=1470, lr=6.91667e-07, gnorm=7.308, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2646
2022-05-10 22:19:27 - progress_bar.py[line:272] - INFO: epoch 001:   1482 / 17711 loss=9.884, loss_v1=0, loss_v2=0, nll_loss=8.741, ntokens=385.1, nsentences=32, sample_size=385.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.893765, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.884, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.856, expert1_balance_bottom=19.167, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=427.75, wps=213.4, ups=0.55, wpb=385.1, bsz=32, num_updates=1480, lr=6.96372e-07, gnorm=7.32, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2664
2022-05-10 22:19:47 - progress_bar.py[line:272] - INFO: epoch 001:   1492 / 17711 loss=9.864, loss_v1=0, loss_v2=0, nll_loss=8.724, ntokens=376, nsentences=32, sample_size=376, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.888365, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.864, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.3, expert1_balance_bottom=19.552, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=422.96, wps=188.9, ups=0.5, wpb=376, bsz=32, num_updates=1490, lr=7.01077e-07, gnorm=7.137, loss_scale=128, train_wall=18, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2684
2022-05-10 22:20:04 - progress_bar.py[line:272] - INFO: epoch 001:   1502 / 17711 loss=9.842, loss_v1=0, loss_v2=0, nll_loss=8.681, ntokens=381, nsentences=32, sample_size=381, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.904661, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.842, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=30.915, expert1_balance_bottom=19.577, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=410.43, wps=215.7, ups=0.57, wpb=381, bsz=32, num_updates=1500, lr=7.05783e-07, gnorm=7.352, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2701
2022-05-10 22:20:22 - progress_bar.py[line:272] - INFO: epoch 001:   1512 / 17711 loss=9.828, loss_v1=0, loss_v2=0, nll_loss=8.691, ntokens=383.5, nsentences=32, sample_size=383.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.882062, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.828, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.209, expert1_balance_bottom=19.23, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=413.23, wps=221, ups=0.58, wpb=383.5, bsz=32, num_updates=1510, lr=7.10488e-07, gnorm=7.233, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2719
2022-05-10 22:20:39 - progress_bar.py[line:272] - INFO: epoch 001:   1522 / 17711 loss=9.924, loss_v1=0, loss_v2=0, nll_loss=8.788, ntokens=385.1, nsentences=32, sample_size=385.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.890423, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.924, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.487, expert1_balance_bottom=19.301, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=442.07, wps=223.7, ups=0.58, wpb=385.1, bsz=32, num_updates=1520, lr=7.15193e-07, gnorm=6.957, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2736
2022-05-10 22:20:56 - progress_bar.py[line:272] - INFO: epoch 001:   1532 / 17711 loss=9.933, loss_v1=0, loss_v2=0, nll_loss=8.796, ntokens=386.2, nsentences=32, sample_size=386.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.89253, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.933, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.157, expert1_balance_bottom=19.665, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=444.53, wps=222, ups=0.57, wpb=386.2, bsz=32, num_updates=1530, lr=7.19898e-07, gnorm=6.963, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2753
2022-05-10 22:21:14 - progress_bar.py[line:272] - INFO: epoch 001:   1542 / 17711 loss=9.858, loss_v1=0, loss_v2=0, nll_loss=8.721, ntokens=381.6, nsentences=32, sample_size=381.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.884655, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.858, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.366, expert1_balance_bottom=19.383, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=421.99, wps=215.7, ups=0.57, wpb=381.6, bsz=32, num_updates=1540, lr=7.24604e-07, gnorm=7.106, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2771
2022-05-10 22:21:31 - progress_bar.py[line:272] - INFO: epoch 001:   1552 / 17711 loss=9.838, loss_v1=0, loss_v2=0, nll_loss=8.687, ntokens=376.8, nsentences=32, sample_size=376.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.895958, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.838, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.401, expert1_balance_bottom=19.454, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=412.12, wps=217.4, ups=0.58, wpb=376.8, bsz=32, num_updates=1550, lr=7.29309e-07, gnorm=7.153, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2788
2022-05-10 22:21:48 - progress_bar.py[line:272] - INFO: epoch 001:   1562 / 17711 loss=9.846, loss_v1=0, loss_v2=0, nll_loss=8.712, ntokens=389.4, nsentences=32, sample_size=389.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.88102, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.846, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.356, expert1_balance_top=31.115, expert1_balance_bottom=19.589, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=419.24, wps=226.5, ups=0.58, wpb=389.4, bsz=32, num_updates=1560, lr=7.34014e-07, gnorm=7.187, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2806
2022-05-10 22:22:06 - progress_bar.py[line:272] - INFO: epoch 001:   1572 / 17711 loss=9.84, loss_v1=0, loss_v2=0, nll_loss=8.705, ntokens=377.2, nsentences=32, sample_size=377.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.881669, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.84, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.439, expert1_balance_bottom=19.597, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=417.17, wps=213.8, ups=0.57, wpb=377.2, bsz=32, num_updates=1570, lr=7.38719e-07, gnorm=7.294, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2823
2022-05-10 22:22:23 - progress_bar.py[line:272] - INFO: epoch 001:   1582 / 17711 loss=9.953, loss_v1=0, loss_v2=0, nll_loss=8.83, ntokens=387.3, nsentences=32, sample_size=387.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.882647, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.953, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.164, expert1_balance_bottom=19.493, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=454.93, wps=221.6, ups=0.57, wpb=387.3, bsz=32, num_updates=1580, lr=7.43424e-07, gnorm=6.631, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2841
2022-05-10 22:22:41 - progress_bar.py[line:272] - INFO: epoch 001:   1592 / 17711 loss=9.895, loss_v1=0, loss_v2=0, nll_loss=8.753, ntokens=380.3, nsentences=32, sample_size=380.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.893013, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.895, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.734, expert1_balance_bottom=19.392, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=431.57, wps=216.3, ups=0.57, wpb=380.3, bsz=32, num_updates=1590, lr=7.4813e-07, gnorm=6.754, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2858
2022-05-10 22:22:59 - progress_bar.py[line:272] - INFO: epoch 001:   1602 / 17711 loss=9.873, loss_v1=0, loss_v2=0, nll_loss=8.736, ntokens=387.2, nsentences=32, sample_size=387.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.886863, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.873, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.302, expert1_balance_bottom=19.633, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=426.33, wps=218.4, ups=0.56, wpb=387.2, bsz=32, num_updates=1600, lr=7.52835e-07, gnorm=7.115, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2876
2022-05-10 22:23:16 - progress_bar.py[line:272] - INFO: epoch 001:   1612 / 17711 loss=9.872, loss_v1=0, loss_v2=0, nll_loss=8.712, ntokens=377.8, nsentences=32, sample_size=377.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.906768, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.872, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.137, expert1_balance_bottom=19.554, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=419.38, wps=218.2, ups=0.58, wpb=377.8, bsz=32, num_updates=1610, lr=7.5754e-07, gnorm=7.065, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2893
2022-05-10 22:23:33 - progress_bar.py[line:272] - INFO: epoch 001:   1622 / 17711 loss=9.793, loss_v1=0, loss_v2=0, nll_loss=8.645, ntokens=387.6, nsentences=32, sample_size=387.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.887718, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.793, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.115, expert1_balance_bottom=19.544, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=400.39, wps=223.1, ups=0.58, wpb=387.6, bsz=32, num_updates=1620, lr=7.62245e-07, gnorm=6.908, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2911
2022-05-10 22:23:51 - progress_bar.py[line:272] - INFO: epoch 001:   1632 / 17711 loss=9.805, loss_v1=0, loss_v2=0, nll_loss=8.664, ntokens=380.4, nsentences=32, sample_size=380.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.882396, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.805, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.508, expert1_balance_bottom=19.442, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=405.76, wps=215.8, ups=0.57, wpb=380.4, bsz=32, num_updates=1630, lr=7.66951e-07, gnorm=7.153, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2928
2022-05-10 22:24:09 - progress_bar.py[line:272] - INFO: epoch 001:   1642 / 17711 loss=9.854, loss_v1=0, loss_v2=0, nll_loss=8.718, ntokens=377.9, nsentences=32, sample_size=377.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.883013, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.854, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.531, expert1_balance_bottom=19.599, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=421.22, wps=212.3, ups=0.56, wpb=377.9, bsz=32, num_updates=1640, lr=7.71656e-07, gnorm=6.789, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2946
2022-05-10 22:24:26 - progress_bar.py[line:272] - INFO: epoch 001:   1652 / 17711 loss=9.875, loss_v1=0, loss_v2=0, nll_loss=8.731, ntokens=378.9, nsentences=32, sample_size=378.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.89316, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.875, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.225, expert1_balance_bottom=19.655, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=424.76, wps=217.4, ups=0.57, wpb=378.9, bsz=32, num_updates=1650, lr=7.76361e-07, gnorm=7.25, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2964
2022-05-10 22:24:44 - progress_bar.py[line:272] - INFO: epoch 001:   1662 / 17711 loss=9.906, loss_v1=0, loss_v2=0, nll_loss=8.787, ntokens=386.2, nsentences=32, sample_size=386.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.873003, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.906, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.682, expert1_balance_bottom=19.195, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=441.85, wps=220.8, ups=0.57, wpb=386.2, bsz=32, num_updates=1660, lr=7.81066e-07, gnorm=7.162, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2981
2022-05-10 22:25:02 - progress_bar.py[line:272] - INFO: epoch 001:   1672 / 17711 loss=9.818, loss_v1=0, loss_v2=0, nll_loss=8.673, ntokens=384.1, nsentences=32, sample_size=384.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.887719, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.818, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.287, expert1_balance_bottom=19.43, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=408.05, wps=217.4, ups=0.57, wpb=384.1, bsz=32, num_updates=1670, lr=7.85771e-07, gnorm=6.877, loss_scale=256, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=2999
2022-05-10 22:25:19 - progress_bar.py[line:272] - INFO: epoch 001:   1682 / 17711 loss=9.851, loss_v1=0, loss_v2=0, nll_loss=8.703, ntokens=383.1, nsentences=32, sample_size=383.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.892963, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.851, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.525, expert1_balance_bottom=19.424, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=416.73, wps=216.9, ups=0.57, wpb=383.1, bsz=32, num_updates=1680, lr=7.90477e-07, gnorm=7.36, loss_scale=256, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3016
2022-05-10 22:25:38 - progress_bar.py[line:272] - INFO: epoch 001:   1692 / 17711 loss=9.81, loss_v1=0, loss_v2=0, nll_loss=8.661, ntokens=389.8, nsentences=32, sample_size=389.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.889688, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.81, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.505, expert1_balance_bottom=19.595, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=404.76, wps=209.5, ups=0.54, wpb=389.8, bsz=32, num_updates=1690, lr=7.95182e-07, gnorm=6.878, loss_scale=256, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3035
2022-05-10 22:25:55 - progress_bar.py[line:272] - INFO: epoch 001:   1702 / 17711 loss=9.794, loss_v1=0, loss_v2=0, nll_loss=8.64, ntokens=385.6, nsentences=32, sample_size=385.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.893016, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.794, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.205, expert1_balance_bottom=19.565, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=398.89, wps=218.8, ups=0.57, wpb=385.6, bsz=32, num_updates=1700, lr=7.99887e-07, gnorm=6.604, loss_scale=256, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3053
2022-05-10 22:26:14 - progress_bar.py[line:272] - INFO: epoch 001:   1712 / 17711 loss=9.847, loss_v1=0, loss_v2=0, nll_loss=8.696, ntokens=378.3, nsentences=32, sample_size=378.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.895352, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.847, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.484, expert1_balance_bottom=19.533, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=414.77, wps=203, ups=0.54, wpb=378.3, bsz=32, num_updates=1710, lr=8.04592e-07, gnorm=7.51, loss_scale=256, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3071
2022-05-10 22:26:32 - progress_bar.py[line:272] - INFO: epoch 001:   1722 / 17711 loss=9.881, loss_v1=0, loss_v2=0, nll_loss=8.747, ntokens=385.9, nsentences=32, sample_size=385.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.883708, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.881, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=30.796, expert1_balance_bottom=19.708, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=429.68, wps=220.9, ups=0.57, wpb=385.9, bsz=32, num_updates=1720, lr=8.09298e-07, gnorm=6.736, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3089
2022-05-10 22:26:49 - progress_bar.py[line:272] - INFO: epoch 001:   1732 / 17711 loss=9.801, loss_v1=0, loss_v2=0, nll_loss=8.648, ntokens=388.8, nsentences=32, sample_size=388.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.892626, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.801, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.076, expert1_balance_bottom=19.775, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=401.29, wps=223.2, ups=0.57, wpb=388.8, bsz=32, num_updates=1730, lr=8.14003e-07, gnorm=7.363, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3106
2022-05-10 22:27:06 - progress_bar.py[line:272] - INFO: epoch 001:   1742 / 17711 loss=9.831, loss_v1=0, loss_v2=0, nll_loss=8.681, ntokens=383.2, nsentences=32, sample_size=383.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.893389, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.831, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.45, expert1_balance_bottom=19.451, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=410.43, wps=222.9, ups=0.58, wpb=383.2, bsz=32, num_updates=1740, lr=8.18708e-07, gnorm=6.674, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3123
2022-05-10 22:27:23 - progress_bar.py[line:272] - INFO: epoch 001:   1752 / 17711 loss=9.771, loss_v1=0, loss_v2=0, nll_loss=8.626, ntokens=384.6, nsentences=32, sample_size=384.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.882832, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.771, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.355, expert1_balance_top=31.744, expert1_balance_bottom=19.515, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=395.15, wps=221.8, ups=0.58, wpb=384.6, bsz=32, num_updates=1750, lr=8.23413e-07, gnorm=6.299, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3141
2022-05-10 22:27:41 - progress_bar.py[line:272] - INFO: epoch 001:   1762 / 17711 loss=9.804, loss_v1=0, loss_v2=0, nll_loss=8.657, ntokens=386.7, nsentences=32, sample_size=386.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.887626, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.804, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=31.36, expert1_balance_bottom=19.489, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=403.73, wps=222.2, ups=0.57, wpb=386.7, bsz=32, num_updates=1760, lr=8.28118e-07, gnorm=6.766, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3158
2022-05-10 22:27:58 - progress_bar.py[line:272] - INFO: epoch 001:   1772 / 17711 loss=9.851, loss_v1=0, loss_v2=0, nll_loss=8.701, ntokens=372.2, nsentences=32, sample_size=372.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.894464, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.851, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=31.601, expert1_balance_bottom=19.293, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=416.2, wps=213.9, ups=0.57, wpb=372.2, bsz=32, num_updates=1770, lr=8.32824e-07, gnorm=7.001, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3175
2022-05-10 22:28:16 - progress_bar.py[line:272] - INFO: epoch 001:   1782 / 17711 loss=9.86, loss_v1=0, loss_v2=0, nll_loss=8.697, ntokens=380.9, nsentences=32, sample_size=380.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.90774, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.86, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=31.363, expert1_balance_bottom=19.35, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=415.02, wps=218.9, ups=0.57, wpb=380.9, bsz=32, num_updates=1780, lr=8.37529e-07, gnorm=7.012, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3193
2022-05-10 22:28:34 - progress_bar.py[line:272] - INFO: epoch 001:   1792 / 17711 loss=9.806, loss_v1=0, loss_v2=0, nll_loss=8.655, ntokens=380.1, nsentences=32, sample_size=380.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.890883, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.806, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=30.727, expert1_balance_bottom=19.868, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=403.19, wps=209, ups=0.55, wpb=380.1, bsz=32, num_updates=1790, lr=8.42234e-07, gnorm=6.75, loss_scale=256, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3211
2022-05-10 22:28:52 - progress_bar.py[line:272] - INFO: epoch 001:   1802 / 17711 loss=9.796, loss_v1=0, loss_v2=0, nll_loss=8.643, ntokens=389.7, nsentences=32, sample_size=389.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.892226, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.796, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=31.346, expert1_balance_bottom=19.522, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=399.84, wps=218.6, ups=0.56, wpb=389.7, bsz=32, num_updates=1800, lr=8.46939e-07, gnorm=6.833, loss_scale=256, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3229
2022-05-10 22:29:10 - progress_bar.py[line:272] - INFO: epoch 001:   1812 / 17711 loss=9.735, loss_v1=0, loss_v2=0, nll_loss=8.579, ntokens=382.9, nsentences=32, sample_size=382.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.888752, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.735, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=30.994, expert1_balance_bottom=19.784, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=382.33, wps=211.5, ups=0.55, wpb=382.9, bsz=32, num_updates=1810, lr=8.51644e-07, gnorm=7.003, loss_scale=256, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3247
2022-05-10 22:29:28 - progress_bar.py[line:272] - INFO: epoch 001:   1822 / 17711 loss=9.847, loss_v1=0, loss_v2=0, nll_loss=8.711, ntokens=390.4, nsentences=32, sample_size=390.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.881975, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.847, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.353, expert1_balance_top=31.091, expert1_balance_bottom=19.648, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=418.99, wps=216.6, ups=0.55, wpb=390.4, bsz=32, num_updates=1820, lr=8.5635e-07, gnorm=6.641, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3265
2022-05-10 22:29:45 - progress_bar.py[line:272] - INFO: epoch 001:   1832 / 17711 loss=9.743, loss_v1=0, loss_v2=0, nll_loss=8.577, ntokens=375.8, nsentences=32, sample_size=375.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.898483, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.743, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.353, expert1_balance_top=31.01, expert1_balance_bottom=19.801, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=381.83, wps=212.7, ups=0.57, wpb=375.8, bsz=32, num_updates=1830, lr=8.61055e-07, gnorm=6.746, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3283
2022-05-10 22:30:03 - progress_bar.py[line:272] - INFO: epoch 001:   1842 / 17711 loss=9.815, loss_v1=0, loss_v2=0, nll_loss=8.681, ntokens=389.6, nsentences=32, sample_size=389.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.877085, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.815, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.354, expert1_balance_top=31.236, expert1_balance_bottom=19.66, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=410.42, wps=224.2, ups=0.58, wpb=389.6, bsz=32, num_updates=1840, lr=8.6576e-07, gnorm=6.512, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3300
2022-05-10 22:30:20 - progress_bar.py[line:272] - INFO: epoch 001:   1852 / 17711 loss=9.833, loss_v1=0, loss_v2=0, nll_loss=8.687, ntokens=381.4, nsentences=32, sample_size=381.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.888857, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.833, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.353, expert1_balance_top=30.947, expert1_balance_bottom=19.667, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=412.22, wps=218.6, ups=0.57, wpb=381.4, bsz=32, num_updates=1850, lr=8.70465e-07, gnorm=6.986, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3317
2022-05-10 22:30:38 - progress_bar.py[line:272] - INFO: epoch 001:   1862 / 17711 loss=9.781, loss_v1=0, loss_v2=0, nll_loss=8.625, ntokens=388.5, nsentences=32, sample_size=388.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.893578, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.781, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.353, expert1_balance_top=31.142, expert1_balance_bottom=19.58, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=394.71, wps=224.9, ups=0.58, wpb=388.5, bsz=32, num_updates=1860, lr=8.75171e-07, gnorm=6.723, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3335
2022-05-10 22:30:54 - progress_bar.py[line:272] - INFO: epoch 001:   1872 / 17711 loss=9.92, loss_v1=0, loss_v2=0, nll_loss=8.778, ntokens=379.1, nsentences=32, sample_size=379.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.895265, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.92, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.353, expert1_balance_top=31.151, expert1_balance_bottom=19.482, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=438.88, wps=225.1, ups=0.59, wpb=379.1, bsz=32, num_updates=1870, lr=8.79876e-07, gnorm=6.584, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3352
2022-05-10 22:31:12 - progress_bar.py[line:272] - INFO: epoch 001:   1882 / 17711 loss=9.728, loss_v1=0, loss_v2=0, nll_loss=8.568, ntokens=381, nsentences=32, sample_size=381, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.892776, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.728, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.353, expert1_balance_top=31.216, expert1_balance_bottom=19.64, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=379.42, wps=218.9, ups=0.57, wpb=381, bsz=32, num_updates=1880, lr=8.84581e-07, gnorm=6.495, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3369
2022-05-10 22:31:29 - progress_bar.py[line:272] - INFO: epoch 001:   1892 / 17711 loss=9.78, loss_v1=0, loss_v2=0, nll_loss=8.635, ntokens=385.9, nsentences=32, sample_size=385.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.883611, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.78, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.353, expert1_balance_top=30.885, expert1_balance_bottom=19.737, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=397.65, wps=221.3, ups=0.57, wpb=385.9, bsz=32, num_updates=1890, lr=8.89286e-07, gnorm=6.749, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3386
2022-05-10 22:31:47 - progress_bar.py[line:272] - INFO: epoch 001:   1902 / 17711 loss=9.775, loss_v1=0, loss_v2=0, nll_loss=8.627, ntokens=390.6, nsentences=32, sample_size=390.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.885351, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.775, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.353, expert1_balance_top=31.713, expert1_balance_bottom=19.098, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=395.28, wps=217.3, ups=0.56, wpb=390.6, bsz=32, num_updates=1900, lr=8.93991e-07, gnorm=6.373, loss_scale=256, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3404
2022-05-10 22:32:05 - progress_bar.py[line:272] - INFO: epoch 001:   1912 / 17711 loss=9.738, loss_v1=0, loss_v2=0, nll_loss=8.595, ntokens=388, nsentences=32, sample_size=388, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.876163, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.738, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.353, expert1_balance_top=31.466, expert1_balance_bottom=19.307, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=386.73, wps=221, ups=0.57, wpb=388, bsz=32, num_updates=1910, lr=8.98697e-07, gnorm=6.631, loss_scale=256, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3422
2022-05-10 22:32:22 - progress_bar.py[line:272] - INFO: epoch 001:   1922 / 17711 loss=9.703, loss_v1=0, loss_v2=0, nll_loss=8.543, ntokens=376.1, nsentences=32, sample_size=376.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.888618, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.703, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.352, expert1_balance_top=30.934, expert1_balance_bottom=19.792, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=373.01, wps=215.3, ups=0.57, wpb=376.1, bsz=32, num_updates=1920, lr=9.03402e-07, gnorm=6.891, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3439
2022-05-10 22:32:40 - progress_bar.py[line:272] - INFO: epoch 001:   1932 / 17711 loss=9.805, loss_v1=0, loss_v2=0, nll_loss=8.66, ntokens=385.5, nsentences=32, sample_size=385.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.885324, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.805, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.352, expert1_balance_top=31.311, expert1_balance_bottom=19.513, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=404.37, wps=221.6, ups=0.57, wpb=385.5, bsz=32, num_updates=1930, lr=9.08107e-07, gnorm=6.704, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3457
2022-05-10 22:32:58 - progress_bar.py[line:272] - INFO: epoch 001:   1942 / 17711 loss=9.706, loss_v1=0, loss_v2=0, nll_loss=8.542, ntokens=377, nsentences=32, sample_size=377, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.892247, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.706, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.352, expert1_balance_top=30.857, expert1_balance_bottom=19.781, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=372.77, wps=208.7, ups=0.55, wpb=377, bsz=32, num_updates=1940, lr=9.12812e-07, gnorm=6.936, loss_scale=256, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3475
2022-05-10 22:33:15 - progress_bar.py[line:272] - INFO: epoch 001:   1952 / 17711 loss=9.721, loss_v1=0, loss_v2=0, nll_loss=8.562, ntokens=382.7, nsentences=32, sample_size=382.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.889269, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.721, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.351, expert1_balance_top=31.178, expert1_balance_bottom=19.509, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=377.88, wps=218.5, ups=0.57, wpb=382.7, bsz=32, num_updates=1950, lr=9.17518e-07, gnorm=6.785, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3492
2022-05-10 22:33:33 - progress_bar.py[line:272] - INFO: epoch 001:   1962 / 17711 loss=9.732, loss_v1=0, loss_v2=0, nll_loss=8.563, ntokens=376.4, nsentences=32, sample_size=376.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.899101, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.732, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.351, expert1_balance_top=30.847, expert1_balance_bottom=19.738, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=378.31, wps=214.7, ups=0.57, wpb=376.4, bsz=32, num_updates=1960, lr=9.22223e-07, gnorm=6.779, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3510
2022-05-10 22:33:51 - progress_bar.py[line:272] - INFO: epoch 001:   1972 / 17711 loss=9.694, loss_v1=0, loss_v2=0, nll_loss=8.526, ntokens=380.2, nsentences=32, sample_size=380.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.894729, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.694, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.351, expert1_balance_top=31.229, expert1_balance_bottom=19.522, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=368.65, wps=213.7, ups=0.56, wpb=380.2, bsz=32, num_updates=1970, lr=9.26928e-07, gnorm=6.588, loss_scale=256, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3528
2022-05-10 22:34:08 - progress_bar.py[line:272] - INFO: epoch 001:   1982 / 17711 loss=9.699, loss_v1=0, loss_v2=0, nll_loss=8.535, ntokens=381.1, nsentences=32, sample_size=381.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.891323, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.699, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.351, expert1_balance_top=31.742, expert1_balance_bottom=19.431, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=370.81, wps=222.4, ups=0.58, wpb=381.1, bsz=32, num_updates=1980, lr=9.31633e-07, gnorm=6.754, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3545
2022-05-10 22:34:25 - progress_bar.py[line:272] - INFO: epoch 001:   1992 / 17711 loss=9.72, loss_v1=0, loss_v2=0, nll_loss=8.546, ntokens=382.9, nsentences=32, sample_size=382.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.902332, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.72, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.351, expert1_balance_top=30.855, expert1_balance_bottom=19.879, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=373.75, wps=219.8, ups=0.57, wpb=382.9, bsz=32, num_updates=1990, lr=9.36338e-07, gnorm=6.849, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3562
2022-05-10 22:34:43 - progress_bar.py[line:272] - INFO: epoch 001:   2002 / 17711 loss=9.761, loss_v1=0, loss_v2=0, nll_loss=8.604, ntokens=388, nsentences=32, sample_size=388, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.89135, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.761, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.351, expert1_balance_top=30.548, expert1_balance_bottom=19.978, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=389.01, wps=221.9, ups=0.57, wpb=388, bsz=32, num_updates=2000, lr=9.41044e-07, gnorm=6.311, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3580
2022-05-10 22:34:43 - train.py[line:470] - INFO: begin validation on "valid" subset on rank 0
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2022-05-10 22:34:43 - train.py[line:480] - INFO: got valid iterator on "valid" subset on rank 0
2022-05-10 22:34:43 - train.py[line:508] - INFO: Begin looping over validation "valid" subset with length "625"
2022-05-10 22:39:37 - train.py[line:517] - INFO: valid_step finished
2022-05-10 22:39:37 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 10.878 | loss_v1 0 | loss_v2 0 | nll_loss 9.748 | ntokens 481.696 | nsentences 8 | sample_size 481.696 | sample_size_v1 0 | sample_size_v2 0 | moe_gate_loss_v1 0 | moe_gate_loss_v2 0 | moe_gate_loss 0.977467 | inner_loss_v1 0 | inner_loss_v2 0 | inner_loss 10.878 | overflow_expert1 0 | overflow_expert2 0 | entropy_gating 1.355 | expert1_balance_top 40.57 | expert1_balance_bottom 13.44 | unused_expert1_count 0 | expert2_balance_top 0 | expert2_balance_bottom 0 | unused_expert2_count 0 | all_to_all_cpu_time_ms 0 | all_to_all_cuda_time_ms 0 | ppl 860.08 | cider 0 | wps 1029.1 | wpb 481.7 | bsz 8 | num_updates 2000
2022-05-10 22:39:55 - progress_bar.py[line:272] - INFO: epoch 001:   2012 / 17711 loss=9.765, loss_v1=0, loss_v2=0, nll_loss=8.621, ntokens=394.8, nsentences=32, sample_size=394.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.879611, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.765, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.351, expert1_balance_top=31.355, expert1_balance_bottom=19.555, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=393.84, wps=12.7, ups=0.03, wpb=394.8, bsz=32, num_updates=2010, lr=9.45749e-07, gnorm=6.7, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3892
2022-05-10 22:40:12 - progress_bar.py[line:272] - INFO: epoch 001:   2022 / 17711 loss=9.732, loss_v1=0, loss_v2=0, nll_loss=8.569, ntokens=376.2, nsentences=32, sample_size=376.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.893527, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.732, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.349, expert1_balance_top=31.123, expert1_balance_bottom=19.602, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=379.72, wps=215.3, ups=0.57, wpb=376.2, bsz=32, num_updates=2020, lr=9.50454e-07, gnorm=6.935, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3909
2022-05-10 22:40:30 - progress_bar.py[line:272] - INFO: epoch 001:   2032 / 17711 loss=9.768, loss_v1=0, loss_v2=0, nll_loss=8.614, ntokens=379.1, nsentences=32, sample_size=379.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.888354, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.768, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.35, expert1_balance_top=31.016, expert1_balance_bottom=19.676, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=391.92, wps=217.3, ups=0.57, wpb=379.1, bsz=32, num_updates=2030, lr=9.55159e-07, gnorm=6.702, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3927
2022-05-10 22:40:47 - progress_bar.py[line:272] - INFO: epoch 001:   2042 / 17711 loss=9.797, loss_v1=0, loss_v2=0, nll_loss=8.652, ntokens=384.2, nsentences=32, sample_size=384.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.884958, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.797, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.349, expert1_balance_top=31.031, expert1_balance_bottom=19.687, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=402.21, wps=217.6, ups=0.57, wpb=384.2, bsz=32, num_updates=2040, lr=9.59864e-07, gnorm=6.542, loss_scale=256, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3944
2022-05-10 22:41:04 - progress_bar.py[line:272] - INFO: epoch 001:   2052 / 17711 loss=9.772, loss_v1=0, loss_v2=0, nll_loss=8.608, ntokens=384.2, nsentences=32, sample_size=384.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.898023, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.772, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.349, expert1_balance_top=31.332, expert1_balance_bottom=19.546, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=390.27, wps=222.7, ups=0.58, wpb=384.2, bsz=32, num_updates=2050, lr=9.6457e-07, gnorm=6.372, loss_scale=256, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3962
2022-05-10 22:41:22 - progress_bar.py[line:272] - INFO: epoch 001:   2062 / 17711 loss=9.777, loss_v1=0, loss_v2=0, nll_loss=8.626, ntokens=388.3, nsentences=32, sample_size=388.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.887326, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.777, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.349, expert1_balance_top=30.993, expert1_balance_bottom=19.724, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=395.17, wps=219.9, ups=0.57, wpb=388.3, bsz=32, num_updates=2060, lr=9.69275e-07, gnorm=6.611, loss_scale=256, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3979
2022-05-10 22:41:26 - trainer.py[line:1047] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2022-05-10 22:41:41 - progress_bar.py[line:272] - INFO: epoch 001:   2073 / 17711 loss=9.757, loss_v1=0, loss_v2=0, nll_loss=8.593, ntokens=382.1, nsentences=32, sample_size=382.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.897177, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.757, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.349, expert1_balance_top=30.986, expert1_balance_bottom=19.63, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=386.24, wps=200.2, ups=0.52, wpb=382.1, bsz=32, num_updates=2070, lr=9.7398e-07, gnorm=6.9, loss_scale=128, train_wall=18, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=3998
2022-05-10 22:41:58 - progress_bar.py[line:272] - INFO: epoch 001:   2083 / 17711 loss=9.668, loss_v1=0, loss_v2=0, nll_loss=8.497, ntokens=378.8, nsentences=32, sample_size=378.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.894304, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.668, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.348, expert1_balance_top=30.517, expert1_balance_bottom=20.177, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=361.25, wps=220.2, ups=0.58, wpb=378.8, bsz=32, num_updates=2080, lr=9.78685e-07, gnorm=6.379, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4016
2022-05-10 22:42:17 - progress_bar.py[line:272] - INFO: epoch 001:   2093 / 17711 loss=9.755, loss_v1=0, loss_v2=0, nll_loss=8.605, ntokens=394.2, nsentences=32, sample_size=394.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.883805, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.755, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.349, expert1_balance_top=30.81, expert1_balance_bottom=19.84, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=389.38, wps=212.9, ups=0.54, wpb=394.2, bsz=32, num_updates=2090, lr=9.83391e-07, gnorm=6.752, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4034
2022-05-10 22:42:35 - progress_bar.py[line:272] - INFO: epoch 001:   2103 / 17711 loss=9.756, loss_v1=0, loss_v2=0, nll_loss=8.593, ntokens=390, nsentences=32, sample_size=390, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.89546, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.756, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.348, expert1_balance_top=30.828, expert1_balance_bottom=19.842, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=386.24, wps=221, ups=0.57, wpb=390, bsz=32, num_updates=2100, lr=9.88096e-07, gnorm=7.093, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4052
2022-05-10 22:42:52 - progress_bar.py[line:272] - INFO: epoch 001:   2113 / 17711 loss=9.748, loss_v1=0, loss_v2=0, nll_loss=8.599, ntokens=382.4, nsentences=32, sample_size=382.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.882399, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.748, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.347, expert1_balance_top=30.835, expert1_balance_bottom=19.863, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=387.81, wps=219.3, ups=0.57, wpb=382.4, bsz=32, num_updates=2110, lr=9.92801e-07, gnorm=6.705, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4069
2022-05-10 22:43:09 - progress_bar.py[line:272] - INFO: epoch 001:   2123 / 17711 loss=9.711, loss_v1=0, loss_v2=0, nll_loss=8.538, ntokens=377.6, nsentences=32, sample_size=377.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.900528, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.711, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.347, expert1_balance_top=30.853, expert1_balance_bottom=19.969, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=371.75, wps=216.2, ups=0.57, wpb=377.6, bsz=32, num_updates=2120, lr=9.97506e-07, gnorm=7.205, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4087
2022-05-10 22:43:27 - progress_bar.py[line:272] - INFO: epoch 001:   2133 / 17711 loss=9.75, loss_v1=0, loss_v2=0, nll_loss=8.594, ntokens=387.5, nsentences=32, sample_size=387.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.889538, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.75, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.347, expert1_balance_top=31.164, expert1_balance_bottom=19.725, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=386.35, wps=219.6, ups=0.57, wpb=387.5, bsz=32, num_updates=2130, lr=1.00221e-06, gnorm=6.861, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4104
2022-05-10 22:43:44 - progress_bar.py[line:272] - INFO: epoch 001:   2143 / 17711 loss=9.737, loss_v1=0, loss_v2=0, nll_loss=8.572, ntokens=383, nsentences=32, sample_size=383, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.895384, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.737, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.346, expert1_balance_top=30.924, expert1_balance_bottom=19.863, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=380.67, wps=221, ups=0.58, wpb=383, bsz=32, num_updates=2140, lr=1.00692e-06, gnorm=6.33, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4122
2022-05-10 22:44:02 - progress_bar.py[line:272] - INFO: epoch 001:   2153 / 17711 loss=9.708, loss_v1=0, loss_v2=0, nll_loss=8.551, ntokens=384.5, nsentences=32, sample_size=384.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.886578, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.708, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.346, expert1_balance_top=31.411, expert1_balance_bottom=19.647, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=375.01, wps=218.7, ups=0.57, wpb=384.5, bsz=32, num_updates=2150, lr=1.01162e-06, gnorm=6.216, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4139
2022-05-10 22:44:19 - progress_bar.py[line:272] - INFO: epoch 001:   2163 / 17711 loss=9.676, loss_v1=0, loss_v2=0, nll_loss=8.492, ntokens=369.8, nsentences=32, sample_size=369.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.906218, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.676, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.345, expert1_balance_top=30.885, expert1_balance_bottom=20.054, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=360.14, wps=214, ups=0.58, wpb=369.8, bsz=32, num_updates=2160, lr=1.01633e-06, gnorm=6.862, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4156
2022-05-10 22:44:37 - progress_bar.py[line:272] - INFO: epoch 001:   2173 / 17711 loss=9.586, loss_v1=0, loss_v2=0, nll_loss=8.404, ntokens=379.3, nsentences=32, sample_size=379.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.895223, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.586, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.345, expert1_balance_top=31.086, expert1_balance_bottom=19.679, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=338.81, wps=218.4, ups=0.58, wpb=379.3, bsz=32, num_updates=2170, lr=1.02103e-06, gnorm=6.548, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4174
2022-05-10 22:44:54 - progress_bar.py[line:272] - INFO: epoch 001:   2183 / 17711 loss=9.734, loss_v1=0, loss_v2=0, nll_loss=8.579, ntokens=378.3, nsentences=32, sample_size=378.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.886083, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.734, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.345, expert1_balance_top=31.021, expert1_balance_bottom=19.717, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=382.36, wps=214.7, ups=0.57, wpb=378.3, bsz=32, num_updates=2180, lr=1.02574e-06, gnorm=6.613, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4191
2022-05-10 22:45:12 - progress_bar.py[line:272] - INFO: epoch 001:   2193 / 17711 loss=9.715, loss_v1=0, loss_v2=0, nll_loss=8.56, ntokens=387.3, nsentences=32, sample_size=387.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.884005, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.715, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.344, expert1_balance_top=31.512, expert1_balance_bottom=19.488, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=377.49, wps=221, ups=0.57, wpb=387.3, bsz=32, num_updates=2190, lr=1.03044e-06, gnorm=6.357, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4209
2022-05-10 22:45:30 - progress_bar.py[line:272] - INFO: epoch 001:   2203 / 17711 loss=9.652, loss_v1=0, loss_v2=0, nll_loss=8.474, ntokens=385, nsentences=32, sample_size=385, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.899236, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.652, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.344, expert1_balance_top=31.225, expert1_balance_bottom=19.727, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=355.45, wps=216.7, ups=0.56, wpb=385, bsz=32, num_updates=2200, lr=1.03515e-06, gnorm=7.205, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4227
2022-05-10 22:45:47 - progress_bar.py[line:272] - INFO: epoch 001:   2213 / 17711 loss=9.703, loss_v1=0, loss_v2=0, nll_loss=8.524, ntokens=381, nsentences=32, sample_size=381, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.904714, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.703, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.343, expert1_balance_top=30.835, expert1_balance_bottom=19.79, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=368.05, wps=215.1, ups=0.56, wpb=381, bsz=32, num_updates=2210, lr=1.03985e-06, gnorm=6.649, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4244
2022-05-10 22:46:05 - progress_bar.py[line:272] - INFO: epoch 001:   2223 / 17711 loss=9.703, loss_v1=0, loss_v2=0, nll_loss=8.535, ntokens=377.4, nsentences=32, sample_size=377.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.894216, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.703, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.343, expert1_balance_top=30.715, expert1_balance_bottom=19.978, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=371, wps=212.4, ups=0.56, wpb=377.4, bsz=32, num_updates=2220, lr=1.04456e-06, gnorm=6.562, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4262
2022-05-10 22:46:23 - progress_bar.py[line:272] - INFO: epoch 001:   2233 / 17711 loss=9.582, loss_v1=0, loss_v2=0, nll_loss=8.406, ntokens=392.9, nsentences=32, sample_size=392.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.889697, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.582, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.342, expert1_balance_top=31.376, expert1_balance_bottom=19.768, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=339.31, wps=224.3, ups=0.57, wpb=392.9, bsz=32, num_updates=2230, lr=1.04926e-06, gnorm=6.523, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4280
2022-05-10 22:46:40 - progress_bar.py[line:272] - INFO: epoch 001:   2243 / 17711 loss=9.632, loss_v1=0, loss_v2=0, nll_loss=8.466, ntokens=380.6, nsentences=32, sample_size=380.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.885184, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.632, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.342, expert1_balance_top=30.814, expert1_balance_bottom=19.727, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=353.66, wps=216.2, ups=0.57, wpb=380.6, bsz=32, num_updates=2240, lr=1.05397e-06, gnorm=6.525, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4297
2022-05-10 22:46:58 - progress_bar.py[line:272] - INFO: epoch 001:   2253 / 17711 loss=9.727, loss_v1=0, loss_v2=0, nll_loss=8.566, ntokens=377.5, nsentences=32, sample_size=377.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.891246, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.727, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.342, expert1_balance_top=30.946, expert1_balance_bottom=19.84, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=378.89, wps=217, ups=0.57, wpb=377.5, bsz=32, num_updates=2250, lr=1.05867e-06, gnorm=6.438, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4315
2022-05-10 22:47:15 - progress_bar.py[line:272] - INFO: epoch 001:   2263 / 17711 loss=9.615, loss_v1=0, loss_v2=0, nll_loss=8.431, ntokens=378.6, nsentences=32, sample_size=378.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.900151, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.615, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.34, expert1_balance_top=30.888, expert1_balance_bottom=20.027, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=345.2, wps=215.5, ups=0.57, wpb=378.6, bsz=32, num_updates=2260, lr=1.06338e-06, gnorm=6.537, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4332
2022-05-10 22:47:33 - progress_bar.py[line:272] - INFO: epoch 001:   2273 / 17711 loss=9.61, loss_v1=0, loss_v2=0, nll_loss=8.448, ntokens=381.7, nsentences=32, sample_size=381.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.880272, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.61, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.34, expert1_balance_top=30.93, expert1_balance_bottom=19.838, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=349.1, wps=216.8, ups=0.57, wpb=381.7, bsz=32, num_updates=2270, lr=1.06808e-06, gnorm=6.541, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4350
2022-05-10 22:47:50 - progress_bar.py[line:272] - INFO: epoch 001:   2283 / 17711 loss=9.673, loss_v1=0, loss_v2=0, nll_loss=8.506, ntokens=380.2, nsentences=32, sample_size=380.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.890122, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.673, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.34, expert1_balance_top=31.334, expert1_balance_bottom=19.599, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=363.53, wps=214.7, ups=0.56, wpb=380.2, bsz=32, num_updates=2280, lr=1.07279e-06, gnorm=6.612, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4368
2022-05-10 22:48:08 - progress_bar.py[line:272] - INFO: epoch 001:   2293 / 17711 loss=9.645, loss_v1=0, loss_v2=0, nll_loss=8.468, ntokens=387.3, nsentences=32, sample_size=387.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.896785, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.645, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.338, expert1_balance_top=30.979, expert1_balance_bottom=19.719, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=354.14, wps=222.6, ups=0.57, wpb=387.3, bsz=32, num_updates=2290, lr=1.07749e-06, gnorm=6.624, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4385
2022-05-10 22:48:25 - progress_bar.py[line:272] - INFO: epoch 001:   2303 / 17711 loss=9.594, loss_v1=0, loss_v2=0, nll_loss=8.428, ntokens=381.6, nsentences=32, sample_size=381.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.881398, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.594, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.338, expert1_balance_top=30.968, expert1_balance_bottom=20.032, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=344.42, wps=220.1, ups=0.58, wpb=381.6, bsz=32, num_updates=2300, lr=1.0822e-06, gnorm=6.476, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4402
2022-05-10 22:48:42 - progress_bar.py[line:272] - INFO: epoch 001:   2313 / 17711 loss=9.617, loss_v1=0, loss_v2=0, nll_loss=8.452, ntokens=391.1, nsentences=32, sample_size=391.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.882984, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.617, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.338, expert1_balance_top=31.183, expert1_balance_bottom=19.893, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=350.17, wps=226, ups=0.58, wpb=391.1, bsz=32, num_updates=2310, lr=1.08691e-06, gnorm=6.677, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4420
2022-05-10 22:49:00 - progress_bar.py[line:272] - INFO: epoch 001:   2323 / 17711 loss=9.66, loss_v1=0, loss_v2=0, nll_loss=8.507, ntokens=385.4, nsentences=32, sample_size=385.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.876066, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.66, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.338, expert1_balance_top=30.78, expert1_balance_bottom=19.861, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=363.83, wps=224.8, ups=0.58, wpb=385.4, bsz=32, num_updates=2320, lr=1.09161e-06, gnorm=6.733, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4437
2022-05-10 22:49:17 - progress_bar.py[line:272] - INFO: epoch 001:   2333 / 17711 loss=9.713, loss_v1=0, loss_v2=0, nll_loss=8.555, ntokens=389, nsentences=32, sample_size=389, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.886478, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.713, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.337, expert1_balance_top=31.322, expert1_balance_bottom=19.695, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=376.15, wps=226, ups=0.58, wpb=389, bsz=32, num_updates=2330, lr=1.09632e-06, gnorm=6.758, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4454
2022-05-10 22:49:34 - progress_bar.py[line:272] - INFO: epoch 001:   2343 / 17711 loss=9.553, loss_v1=0, loss_v2=0, nll_loss=8.374, ntokens=382.8, nsentences=32, sample_size=382.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.889474, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.553, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.335, expert1_balance_top=31.094, expert1_balance_bottom=19.891, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=331.66, wps=221.3, ups=0.58, wpb=382.8, bsz=32, num_updates=2340, lr=1.10102e-06, gnorm=6.607, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4471
2022-05-10 22:49:52 - progress_bar.py[line:272] - INFO: epoch 001:   2353 / 17711 loss=9.652, loss_v1=0, loss_v2=0, nll_loss=8.511, ntokens=398.2, nsentences=32, sample_size=398.2, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.864239, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.652, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.336, expert1_balance_top=31.378, expert1_balance_bottom=19.725, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=364.9, wps=227.2, ups=0.57, wpb=398.2, bsz=32, num_updates=2350, lr=1.10573e-06, gnorm=6.73, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4489
2022-05-10 22:50:09 - progress_bar.py[line:272] - INFO: epoch 001:   2363 / 17711 loss=9.652, loss_v1=0, loss_v2=0, nll_loss=8.481, ntokens=385.5, nsentences=32, sample_size=385.5, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.891554, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.652, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.334, expert1_balance_top=30.961, expert1_balance_bottom=19.943, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=357.26, wps=225.4, ups=0.58, wpb=385.5, bsz=32, num_updates=2360, lr=1.11043e-06, gnorm=6.435, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4506
2022-05-10 22:50:26 - progress_bar.py[line:272] - INFO: epoch 001:   2373 / 17711 loss=9.656, loss_v1=0, loss_v2=0, nll_loss=8.48, ntokens=374.3, nsentences=32, sample_size=374.3, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.896559, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.656, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.334, expert1_balance_top=30.865, expert1_balance_bottom=20.191, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=357.08, wps=214.4, ups=0.57, wpb=374.3, bsz=32, num_updates=2370, lr=1.11514e-06, gnorm=6.874, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4523
2022-05-10 22:50:44 - progress_bar.py[line:272] - INFO: epoch 001:   2383 / 17711 loss=9.675, loss_v1=0, loss_v2=0, nll_loss=8.504, ntokens=377.6, nsentences=32, sample_size=377.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.893722, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.675, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.333, expert1_balance_top=31.744, expert1_balance_bottom=19.571, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=363.09, wps=214.7, ups=0.57, wpb=377.6, bsz=32, num_updates=2380, lr=1.11984e-06, gnorm=6.677, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4541
2022-05-10 22:51:01 - progress_bar.py[line:272] - INFO: epoch 001:   2393 / 17711 loss=9.581, loss_v1=0, loss_v2=0, nll_loss=8.411, ntokens=389.8, nsentences=32, sample_size=389.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.883963, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.581, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.332, expert1_balance_top=30.739, expert1_balance_bottom=19.982, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=340.35, wps=223.8, ups=0.57, wpb=389.8, bsz=32, num_updates=2390, lr=1.12455e-06, gnorm=6.172, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4558
2022-05-10 22:51:19 - progress_bar.py[line:272] - INFO: epoch 001:   2403 / 17711 loss=9.638, loss_v1=0, loss_v2=0, nll_loss=8.475, ntokens=386.7, nsentences=32, sample_size=386.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.883271, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.638, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.332, expert1_balance_top=30.755, expert1_balance_bottom=19.981, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=355.8, wps=222.3, ups=0.57, wpb=386.7, bsz=32, num_updates=2400, lr=1.12925e-06, gnorm=6.602, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4576
2022-05-10 22:51:36 - progress_bar.py[line:272] - INFO: epoch 001:   2413 / 17711 loss=9.644, loss_v1=0, loss_v2=0, nll_loss=8.472, ntokens=384, nsentences=32, sample_size=384, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.892308, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.644, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.33, expert1_balance_top=31.343, expert1_balance_bottom=19.703, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=354.99, wps=221.9, ups=0.58, wpb=384, bsz=32, num_updates=2410, lr=1.13396e-06, gnorm=6.483, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4593
2022-05-10 22:51:53 - progress_bar.py[line:272] - INFO: epoch 001:   2423 / 17711 loss=9.694, loss_v1=0, loss_v2=0, nll_loss=8.528, ntokens=376.4, nsentences=32, sample_size=376.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.891713, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.694, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.33, expert1_balance_top=31.109, expert1_balance_bottom=19.817, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=369.02, wps=217.5, ups=0.58, wpb=376.4, bsz=32, num_updates=2420, lr=1.13866e-06, gnorm=6.27, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4610
2022-05-10 22:52:11 - progress_bar.py[line:272] - INFO: epoch 001:   2433 / 17711 loss=9.588, loss_v1=0, loss_v2=0, nll_loss=8.4, ntokens=377.1, nsentences=32, sample_size=377.1, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.89954, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.588, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.328, expert1_balance_top=31.278, expert1_balance_bottom=19.996, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=337.82, wps=211.3, ups=0.56, wpb=377.1, bsz=32, num_updates=2430, lr=1.14337e-06, gnorm=6.328, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4628
2022-05-10 22:52:28 - progress_bar.py[line:272] - INFO: epoch 001:   2443 / 17711 loss=9.65, loss_v1=0, loss_v2=0, nll_loss=8.473, ntokens=381.8, nsentences=32, sample_size=381.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.895669, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.65, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.328, expert1_balance_top=30.915, expert1_balance_bottom=19.895, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=355.44, wps=220.2, ups=0.58, wpb=381.8, bsz=32, num_updates=2440, lr=1.14807e-06, gnorm=6.476, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4646
2022-05-10 22:52:45 - progress_bar.py[line:272] - INFO: epoch 001:   2453 / 17711 loss=9.713, loss_v1=0, loss_v2=0, nll_loss=8.558, ntokens=383.4, nsentences=32, sample_size=383.4, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.882591, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.713, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.328, expert1_balance_top=30.957, expert1_balance_bottom=19.942, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=377.01, wps=227.9, ups=0.59, wpb=383.4, bsz=32, num_updates=2450, lr=1.15278e-06, gnorm=6.387, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4662
2022-05-10 22:53:02 - progress_bar.py[line:272] - INFO: epoch 001:   2463 / 17711 loss=9.577, loss_v1=0, loss_v2=0, nll_loss=8.393, ntokens=382.7, nsentences=32, sample_size=382.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.896194, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.577, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.325, expert1_balance_top=31.232, expert1_balance_bottom=19.895, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=336.06, wps=224.2, ups=0.59, wpb=382.7, bsz=32, num_updates=2460, lr=1.15748e-06, gnorm=6.507, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4680
2022-05-10 22:53:19 - progress_bar.py[line:272] - INFO: epoch 001:   2473 / 17711 loss=9.601, loss_v1=0, loss_v2=0, nll_loss=8.413, ntokens=379.8, nsentences=32, sample_size=379.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.901573, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.601, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.324, expert1_balance_top=31.395, expert1_balance_bottom=19.758, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=340.78, wps=222.4, ups=0.59, wpb=379.8, bsz=32, num_updates=2470, lr=1.16219e-06, gnorm=6.799, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4697
2022-05-10 22:53:37 - progress_bar.py[line:272] - INFO: epoch 001:   2483 / 17711 loss=9.606, loss_v1=0, loss_v2=0, nll_loss=8.435, ntokens=388.6, nsentences=32, sample_size=388.6, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.886157, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.606, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.323, expert1_balance_top=31.239, expert1_balance_bottom=19.754, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=346.14, wps=222.4, ups=0.57, wpb=388.6, bsz=32, num_updates=2480, lr=1.16689e-06, gnorm=6.827, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4714
2022-05-10 22:53:54 - progress_bar.py[line:272] - INFO: epoch 001:   2493 / 17711 loss=9.566, loss_v1=0, loss_v2=0, nll_loss=8.388, ntokens=380.8, nsentences=32, sample_size=380.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.88847, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.566, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.322, expert1_balance_top=30.688, expert1_balance_bottom=20.11, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=335.1, wps=219.4, ups=0.58, wpb=380.8, bsz=32, num_updates=2490, lr=1.1716e-06, gnorm=6.859, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4731
2022-05-10 22:54:12 - progress_bar.py[line:272] - INFO: epoch 001:   2503 / 17711 loss=9.644, loss_v1=0, loss_v2=0, nll_loss=8.479, ntokens=383.7, nsentences=32, sample_size=383.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.885017, inner_loss_v1=0, inner_loss_v2=0, inner_loss=9.644, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.321, expert1_balance_top=31.513, expert1_balance_bottom=19.564, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=356.79, wps=218.2, ups=0.57, wpb=383.7, bsz=32, num_updates=2500, lr=1.1763e-06, gnorm=6.637, loss_scale=128, train_wall=17, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4749
2022-05-10 22:54:29 - progress_bar.py[line:272] - INFO: epoch 001:   2513 / 17711 loss=8.867, loss_v1=0, loss_v2=0, nll_loss=7.603, ntokens=377, nsentences=32, sample_size=307.9, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.881868, inner_loss_v1=0, inner_loss_v2=0, inner_loss=8.867, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.32, expert1_balance_top=31.124, expert1_balance_bottom=20.011, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=194.4, wps=216.6, ups=0.57, wpb=377, bsz=32, num_updates=2510, lr=1.18101e-06, gnorm=7.371, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4766
2022-05-10 22:54:47 - progress_bar.py[line:272] - INFO: epoch 001:   2523 / 17711 loss=8.883, loss_v1=0, loss_v2=0, nll_loss=7.634, ntokens=385.4, nsentences=32, sample_size=306.8, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.881894, inner_loss_v1=0, inner_loss_v2=0, inner_loss=8.883, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.32, expert1_balance_top=30.959, expert1_balance_bottom=19.977, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=198.69, wps=219, ups=0.57, wpb=385.4, bsz=32, num_updates=2520, lr=1.18571e-06, gnorm=6.785, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4784
2022-05-10 22:55:04 - progress_bar.py[line:272] - INFO: epoch 001:   2533 / 17711 loss=8.932, loss_v1=0, loss_v2=0, nll_loss=7.695, ntokens=386.9, nsentences=32, sample_size=307.7, sample_size_v1=0, sample_size_v2=0, moe_gate_loss_v1=0, moe_gate_loss_v2=0, moe_gate_loss=0.874878, inner_loss_v1=0, inner_loss_v2=0, inner_loss=8.932, overflow_expert1=0, overflow_expert2=0, entropy_gating=1.319, expert1_balance_top=31.429, expert1_balance_bottom=19.748, unused_expert1_count=0, expert2_balance_top=0, expert2_balance_bottom=0, unused_expert2_count=0, all_to_all_cpu_time_ms=0, all_to_all_cuda_time_ms=0, ppl=207.27, wps=224.5, ups=0.58, wpb=386.9, bsz=32, num_updates=2530, lr=1.19042e-06, gnorm=7.289, loss_scale=128, train_wall=16, cuda_gb_allocated=14.1, cuda_gb_reserved=14.9, cuda_gb_free=9.6, wall=4801
Traceback (most recent call last):
  File "../../train.py", line 572, in <module>
Killing subprocess 63491
Main process received SIGINT, exiting
