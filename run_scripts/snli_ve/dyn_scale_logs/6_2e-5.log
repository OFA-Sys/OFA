2022-03-24 23:16:13 - utils.py[line:255] - INFO: distributed init (rank 3): env://
2022-03-24 23:16:13 - utils.py[line:261] - INFO: Start init
2022-03-24 23:16:13 - utils.py[line:255] - INFO: distributed init (rank 0): env://
2022-03-24 23:16:13 - utils.py[line:261] - INFO: Start init
2022-03-24 23:16:13 - utils.py[line:255] - INFO: distributed init (rank 1): env://
2022-03-24 23:16:13 - utils.py[line:261] - INFO: Start init
2022-03-24 23:16:13 - distributed_c10d.py[line:191] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-03-24 23:16:13 - utils.py[line:255] - INFO: distributed init (rank 2): env://
2022-03-24 23:16:13 - utils.py[line:261] - INFO: Start init
2022-03-24 23:16:13 - distributed_c10d.py[line:191] - INFO: Added key: store_based_barrier_key:1 to store for rank: 2
2022-03-24 23:16:14 - distributed_c10d.py[line:191] - INFO: Added key: store_based_barrier_key:1 to store for rank: 3
2022-03-24 23:16:14 - distributed_c10d.py[line:191] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-03-24 23:16:14 - utils.py[line:271] - INFO: initialized host heming-ng1 as rank 0
single-machine distributed training is initialized.
2022-03-24 23:16:14 - utils.py[line:271] - INFO: initialized host heming-ng1 as rank 2
single-machine distributed training is initialized.
2022-03-24 23:16:14 - utils.py[line:271] - INFO: initialized host heming-ng1 as rank 3
single-machine distributed training is initialized.
2022-03-24 23:16:14 - utils.py[line:271] - INFO: initialized host heming-ng1 as rank 1
single-machine distributed training is initialized.
2022-03-24 23:16:17 - train.py[line:76] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 8, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 500, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 8, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 6, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [2e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './dyn_scale_checkpoints/6_2e-5', 'restore_file': '../../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 500, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'snli_score', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_resmo', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_caption=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1, "maybe": 2}', arch='ofa_resmo', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=8, batch_size_valid=8, best_checkpoint_metric='snli_score', bf16=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../dataset/snli_ve_data/snli_ve_train.tsv,../../dataset/snli_ve_data/snli_ve_dev.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.2, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=4, distributed_port=-1, distributed_rank=0, distributed_world_size=4, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.2, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.0, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[2e-05], lr_scheduler='polynomial_decay', max_epoch=6, max_source_positions=1024, max_src_length=80, max_target_positions=1024, max_tgt_length=20, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=4, num_bins=1000, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='../../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./dyn_scale_checkpoints/6_2e-5', save_interval=1, save_interval_updates=500, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,2,3,4,5', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='snli_ve', tensorboard_logdir=None, threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[32], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', valid_batch_size=20, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=500, wandb_project=None, warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'snli_ve', 'data': '../../dataset/snli_ve_data/snli_ve_train.tsv,../../dataset/snli_ve_data/snli_ve_dev.tsv', 'selected_cols': '0,2,3,4,5', 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 80, 'max_tgt_length': 20, 'code_dict_size': 8192, 'patch_image_size': 480, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'ans2label_dict': '{"no": 0, "yes":1, "maybe": 2}', 'add_caption': True, 'valid_batch_size': 20, 'prompt_type': 'prev_output'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.0, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [2e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [2e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-03-24 23:16:17 - ofa_task.py[line:103] - INFO: source dictionary: 59457 types
2022-03-24 23:16:17 - ofa_task.py[line:104] - INFO: target dictionary: 59457 types
local datafile ../../dataset/snli_ve_data/snli_ve_dev.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_dev.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
2022-03-24 23:16:23 - train.py[line:100] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (doe): Dummy_layer(
          (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
          (activation_dropout_module): FairseqDropout()
          (dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (doe): Dummy_layer(
          (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
          (activation_dropout_module): FairseqDropout()
          (dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (doe): Dummy_layer(
          (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
          (activation_dropout_module): FairseqDropout()
          (dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (doe): Dummy_layer(
          (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
          (activation_dropout_module): FairseqDropout()
          (dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.12000000476837158)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (doe): Dummy_layer(
          (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
          (activation_dropout_module): FairseqDropout()
          (dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.1599999964237213)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (doe): Dummy_layer(
          (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
          (activation_dropout_module): FairseqDropout()
          (dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.20000000298023224)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (doe): Dummy_layer(
          (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
          (activation_dropout_module): FairseqDropout()
          (dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (doe): Dummy_layer(
          (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
          (activation_dropout_module): FairseqDropout()
          (dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (doe): Dummy_layer(
          (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
          (activation_dropout_module): FairseqDropout()
          (dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (doe): Dummy_layer(
          (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
          (activation_dropout_module): FairseqDropout()
          (dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.12000000476837158)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (doe): Dummy_layer(
          (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
          (activation_dropout_module): FairseqDropout()
          (dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.1599999964237213)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (doe): Dummy_layer(
          (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
          (activation_dropout_module): FairseqDropout()
          (dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.20000000298023224)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-03-24 23:16:23 - train.py[line:101] - INFO: task: SnliVeTask
2022-03-24 23:16:23 - train.py[line:102] - INFO: model: OFAModel
2022-03-24 23:16:23 - train.py[line:103] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-03-24 23:16:23 - train.py[line:104] - INFO: num. shared model params: 238,907,726 (num. trained: 238,907,726)
2022-03-24 23:16:23 - train.py[line:111] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../dataset/snli_ve_data/snli_ve_dev.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_dev.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_dev.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/snli_ve_data/snli_ve_dev.tsv slice_id 2 row count 4464 total row count 17858
/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:266: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
local datafile ../../dataset/snli_ve_data/snli_ve_dev.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/snli_ve_data/snli_ve_dev.tsv slice_id 3 row count 4464 total row count 17858
/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:266: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
local datafile ../../dataset/snli_ve_data/snli_ve_dev.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/snli_ve_data/snli_ve_dev.tsv slice_id 0 row count 4465 total row count 17858
/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:266: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
local datafile ../../dataset/snli_ve_data/snli_ve_dev.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/snli_ve_data/snli_ve_dev.tsv slice_id 1 row count 4465 total row count 17858
/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:266: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
2022-03-24 23:16:24 - distributed_c10d.py[line:191] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.layers.0.ffn_layernorm.weight <- encoder.layers.0.doe.ffn_layernorm.weight
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.layers.0.ffn_layernorm.bias <- encoder.layers.0.doe.ffn_layernorm.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.layers.1.ffn_layernorm.weight <- encoder.layers.1.doe.ffn_layernorm.weight
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.layers.1.ffn_layernorm.bias <- encoder.layers.1.doe.ffn_layernorm.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.layers.2.ffn_layernorm.weight <- encoder.layers.2.doe.ffn_layernorm.weight
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.layers.2.ffn_layernorm.bias <- encoder.layers.2.doe.ffn_layernorm.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.layers.3.ffn_layernorm.weight <- encoder.layers.3.doe.ffn_layernorm.weight
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.layers.3.ffn_layernorm.bias <- encoder.layers.3.doe.ffn_layernorm.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.layers.4.ffn_layernorm.weight <- encoder.layers.4.doe.ffn_layernorm.weight
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.layers.4.ffn_layernorm.bias <- encoder.layers.4.doe.ffn_layernorm.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.layers.5.ffn_layernorm.weight <- encoder.layers.5.doe.ffn_layernorm.weight
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: encoder.layers.5.ffn_layernorm.bias <- encoder.layers.5.doe.ffn_layernorm.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: decoder.layers.0.ffn_layernorm.weight <- decoder.layers.0.doe.ffn_layernorm.weight
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: decoder.layers.0.ffn_layernorm.bias <- decoder.layers.0.doe.ffn_layernorm.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: decoder.layers.1.ffn_layernorm.weight <- decoder.layers.1.doe.ffn_layernorm.weight
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: decoder.layers.1.ffn_layernorm.bias <- decoder.layers.1.doe.ffn_layernorm.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: decoder.layers.2.ffn_layernorm.weight <- decoder.layers.2.doe.ffn_layernorm.weight
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: decoder.layers.2.ffn_layernorm.bias <- decoder.layers.2.doe.ffn_layernorm.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: decoder.layers.3.ffn_layernorm.weight <- decoder.layers.3.doe.ffn_layernorm.weight
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: decoder.layers.3.ffn_layernorm.bias <- decoder.layers.3.doe.ffn_layernorm.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: decoder.layers.4.ffn_layernorm.weight <- decoder.layers.4.doe.ffn_layernorm.weight
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: decoder.layers.4.ffn_layernorm.bias <- decoder.layers.4.doe.ffn_layernorm.bias
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: decoder.layers.5.ffn_layernorm.weight <- decoder.layers.5.doe.ffn_layernorm.weight
2022-03-24 23:16:25 - trainer.py[line:124] - INFO: detected shared parameter: decoder.layers.5.ffn_layernorm.bias <- decoder.layers.5.doe.ffn_layernorm.bias
2022-03-24 23:16:25 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 4 workers***********************
2022-03-24 23:16:25 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2022-03-24 23:16:25 - utils.py[line:761] - INFO: rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2022-03-24 23:16:25 - utils.py[line:761] - INFO: rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2022-03-24 23:16:25 - utils.py[line:761] - INFO: rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2022-03-24 23:16:25 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 4 workers***********************
2022-03-24 23:16:25 - train.py[line:142] - INFO: training on 4 devices (GPUs/TPUs)
2022-03-24 23:16:25 - train.py[line:147] - INFO: max tokens per device = None and max sentences per device = 8
2022-03-24 23:16:25 - trainer.py[line:459] - INFO: Preparing to load checkpoint ../../checkpoints/ofa_base.pt
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2022-03-24 23:16:31 - adam.py[line:68] - INFO: using FusedAdam
2022-03-24 23:16:31 - trainer.py[line:618] - INFO: Loaded checkpoint ../../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2022-03-24 23:16:31 - trainer.py[line:640] - INFO: loading train data for epoch 1
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 row count 132381 total row count 529527
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 row count 132382 total row count 529527
/workspace/OFA/data/mm_data/snli_ve_dataset.py:60: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  decoder_prompts = np.array([s['decoder_prompt'].tolist() for s in samples])
slice_id 3 seek offset 397146
Total steps 3108, warmup steps 186, warmup_factor 0.005376344086021506
/workspace/OFA/data/mm_data/snli_ve_dataset.py:60: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  decoder_prompts = np.array([s['decoder_prompt'].tolist() for s in samples])
slice_id 2 seek offset 264764
Total steps 3108, warmup steps 186, warmup_factor 0.005376344086021506
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping

file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 row count 132382 total row count 529527
file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 row count 132382 total row count 529527
/workspace/OFA/data/mm_data/snli_ve_dataset.py:60: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  decoder_prompts = np.array([s['decoder_prompt'].tolist() for s in samples])
slice_id 0 seek offset 0
Total steps 3108, warmup steps 186, warmup_factor 0.005376344086021506
2022-03-24 23:16:51 - trainer.py[line:704] - INFO: begin training epoch 1
2022-03-24 23:16:51 - train.py[line:295] - INFO: Start iterating over samples
/workspace/OFA/data/mm_data/snli_ve_dataset.py:60: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  decoder_prompts = np.array([s['decoder_prompt'].tolist() for s in samples])
slice_id 1 seek offset 132382
Total steps 3108, warmup steps 186, warmup_factor 0.005376344086021506
2022-03-24 23:17:18 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-24 23:17:38 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-24 23:17:58 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-24 23:19:57 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-24 23:21:03 - progress_bar.py[line:272] - INFO: epoch 001:     14 / 518 loss=1.439, loss_v1=0, loss_v2=0, nll_loss=1.439, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=112.3, ups=0.05, wpb=2048, bsz=1024, num_updates=10, lr=1.07527e-06, gnorm=18.969, clip=100, loss_scale=8, train_wall=202, gb_free=8.4, wall=278
2022-03-24 23:23:46 - progress_bar.py[line:272] - INFO: epoch 001:     24 / 518 loss=1.18, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=125.1, ups=0.06, wpb=2048, bsz=1024, num_updates=20, lr=2.15054e-06, gnorm=15.745, clip=100, loss_scale=8, train_wall=131, gb_free=8.4, wall=442
2022-03-24 23:26:30 - progress_bar.py[line:272] - INFO: epoch 001:     34 / 518 loss=0.778, loss_v1=0, loss_v2=0, nll_loss=0.778, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=125, ups=0.06, wpb=2048, bsz=1024, num_updates=30, lr=3.22581e-06, gnorm=12.091, clip=100, loss_scale=8, train_wall=132, gb_free=8, wall=606
2022-03-24 23:29:13 - progress_bar.py[line:272] - INFO: epoch 001:     44 / 518 loss=0.676, loss_v1=0, loss_v2=0, nll_loss=0.676, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=125.5, ups=0.06, wpb=2048, bsz=1024, num_updates=40, lr=4.30108e-06, gnorm=8.181, clip=100, loss_scale=8, train_wall=131, gb_free=8.3, wall=769
2022-03-24 23:31:57 - progress_bar.py[line:272] - INFO: epoch 001:     54 / 518 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.57, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=125.3, ups=0.06, wpb=2048, bsz=1024, num_updates=50, lr=5.37634e-06, gnorm=1.921, clip=90, loss_scale=8, train_wall=131, gb_free=8, wall=932
2022-03-24 23:34:41 - progress_bar.py[line:272] - INFO: epoch 001:     64 / 518 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=125.2, ups=0.06, wpb=2048, bsz=1024, num_updates=60, lr=6.45161e-06, gnorm=1.092, clip=50, loss_scale=8, train_wall=131, gb_free=8.3, wall=1096
2022-03-24 23:37:24 - progress_bar.py[line:272] - INFO: epoch 001:     74 / 518 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=125, ups=0.06, wpb=2048, bsz=1024, num_updates=70, lr=7.52688e-06, gnorm=0.787, clip=10, loss_scale=8, train_wall=131, gb_free=8.3, wall=1260
2022-03-24 23:40:08 - progress_bar.py[line:272] - INFO: epoch 001:     84 / 518 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=125, ups=0.06, wpb=2048, bsz=1024, num_updates=80, lr=8.60215e-06, gnorm=0.832, clip=10, loss_scale=8, train_wall=131, gb_free=8.3, wall=1424
2022-03-24 23:42:52 - progress_bar.py[line:272] - INFO: epoch 001:     94 / 518 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=125.2, ups=0.06, wpb=2048, bsz=1024, num_updates=90, lr=9.67742e-06, gnorm=1.164, clip=80, loss_scale=8, train_wall=131, gb_free=7.9, wall=1587
2022-03-24 23:45:36 - progress_bar.py[line:272] - INFO: epoch 001:    104 / 518 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=124.7, ups=0.06, wpb=2048, bsz=1024, num_updates=100, lr=1.07527e-05, gnorm=1.172, clip=80, loss_scale=8, train_wall=132, gb_free=8.4, wall=1751
2022-03-24 23:48:20 - progress_bar.py[line:272] - INFO: epoch 001:    114 / 518 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=124.8, ups=0.06, wpb=2048, bsz=1024, num_updates=110, lr=1.1828e-05, gnorm=1.075, clip=80, loss_scale=8, train_wall=130, gb_free=7.8, wall=1915
2022-03-24 23:51:05 - progress_bar.py[line:272] - INFO: epoch 001:    124 / 518 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=124.3, ups=0.06, wpb=2048, bsz=1024, num_updates=120, lr=1.29032e-05, gnorm=1.087, clip=70, loss_scale=8, train_wall=130, gb_free=8.4, wall=2080
2022-03-24 23:53:48 - progress_bar.py[line:272] - INFO: epoch 001:    134 / 518 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=125.4, ups=0.06, wpb=2048, bsz=1024, num_updates=130, lr=1.39785e-05, gnorm=0.92, clip=20, loss_scale=8, train_wall=130, gb_free=7.9, wall=2243
2022-03-24 23:56:32 - progress_bar.py[line:272] - INFO: epoch 001:    144 / 518 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=124.8, ups=0.06, wpb=2048, bsz=1024, num_updates=140, lr=1.50538e-05, gnorm=0.904, clip=30, loss_scale=8, train_wall=130, gb_free=7.9, wall=2408
2022-03-24 23:59:15 - progress_bar.py[line:272] - INFO: epoch 001:    154 / 518 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=125.5, ups=0.06, wpb=2048, bsz=1024, num_updates=150, lr=1.6129e-05, gnorm=0.847, clip=20, loss_scale=8, train_wall=130, gb_free=8.3, wall=2571
2022-03-25 00:01:59 - progress_bar.py[line:272] - INFO: epoch 001:    164 / 518 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=125, ups=0.06, wpb=2048, bsz=1024, num_updates=160, lr=1.72043e-05, gnorm=0.814, clip=0, loss_scale=8, train_wall=130, gb_free=8.4, wall=2735
2022-03-25 00:04:44 - progress_bar.py[line:272] - INFO: epoch 001:    174 / 518 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=124, ups=0.06, wpb=2048, bsz=1024, num_updates=170, lr=1.82796e-05, gnorm=0.806, clip=20, loss_scale=8, train_wall=131, gb_free=8.3, wall=2900
2022-03-25 00:07:29 - progress_bar.py[line:272] - INFO: epoch 001:    184 / 518 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=124.1, ups=0.06, wpb=2048, bsz=1024, num_updates=180, lr=1.93548e-05, gnorm=0.854, clip=10, loss_scale=8, train_wall=132, gb_free=8.4, wall=3065
2022-03-25 00:10:15 - progress_bar.py[line:272] - INFO: epoch 001:    194 / 518 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=123.9, ups=0.06, wpb=2048, bsz=1024, num_updates=190, lr=1.99726e-05, gnorm=0.935, clip=60, loss_scale=8, train_wall=133, gb_free=7.9, wall=3230
2022-03-25 00:12:58 - progress_bar.py[line:272] - INFO: epoch 001:    204 / 518 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=125.3, ups=0.06, wpb=2048, bsz=1024, num_updates=200, lr=1.99042e-05, gnorm=0.935, clip=50, loss_scale=8, train_wall=131, gb_free=8.1, wall=3393
2022-03-25 00:15:43 - progress_bar.py[line:272] - INFO: epoch 001:    214 / 518 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=124.5, ups=0.06, wpb=2048, bsz=1024, num_updates=210, lr=1.98357e-05, gnorm=0.695, clip=0, loss_scale=8, train_wall=131, gb_free=7.8, wall=3558
2022-03-25 00:18:26 - progress_bar.py[line:272] - INFO: epoch 001:    224 / 518 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=125.7, ups=0.06, wpb=2048, bsz=1024, num_updates=220, lr=1.97673e-05, gnorm=0.704, clip=0, loss_scale=8, train_wall=132, gb_free=8.3, wall=3721
2022-03-25 00:21:10 - progress_bar.py[line:272] - INFO: epoch 001:    234 / 518 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=124.9, ups=0.06, wpb=2048, bsz=1024, num_updates=230, lr=1.96988e-05, gnorm=0.647, clip=0, loss_scale=8, train_wall=132, gb_free=8.4, wall=3885
2022-03-25 00:23:53 - progress_bar.py[line:272] - INFO: epoch 001:    244 / 518 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=125.4, ups=0.06, wpb=2048, bsz=1024, num_updates=240, lr=1.96304e-05, gnorm=0.633, clip=0, loss_scale=8, train_wall=131, gb_free=8.2, wall=4048
2022-03-25 00:26:36 - progress_bar.py[line:272] - INFO: epoch 001:    254 / 518 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=125.7, ups=0.06, wpb=2048, bsz=1024, num_updates=250, lr=1.95619e-05, gnorm=0.587, clip=0, loss_scale=8, train_wall=130, gb_free=7.6, wall=4211
2022-03-25 00:29:20 - progress_bar.py[line:272] - INFO: epoch 001:    264 / 518 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=124.4, ups=0.06, wpb=2048, bsz=1024, num_updates=260, lr=1.94935e-05, gnorm=0.621, clip=0, loss_scale=8, train_wall=132, gb_free=8.3, wall=4376
2022-03-25 00:32:04 - progress_bar.py[line:272] - INFO: epoch 001:    274 / 518 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=125.3, ups=0.06, wpb=2048, bsz=1024, num_updates=270, lr=1.94251e-05, gnorm=0.634, clip=0, loss_scale=8, train_wall=131, gb_free=8, wall=4539
2022-03-25 00:34:47 - progress_bar.py[line:272] - INFO: epoch 001:    284 / 518 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=125.5, ups=0.06, wpb=2048, bsz=1024, num_updates=280, lr=1.93566e-05, gnorm=0.643, clip=0, loss_scale=8, train_wall=130, gb_free=8.4, wall=4702
2022-03-25 00:37:31 - progress_bar.py[line:272] - INFO: epoch 001:    294 / 518 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=125.1, ups=0.06, wpb=2048, bsz=1024, num_updates=290, lr=1.92882e-05, gnorm=0.674, clip=0, loss_scale=8, train_wall=131, gb_free=7.1, wall=4866
2022-03-25 00:40:15 - progress_bar.py[line:272] - INFO: epoch 001:    304 / 518 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=2046.2, nsentences=1023.1, sample_size=2046.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=124.8, ups=0.06, wpb=2046.2, bsz=1023.1, num_updates=300, lr=1.92197e-05, gnorm=0.679, clip=0, loss_scale=8, train_wall=130, gb_free=8, wall=5030
2022-03-25 00:42:59 - progress_bar.py[line:272] - INFO: epoch 001:    314 / 518 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=124.8, ups=0.06, wpb=2048, bsz=1024, num_updates=310, lr=1.91513e-05, gnorm=0.673, clip=0, loss_scale=8, train_wall=131, gb_free=8.2, wall=5194
2022-03-25 00:45:43 - progress_bar.py[line:272] - INFO: epoch 001:    324 / 518 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=124.4, ups=0.06, wpb=2048, bsz=1024, num_updates=320, lr=1.90828e-05, gnorm=0.627, clip=10, loss_scale=8, train_wall=131, gb_free=7.8, wall=5359
2022-03-25 00:48:26 - progress_bar.py[line:272] - INFO: epoch 001:    334 / 518 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=125.7, ups=0.06, wpb=2048, bsz=1024, num_updates=330, lr=1.90144e-05, gnorm=0.647, clip=0, loss_scale=8, train_wall=130, gb_free=8.2, wall=5522
2022-03-25 00:51:10 - progress_bar.py[line:272] - INFO: epoch 001:    344 / 518 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=125.3, ups=0.06, wpb=2048, bsz=1024, num_updates=340, lr=1.89459e-05, gnorm=0.612, clip=0, loss_scale=8, train_wall=131, gb_free=8.3, wall=5685
2022-03-25 00:53:54 - progress_bar.py[line:272] - INFO: epoch 001:    354 / 518 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=125, ups=0.06, wpb=2048, bsz=1024, num_updates=350, lr=1.88775e-05, gnorm=0.688, clip=0, loss_scale=8, train_wall=131, gb_free=7.9, wall=5849
2022-03-25 00:56:34 - progress_bar.py[line:272] - INFO: epoch 001:    364 / 518 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=127.3, ups=0.06, wpb=2048, bsz=1024, num_updates=360, lr=1.8809e-05, gnorm=0.687, clip=0, loss_scale=8, train_wall=130, gb_free=8.2, wall=6010
2022-03-25 00:59:15 - progress_bar.py[line:272] - INFO: epoch 001:    374 / 518 loss=0.228, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=370, lr=1.87406e-05, gnorm=0.654, clip=0, loss_scale=8, train_wall=130, gb_free=8.4, wall=6170
2022-03-25 01:01:56 - progress_bar.py[line:272] - INFO: epoch 001:    384 / 518 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=127.3, ups=0.06, wpb=2048, bsz=1024, num_updates=380, lr=1.86721e-05, gnorm=0.717, clip=10, loss_scale=8, train_wall=131, gb_free=8.2, wall=6331
2022-03-25 01:04:36 - progress_bar.py[line:272] - INFO: epoch 001:    394 / 518 loss=0.227, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=390, lr=1.86037e-05, gnorm=0.634, clip=0, loss_scale=8, train_wall=130, gb_free=8.3, wall=6491
2022-03-25 01:07:16 - progress_bar.py[line:272] - INFO: epoch 001:    404 / 518 loss=0.223, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=400, lr=1.85352e-05, gnorm=0.606, clip=0, loss_scale=8, train_wall=130, gb_free=8.2, wall=6651
2022-03-25 01:09:56 - progress_bar.py[line:272] - INFO: epoch 001:    414 / 518 loss=0.224, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=128.2, ups=0.06, wpb=2048, bsz=1024, num_updates=410, lr=1.84668e-05, gnorm=0.637, clip=0, loss_scale=8, train_wall=130, gb_free=8.3, wall=6811
2022-03-25 01:12:36 - progress_bar.py[line:272] - INFO: epoch 001:    424 / 518 loss=0.223, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=420, lr=1.83984e-05, gnorm=0.748, clip=10, loss_scale=8, train_wall=130, gb_free=8.5, wall=6971
2022-03-25 01:15:16 - progress_bar.py[line:272] - INFO: epoch 001:    434 / 518 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=430, lr=1.83299e-05, gnorm=0.58, clip=0, loss_scale=8, train_wall=130, gb_free=8.3, wall=7131
2022-03-25 01:17:56 - progress_bar.py[line:272] - INFO: epoch 001:    444 / 518 loss=0.223, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=440, lr=1.82615e-05, gnorm=0.662, clip=0, loss_scale=8, train_wall=130, gb_free=8.2, wall=7291
2022-03-25 01:20:35 - progress_bar.py[line:272] - INFO: epoch 001:    454 / 518 loss=0.223, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=128.7, ups=0.06, wpb=2048, bsz=1024, num_updates=450, lr=1.8193e-05, gnorm=0.791, clip=20, loss_scale=8, train_wall=129, gb_free=7.8, wall=7450
2022-03-25 01:23:15 - progress_bar.py[line:272] - INFO: epoch 001:    464 / 518 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=460, lr=1.81246e-05, gnorm=0.668, clip=0, loss_scale=8, train_wall=130, gb_free=8, wall=7610
2022-03-25 01:25:56 - progress_bar.py[line:272] - INFO: epoch 001:    474 / 518 loss=0.212, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=127.6, ups=0.06, wpb=2048, bsz=1024, num_updates=470, lr=1.80561e-05, gnorm=0.688, clip=0, loss_scale=8, train_wall=130, gb_free=8.1, wall=7771
2022-03-25 01:28:35 - progress_bar.py[line:272] - INFO: epoch 001:    484 / 518 loss=0.211, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=128.1, ups=0.06, wpb=2048, bsz=1024, num_updates=480, lr=1.79877e-05, gnorm=0.635, clip=0, loss_scale=8, train_wall=129, gb_free=8.5, wall=7931
2022-03-25 01:30:28 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-25 01:31:32 - progress_bar.py[line:272] - INFO: epoch 001:    495 / 518 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=115.8, ups=0.06, wpb=2048, bsz=1024, num_updates=490, lr=1.79192e-05, gnorm=0.595, clip=0, loss_scale=4, train_wall=144, gb_free=8.3, wall=8107
2022-03-25 01:34:13 - progress_bar.py[line:272] - INFO: epoch 001:    505 / 518 loss=0.21, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=127.7, ups=0.06, wpb=2048, bsz=1024, num_updates=500, lr=1.78508e-05, gnorm=0.588, clip=0, loss_scale=4, train_wall=130, gb_free=8.1, wall=8268
slice_id 3 seek offset 13394
slice_id 1 seek offset 4465
slice_id 2 seek offset 8930
2022-03-25 01:34:13 - train.py[line:435] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 2 seek offset 8930
slice_id 3 seek offset 13394
slice_id 1 seek offset 4465
2022-03-25 01:38:29 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.199 | loss_v1 0 | loss_v2 0 | nll_loss 0.199 | ntokens 63.893 | nsentences 31.946 | sample_size 63.893 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.15 | snli_score 0.8491 | wps 139.5 | wpb 63.9 | bsz 31.9 | num_updates 500
2022-03-25 01:38:29 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 500 updates
2022-03-25 01:38:29 - trainer.py[line:432] - INFO: Saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint_1_500.pt
2022-03-25 01:38:36 - trainer.py[line:442] - INFO: Finished saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint_1_500.pt
2022-03-25 01:38:43 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./dyn_scale_checkpoints/6_2e-5/checkpoint_1_500.pt (epoch 1 @ 500 updates, score 0.8491) (writing took 13.706470740027726 seconds)
2022-03-25 01:41:23 - progress_bar.py[line:272] - INFO: epoch 001:    515 / 518 loss=0.212, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=47.6, ups=0.02, wpb=2048, bsz=1024, num_updates=510, lr=1.77823e-05, gnorm=0.647, clip=0, loss_scale=4, train_wall=130, gb_free=8, wall=8698
slice_id 3 seek offset 13394
slice_id 2 seek offset 8930
slice_id 1 seek offset 4465
2022-03-25 01:41:57 - train.py[line:435] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 3 seek offset 13394
slice_id 2 seek offset 8930
slice_id 1 seek offset 4465
2022-03-25 01:46:15 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.196 | loss_v1 0 | loss_v2 0 | nll_loss 0.196 | ntokens 63.893 | nsentences 31.946 | sample_size 63.893 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.15 | snli_score 0.8516 | wps 138.3 | wpb 63.9 | bsz 31.9 | num_updates 513 | best_snli_score 0.8516
2022-03-25 01:46:15 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 513 updates
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
2022-03-25 01:46:15 - trainer.py[line:432] - INFO: Saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint1.pt
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2022-03-25 01:46:25 - trainer.py[line:442] - INFO: Finished saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint1.pt
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 row count 132382 total row count 529527
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 row count 132381 total row count 529527
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 row count 132382 total row count 529527
slice_id 1 seek offset 132382
slice_id 2 seek offset 264764
slice_id 3 seek offset 397146
2022-03-25 01:46:41 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./dyn_scale_checkpoints/6_2e-5/checkpoint1.pt (epoch 1 @ 513 updates, score 0.8516) (writing took 25.366003043949604 seconds)
2022-03-25 01:46:41 - train.py[line:322] - INFO: end of epoch 1 (average epoch stats below)
2022-03-25 01:46:41 - progress_bar.py[line:282] - INFO: epoch 001 | loss 0.339 | loss_v1 0 | loss_v2 0 | nll_loss 0.339 | ntokens 2044.47 | nsentences 1022.24 | sample_size 2044.47 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.26 | wps 117.6 | ups 0.06 | wpb 2044.5 | bsz 1022.2 | num_updates 513 | lr 1.77618e-05 | gnorm 1.788 | clip 22.2 | loss_scale 4 | train_wall 6776 | gb_free 8.2 | wall 9016
2022-03-25 01:46:41 - trainer.py[line:640] - INFO: loading train data for epoch 2
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 row count 132382 total row count 529527
slice_id 0 seek offset 0
2022-03-25 01:46:58 - trainer.py[line:704] - INFO: begin training epoch 2
2022-03-25 01:46:58 - train.py[line:295] - INFO: Start iterating over samples
2022-03-25 01:48:50 - progress_bar.py[line:272] - INFO: epoch 002:      7 / 518 loss=0.214, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=1868.8, nsentences=934.4, sample_size=1868.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=41.8, ups=0.02, wpb=1868.8, bsz=934.4, num_updates=520, lr=1.77139e-05, gnorm=0.757, clip=10, loss_scale=4, train_wall=117, gb_free=8.2, wall=9146
2022-03-25 01:51:30 - progress_bar.py[line:272] - INFO: epoch 002:     17 / 518 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=128.3, ups=0.06, wpb=2048, bsz=1024, num_updates=530, lr=1.76454e-05, gnorm=0.551, clip=0, loss_scale=4, train_wall=129, gb_free=8, wall=9305
2022-03-25 01:54:10 - progress_bar.py[line:272] - INFO: epoch 002:     27 / 518 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=540, lr=1.7577e-05, gnorm=0.579, clip=0, loss_scale=4, train_wall=130, gb_free=8.4, wall=9465
2022-03-25 01:56:51 - progress_bar.py[line:272] - INFO: epoch 002:     37 / 518 loss=0.209, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=127.4, ups=0.06, wpb=2048, bsz=1024, num_updates=550, lr=1.75086e-05, gnorm=0.591, clip=0, loss_scale=4, train_wall=130, gb_free=8.1, wall=9626
2022-03-25 01:59:31 - progress_bar.py[line:272] - INFO: epoch 002:     47 / 518 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=128.1, ups=0.06, wpb=2048, bsz=1024, num_updates=560, lr=1.74401e-05, gnorm=0.596, clip=0, loss_scale=4, train_wall=130, gb_free=8.3, wall=9786
2022-03-25 02:02:10 - progress_bar.py[line:272] - INFO: epoch 002:     57 / 518 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=128.2, ups=0.06, wpb=2048, bsz=1024, num_updates=570, lr=1.73717e-05, gnorm=0.546, clip=0, loss_scale=4, train_wall=129, gb_free=8.2, wall=9946
2022-03-25 02:04:51 - progress_bar.py[line:272] - INFO: epoch 002:     67 / 518 loss=0.21, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=127.2, ups=0.06, wpb=2048, bsz=1024, num_updates=580, lr=1.73032e-05, gnorm=0.579, clip=0, loss_scale=4, train_wall=131, gb_free=7.8, wall=10107
2022-03-25 02:07:32 - progress_bar.py[line:272] - INFO: epoch 002:     77 / 518 loss=0.202, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=590, lr=1.72348e-05, gnorm=0.563, clip=0, loss_scale=4, train_wall=130, gb_free=8.3, wall=10267
2022-03-25 02:10:13 - progress_bar.py[line:272] - INFO: epoch 002:     87 / 518 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=127.2, ups=0.06, wpb=2048, bsz=1024, num_updates=600, lr=1.71663e-05, gnorm=0.595, clip=0, loss_scale=4, train_wall=131, gb_free=8.1, wall=10428
2022-03-25 02:12:54 - progress_bar.py[line:272] - INFO: epoch 002:     97 / 518 loss=0.213, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=127.4, ups=0.06, wpb=2048, bsz=1024, num_updates=610, lr=1.70979e-05, gnorm=0.523, clip=0, loss_scale=4, train_wall=130, gb_free=8.3, wall=10589
2022-03-25 02:15:34 - progress_bar.py[line:272] - INFO: epoch 002:    107 / 518 loss=0.217, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=620, lr=1.70294e-05, gnorm=0.514, clip=0, loss_scale=4, train_wall=130, gb_free=8, wall=10749
2022-03-25 02:18:14 - progress_bar.py[line:272] - INFO: epoch 002:    117 / 518 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=630, lr=1.6961e-05, gnorm=0.51, clip=0, loss_scale=4, train_wall=129, gb_free=7.1, wall=10909
2022-03-25 02:20:54 - progress_bar.py[line:272] - INFO: epoch 002:    127 / 518 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=127.4, ups=0.06, wpb=2048, bsz=1024, num_updates=640, lr=1.68925e-05, gnorm=0.556, clip=0, loss_scale=4, train_wall=130, gb_free=8, wall=11070
2022-03-25 02:23:34 - progress_bar.py[line:272] - INFO: epoch 002:    137 / 518 loss=0.198, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=128.1, ups=0.06, wpb=2048, bsz=1024, num_updates=650, lr=1.68241e-05, gnorm=0.548, clip=0, loss_scale=4, train_wall=129, gb_free=8.1, wall=11230
2022-03-25 02:26:15 - progress_bar.py[line:272] - INFO: epoch 002:    147 / 518 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=127.6, ups=0.06, wpb=2048, bsz=1024, num_updates=660, lr=1.67556e-05, gnorm=0.493, clip=0, loss_scale=4, train_wall=130, gb_free=7.9, wall=11390
2022-03-25 02:28:55 - progress_bar.py[line:272] - INFO: epoch 002:    157 / 518 loss=0.206, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=670, lr=1.66872e-05, gnorm=0.523, clip=0, loss_scale=4, train_wall=129, gb_free=8.4, wall=11550
2022-03-25 02:31:36 - progress_bar.py[line:272] - INFO: epoch 002:    167 / 518 loss=0.21, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=127.7, ups=0.06, wpb=2048, bsz=1024, num_updates=680, lr=1.66188e-05, gnorm=0.579, clip=0, loss_scale=4, train_wall=129, gb_free=8.3, wall=11711
2022-03-25 02:34:16 - progress_bar.py[line:272] - INFO: epoch 002:    177 / 518 loss=0.207, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=690, lr=1.65503e-05, gnorm=0.562, clip=0, loss_scale=4, train_wall=130, gb_free=8, wall=11871
2022-03-25 02:36:56 - progress_bar.py[line:272] - INFO: epoch 002:    187 / 518 loss=0.201, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=700, lr=1.64819e-05, gnorm=0.585, clip=0, loss_scale=4, train_wall=130, gb_free=8.5, wall=12031
2022-03-25 02:39:36 - progress_bar.py[line:272] - INFO: epoch 002:    197 / 518 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=710, lr=1.64134e-05, gnorm=0.592, clip=0, loss_scale=4, train_wall=130, gb_free=8.1, wall=12191
2022-03-25 02:42:15 - progress_bar.py[line:272] - INFO: epoch 002:    207 / 518 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=128.6, ups=0.06, wpb=2048, bsz=1024, num_updates=720, lr=1.6345e-05, gnorm=0.593, clip=0, loss_scale=4, train_wall=129, gb_free=8.4, wall=12351
2022-03-25 02:44:55 - progress_bar.py[line:272] - INFO: epoch 002:    217 / 518 loss=0.193, loss_v1=0, loss_v2=0, nll_loss=0.193, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=128.3, ups=0.06, wpb=2048, bsz=1024, num_updates=730, lr=1.62765e-05, gnorm=0.547, clip=0, loss_scale=4, train_wall=129, gb_free=6.8, wall=12510
2022-03-25 02:47:34 - progress_bar.py[line:272] - INFO: epoch 002:    227 / 518 loss=0.2, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=128.6, ups=0.06, wpb=2048, bsz=1024, num_updates=740, lr=1.62081e-05, gnorm=0.513, clip=0, loss_scale=4, train_wall=129, gb_free=8, wall=12669
2022-03-25 02:50:13 - progress_bar.py[line:272] - INFO: epoch 002:    237 / 518 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=128.6, ups=0.06, wpb=2048, bsz=1024, num_updates=750, lr=1.61396e-05, gnorm=0.457, clip=0, loss_scale=4, train_wall=129, gb_free=8.4, wall=12829
2022-03-25 02:52:53 - progress_bar.py[line:272] - INFO: epoch 002:    247 / 518 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=128.7, ups=0.06, wpb=2048, bsz=1024, num_updates=760, lr=1.60712e-05, gnorm=0.493, clip=0, loss_scale=4, train_wall=129, gb_free=8.4, wall=12988
2022-03-25 02:55:33 - progress_bar.py[line:272] - INFO: epoch 002:    257 / 518 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.7, ups=0.06, wpb=2048, bsz=1024, num_updates=770, lr=1.60027e-05, gnorm=0.511, clip=0, loss_scale=4, train_wall=130, gb_free=8.1, wall=13148
2022-03-25 02:58:12 - progress_bar.py[line:272] - INFO: epoch 002:    267 / 518 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=128.5, ups=0.06, wpb=2048, bsz=1024, num_updates=780, lr=1.59343e-05, gnorm=0.561, clip=0, loss_scale=4, train_wall=129, gb_free=7.5, wall=13308
2022-03-25 03:00:52 - progress_bar.py[line:272] - INFO: epoch 002:    277 / 518 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=128.1, ups=0.06, wpb=2048, bsz=1024, num_updates=790, lr=1.58658e-05, gnorm=0.518, clip=0, loss_scale=4, train_wall=129, gb_free=8, wall=13467
2022-03-25 03:03:32 - progress_bar.py[line:272] - INFO: epoch 002:    287 / 518 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=800, lr=1.57974e-05, gnorm=0.582, clip=0, loss_scale=4, train_wall=129, gb_free=7.8, wall=13628
2022-03-25 03:06:12 - progress_bar.py[line:272] - INFO: epoch 002:    297 / 518 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=810, lr=1.5729e-05, gnorm=0.623, clip=10, loss_scale=4, train_wall=130, gb_free=7.6, wall=13788
2022-03-25 03:08:53 - progress_bar.py[line:272] - INFO: epoch 002:    307 / 518 loss=0.191, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.7, ups=0.06, wpb=2048, bsz=1024, num_updates=820, lr=1.56605e-05, gnorm=0.55, clip=0, loss_scale=4, train_wall=130, gb_free=8.4, wall=13948
2022-03-25 03:11:33 - progress_bar.py[line:272] - INFO: epoch 002:    317 / 518 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.7, ups=0.06, wpb=2048, bsz=1024, num_updates=830, lr=1.55921e-05, gnorm=0.516, clip=0, loss_scale=4, train_wall=130, gb_free=8.1, wall=14108
2022-03-25 03:14:13 - progress_bar.py[line:272] - INFO: epoch 002:    327 / 518 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=840, lr=1.55236e-05, gnorm=0.515, clip=0, loss_scale=4, train_wall=129, gb_free=8.2, wall=14269
2022-03-25 03:16:54 - progress_bar.py[line:272] - INFO: epoch 002:    337 / 518 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.7, ups=0.06, wpb=2048, bsz=1024, num_updates=850, lr=1.54552e-05, gnorm=0.542, clip=0, loss_scale=4, train_wall=130, gb_free=8, wall=14429
2022-03-25 03:19:34 - progress_bar.py[line:272] - INFO: epoch 002:    347 / 518 loss=0.199, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=127.6, ups=0.06, wpb=2048, bsz=1024, num_updates=860, lr=1.53867e-05, gnorm=0.52, clip=0, loss_scale=4, train_wall=130, gb_free=8.2, wall=14589
2022-03-25 03:22:15 - progress_bar.py[line:272] - INFO: epoch 002:    357 / 518 loss=0.195, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=870, lr=1.53183e-05, gnorm=0.561, clip=0, loss_scale=4, train_wall=130, gb_free=8, wall=14750
2022-03-25 03:24:55 - progress_bar.py[line:272] - INFO: epoch 002:    367 / 518 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=127.6, ups=0.06, wpb=2048, bsz=1024, num_updates=880, lr=1.52498e-05, gnorm=0.611, clip=0, loss_scale=4, train_wall=130, gb_free=8.2, wall=14911
2022-03-25 03:27:35 - progress_bar.py[line:272] - INFO: epoch 002:    377 / 518 loss=0.196, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=890, lr=1.51814e-05, gnorm=0.586, clip=0, loss_scale=4, train_wall=130, gb_free=7.8, wall=15071
2022-03-25 03:30:16 - progress_bar.py[line:272] - INFO: epoch 002:    387 / 518 loss=0.197, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=127.7, ups=0.06, wpb=2048, bsz=1024, num_updates=900, lr=1.51129e-05, gnorm=0.618, clip=0, loss_scale=4, train_wall=130, gb_free=8.1, wall=15231
2022-03-25 03:32:56 - progress_bar.py[line:272] - INFO: epoch 002:    397 / 518 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=128.1, ups=0.06, wpb=2048, bsz=1024, num_updates=910, lr=1.50445e-05, gnorm=0.528, clip=0, loss_scale=4, train_wall=130, gb_free=8.5, wall=15391
2022-03-25 03:35:36 - progress_bar.py[line:272] - INFO: epoch 002:    407 / 518 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=920, lr=1.4976e-05, gnorm=0.519, clip=0, loss_scale=4, train_wall=130, gb_free=8.2, wall=15551
2022-03-25 03:38:15 - progress_bar.py[line:272] - INFO: epoch 002:    417 / 518 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=128.4, ups=0.06, wpb=2048, bsz=1024, num_updates=930, lr=1.49076e-05, gnorm=0.489, clip=0, loss_scale=4, train_wall=130, gb_free=7.8, wall=15710
2022-03-25 03:40:54 - progress_bar.py[line:272] - INFO: epoch 002:    427 / 518 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=128.7, ups=0.06, wpb=2048, bsz=1024, num_updates=940, lr=1.48392e-05, gnorm=0.555, clip=0, loss_scale=4, train_wall=129, gb_free=7.9, wall=15870
2022-03-25 03:43:35 - progress_bar.py[line:272] - INFO: epoch 002:    437 / 518 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=950, lr=1.47707e-05, gnorm=0.574, clip=0, loss_scale=4, train_wall=130, gb_free=8, wall=16030
2022-03-25 03:46:14 - progress_bar.py[line:272] - INFO: epoch 002:    447 / 518 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=128.2, ups=0.06, wpb=2048, bsz=1024, num_updates=960, lr=1.47023e-05, gnorm=0.598, clip=0, loss_scale=4, train_wall=130, gb_free=8.4, wall=16190
2022-03-25 03:48:54 - progress_bar.py[line:272] - INFO: epoch 002:    457 / 518 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=2046.2, nsentences=1023.1, sample_size=2046.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=128.1, ups=0.06, wpb=2046.2, bsz=1023.1, num_updates=970, lr=1.46338e-05, gnorm=0.629, clip=0, loss_scale=4, train_wall=129, gb_free=7.9, wall=16349
2022-03-25 03:51:34 - progress_bar.py[line:272] - INFO: epoch 002:    467 / 518 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=980, lr=1.45654e-05, gnorm=0.597, clip=0, loss_scale=4, train_wall=130, gb_free=8.3, wall=16510
2022-03-25 03:54:15 - progress_bar.py[line:272] - INFO: epoch 002:    477 / 518 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.7, ups=0.06, wpb=2048, bsz=1024, num_updates=990, lr=1.44969e-05, gnorm=0.521, clip=0, loss_scale=4, train_wall=130, gb_free=8.2, wall=16670
2022-03-25 03:56:55 - progress_bar.py[line:272] - INFO: epoch 002:    487 / 518 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=1000, lr=1.44285e-05, gnorm=0.584, clip=0, loss_scale=8, train_wall=130, gb_free=8.3, wall=16830
slice_id 2 seek offset 8930
slice_id 3 seek offset 13394
slice_id 1 seek offset 4465
2022-03-25 03:56:55 - train.py[line:435] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 3 seek offset 13394
slice_id 2 seek offset 8930
slice_id 1 seek offset 4465
2022-03-25 04:01:05 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 0.181 | loss_v1 0 | loss_v2 0 | nll_loss 0.181 | ntokens 63.893 | nsentences 31.946 | sample_size 63.893 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.13 | snli_score 0.8659 | wps 143 | wpb 63.9 | bsz 31.9 | num_updates 1000 | best_snli_score 0.8659
2022-03-25 04:01:05 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 1000 updates
2022-03-25 04:01:05 - trainer.py[line:432] - INFO: Saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint_2_1000.pt
2022-03-25 04:01:14 - trainer.py[line:442] - INFO: Finished saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint_2_1000.pt
2022-03-25 04:01:30 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./dyn_scale_checkpoints/6_2e-5/checkpoint_2_1000.pt (epoch 2 @ 1000 updates, score 0.8659) (writing took 24.72079827694688 seconds)
2022-03-25 04:04:11 - progress_bar.py[line:272] - INFO: epoch 002:    497 / 518 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=47, ups=0.02, wpb=2048, bsz=1024, num_updates=1010, lr=1.436e-05, gnorm=0.505, clip=0, loss_scale=8, train_wall=131, gb_free=8.3, wall=17266
2022-03-25 04:06:52 - progress_bar.py[line:272] - INFO: epoch 002:    507 / 518 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.2, ups=0.06, wpb=2048, bsz=1024, num_updates=1020, lr=1.42916e-05, gnorm=0.538, clip=0, loss_scale=8, train_wall=130, gb_free=8.4, wall=17427
2022-03-25 04:09:32 - progress_bar.py[line:272] - INFO: epoch 002:    517 / 518 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=1030, lr=1.42231e-05, gnorm=0.535, clip=0, loss_scale=8, train_wall=130, gb_free=8.3, wall=17587
slice_id 2 seek offset 8930
2022-03-25 04:09:34 - train.py[line:435] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 3 seek offset 13394
slice_id 1 seek offset 4465
slice_id 0 seek offset 0
slice_id 3 seek offset 13394
slice_id 2 seek offset 8930
slice_id 1 seek offset 4465
2022-03-25 04:13:47 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 0.183 | loss_v1 0 | loss_v2 0 | nll_loss 0.183 | ntokens 63.893 | nsentences 31.946 | sample_size 63.893 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.14 | snli_score 0.8643 | wps 141 | wpb 63.9 | bsz 31.9 | num_updates 1031 | best_snli_score 0.8659
2022-03-25 04:13:47 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 1031 updates
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
2022-03-25 04:13:47 - trainer.py[line:432] - INFO: Saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint2.pt
2022-03-25 04:13:56 - trainer.py[line:442] - INFO: Finished saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint2.pt
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 row count 132382 total row count 529527
slice_id 1 seek offset 132382
2022-03-25 04:14:04 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./dyn_scale_checkpoints/6_2e-5/checkpoint2.pt (epoch 2 @ 1031 updates, score 0.8643) (writing took 16.57380115694832 seconds)
2022-03-25 04:14:04 - train.py[line:322] - INFO: end of epoch 2 (average epoch stats below)
2022-03-25 04:14:04 - progress_bar.py[line:282] - INFO: epoch 002 | loss 0.196 | loss_v1 0 | loss_v2 0 | nll_loss 0.196 | ntokens 2044.51 | nsentences 1022.25 | sample_size 2044.51 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.15 | wps 119.8 | ups 0.06 | wpb 2044.5 | bsz 1022.3 | num_updates 1031 | lr 1.42163e-05 | gnorm 0.556 | clip 0.4 | loss_scale 8 | train_wall 6708 | gb_free 8.2 | wall 17859
2022-03-25 04:14:04 - trainer.py[line:640] - INFO: loading train data for epoch 3
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping

file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 row count 132381 total row count 529527file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 row count 132382 total row count 529527

slice_id 2 seek offset 264764
slice_id 3 seek offset 397146
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 row count 132382 total row count 529527
slice_id 0 seek offset 0
2022-03-25 04:14:21 - trainer.py[line:704] - INFO: begin training epoch 3
2022-03-25 04:14:21 - train.py[line:295] - INFO: Start iterating over samples
2022-03-25 04:16:46 - progress_bar.py[line:272] - INFO: epoch 003:      9 / 518 loss=0.187, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=1868.8, nsentences=934.4, sample_size=1868.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=43, ups=0.02, wpb=1868.8, bsz=934.4, num_updates=1040, lr=1.41547e-05, gnorm=0.644, clip=10, loss_scale=8, train_wall=118, gb_free=8.1, wall=18022
2022-03-25 04:19:26 - progress_bar.py[line:272] - INFO: epoch 003:     19 / 518 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=1050, lr=1.40862e-05, gnorm=0.497, clip=0, loss_scale=8, train_wall=129, gb_free=8.3, wall=18182
2022-03-25 04:22:07 - progress_bar.py[line:272] - INFO: epoch 003:     29 / 518 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=1060, lr=1.40178e-05, gnorm=0.497, clip=0, loss_scale=8, train_wall=130, gb_free=8.3, wall=18342
2022-03-25 04:24:46 - progress_bar.py[line:272] - INFO: epoch 003:     39 / 518 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=128.1, ups=0.06, wpb=2048, bsz=1024, num_updates=1070, lr=1.39493e-05, gnorm=0.513, clip=0, loss_scale=8, train_wall=129, gb_free=8.2, wall=18502
2022-03-25 04:27:26 - progress_bar.py[line:272] - INFO: epoch 003:     49 / 518 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=128.1, ups=0.06, wpb=2048, bsz=1024, num_updates=1080, lr=1.38809e-05, gnorm=0.491, clip=0, loss_scale=8, train_wall=130, gb_free=8.3, wall=18662
2022-03-25 04:30:06 - progress_bar.py[line:272] - INFO: epoch 003:     59 / 518 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=128.1, ups=0.06, wpb=2048, bsz=1024, num_updates=1090, lr=1.38125e-05, gnorm=0.547, clip=0, loss_scale=8, train_wall=130, gb_free=8.3, wall=18822
2022-03-25 04:32:47 - progress_bar.py[line:272] - INFO: epoch 003:     69 / 518 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=1100, lr=1.3744e-05, gnorm=0.511, clip=0, loss_scale=8, train_wall=130, gb_free=8.2, wall=18982
2022-03-25 04:35:28 - progress_bar.py[line:272] - INFO: epoch 003:     79 / 518 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.3, ups=0.06, wpb=2048, bsz=1024, num_updates=1110, lr=1.36756e-05, gnorm=0.489, clip=0, loss_scale=8, train_wall=130, gb_free=8.2, wall=19143
2022-03-25 04:38:09 - progress_bar.py[line:272] - INFO: epoch 003:     89 / 518 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.1, ups=0.06, wpb=2048, bsz=1024, num_updates=1120, lr=1.36071e-05, gnorm=0.512, clip=0, loss_scale=8, train_wall=131, gb_free=8, wall=19304
2022-03-25 04:40:50 - progress_bar.py[line:272] - INFO: epoch 003:     99 / 518 loss=0.19, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.3, ups=0.06, wpb=2048, bsz=1024, num_updates=1130, lr=1.35387e-05, gnorm=0.504, clip=0, loss_scale=8, train_wall=130, gb_free=8, wall=19465
2022-03-25 04:43:30 - progress_bar.py[line:272] - INFO: epoch 003:    109 / 518 loss=0.192, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=1140, lr=1.34702e-05, gnorm=0.465, clip=0, loss_scale=8, train_wall=130, gb_free=8.2, wall=19625
2022-03-25 04:46:11 - progress_bar.py[line:272] - INFO: epoch 003:    119 / 518 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.4, ups=0.06, wpb=2048, bsz=1024, num_updates=1150, lr=1.34018e-05, gnorm=0.489, clip=0, loss_scale=8, train_wall=130, gb_free=8.1, wall=19786
2022-03-25 04:48:51 - progress_bar.py[line:272] - INFO: epoch 003:    129 / 518 loss=0.175, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=1160, lr=1.33333e-05, gnorm=0.523, clip=0, loss_scale=8, train_wall=129, gb_free=7.6, wall=19946
2022-03-25 04:51:31 - progress_bar.py[line:272] - INFO: epoch 003:    139 / 518 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=1170, lr=1.32649e-05, gnorm=0.521, clip=0, loss_scale=8, train_wall=129, gb_free=7.7, wall=20106
2022-03-25 04:54:12 - progress_bar.py[line:272] - INFO: epoch 003:    149 / 518 loss=0.189, loss_v1=0, loss_v2=0, nll_loss=0.189, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.2, ups=0.06, wpb=2048, bsz=1024, num_updates=1180, lr=1.31964e-05, gnorm=0.517, clip=0, loss_scale=8, train_wall=130, gb_free=7.6, wall=20267
2022-03-25 04:56:52 - progress_bar.py[line:272] - INFO: epoch 003:    159 / 518 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=1190, lr=1.3128e-05, gnorm=0.541, clip=0, loss_scale=8, train_wall=130, gb_free=8.1, wall=20427
2022-03-25 04:59:33 - progress_bar.py[line:272] - INFO: epoch 003:    169 / 518 loss=0.186, loss_v1=0, loss_v2=0, nll_loss=0.186, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=1200, lr=1.30595e-05, gnorm=0.515, clip=0, loss_scale=8, train_wall=129, gb_free=7.8, wall=20588
2022-03-25 05:02:13 - progress_bar.py[line:272] - INFO: epoch 003:    179 / 518 loss=0.183, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=1210, lr=1.29911e-05, gnorm=0.551, clip=0, loss_scale=8, train_wall=130, gb_free=8.3, wall=20749
2022-03-25 05:04:55 - progress_bar.py[line:272] - INFO: epoch 003:    189 / 518 loss=0.184, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=126.9, ups=0.06, wpb=2048, bsz=1024, num_updates=1220, lr=1.29227e-05, gnorm=0.579, clip=0, loss_scale=8, train_wall=131, gb_free=8.4, wall=20910
2022-03-25 05:07:35 - progress_bar.py[line:272] - INFO: epoch 003:    199 / 518 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=2046.2, nsentences=1023.1, sample_size=2046.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=128, ups=0.06, wpb=2046.2, bsz=1023.1, num_updates=1230, lr=1.28542e-05, gnorm=0.569, clip=0, loss_scale=8, train_wall=129, gb_free=8.2, wall=21070
2022-03-25 05:10:15 - progress_bar.py[line:272] - INFO: epoch 003:    209 / 518 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=1240, lr=1.27858e-05, gnorm=0.507, clip=0, loss_scale=8, train_wall=130, gb_free=8.3, wall=21230
2022-03-25 05:12:55 - progress_bar.py[line:272] - INFO: epoch 003:    219 / 518 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=1250, lr=1.27173e-05, gnorm=0.615, clip=0, loss_scale=8, train_wall=130, gb_free=8.5, wall=21390
2022-03-25 05:15:35 - progress_bar.py[line:272] - INFO: epoch 003:    229 / 518 loss=0.185, loss_v1=0, loss_v2=0, nll_loss=0.185, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=128.5, ups=0.06, wpb=2048, bsz=1024, num_updates=1260, lr=1.26489e-05, gnorm=0.596, clip=0, loss_scale=8, train_wall=129, gb_free=7.8, wall=21550
2022-03-25 05:18:14 - progress_bar.py[line:272] - INFO: epoch 003:    239 / 518 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=128.7, ups=0.06, wpb=2048, bsz=1024, num_updates=1270, lr=1.25804e-05, gnorm=0.492, clip=0, loss_scale=8, train_wall=129, gb_free=8, wall=21709
2022-03-25 05:20:54 - progress_bar.py[line:272] - INFO: epoch 003:    249 / 518 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128.2, ups=0.06, wpb=2048, bsz=1024, num_updates=1280, lr=1.2512e-05, gnorm=0.546, clip=0, loss_scale=8, train_wall=129, gb_free=7.2, wall=21869
2022-03-25 05:23:33 - progress_bar.py[line:272] - INFO: epoch 003:    259 / 518 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128.1, ups=0.06, wpb=2048, bsz=1024, num_updates=1290, lr=1.24435e-05, gnorm=0.545, clip=0, loss_scale=8, train_wall=129, gb_free=8.1, wall=22029
2022-03-25 05:26:14 - progress_bar.py[line:272] - INFO: epoch 003:    269 / 518 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=1300, lr=1.23751e-05, gnorm=0.514, clip=0, loss_scale=8, train_wall=130, gb_free=8.1, wall=22189
2022-03-25 05:28:54 - progress_bar.py[line:272] - INFO: epoch 003:    279 / 518 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=128.1, ups=0.06, wpb=2048, bsz=1024, num_updates=1310, lr=1.23066e-05, gnorm=0.453, clip=0, loss_scale=8, train_wall=129, gb_free=7.3, wall=22349
2022-03-25 05:31:33 - progress_bar.py[line:272] - INFO: epoch 003:    289 / 518 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128.3, ups=0.06, wpb=2048, bsz=1024, num_updates=1320, lr=1.22382e-05, gnorm=0.535, clip=0, loss_scale=8, train_wall=129, gb_free=8.2, wall=22508
2022-03-25 05:34:13 - progress_bar.py[line:272] - INFO: epoch 003:    299 / 518 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=128.3, ups=0.06, wpb=2048, bsz=1024, num_updates=1330, lr=1.21697e-05, gnorm=0.555, clip=0, loss_scale=8, train_wall=129, gb_free=8, wall=22668
2022-03-25 05:36:53 - progress_bar.py[line:272] - INFO: epoch 003:    309 / 518 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.6, ups=0.06, wpb=2048, bsz=1024, num_updates=1340, lr=1.21013e-05, gnorm=0.524, clip=0, loss_scale=8, train_wall=129, gb_free=8, wall=22829
2022-03-25 05:39:35 - progress_bar.py[line:272] - INFO: epoch 003:    319 / 518 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127, ups=0.06, wpb=2048, bsz=1024, num_updates=1350, lr=1.20329e-05, gnorm=0.487, clip=0, loss_scale=8, train_wall=130, gb_free=7.4, wall=22990
2022-03-25 05:42:14 - progress_bar.py[line:272] - INFO: epoch 003:    329 / 518 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128.1, ups=0.06, wpb=2048, bsz=1024, num_updates=1360, lr=1.19644e-05, gnorm=0.522, clip=0, loss_scale=8, train_wall=129, gb_free=8.1, wall=23150
2022-03-25 05:44:55 - progress_bar.py[line:272] - INFO: epoch 003:    339 / 518 loss=0.182, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.7, ups=0.06, wpb=2048, bsz=1024, num_updates=1370, lr=1.1896e-05, gnorm=0.549, clip=0, loss_scale=8, train_wall=129, gb_free=8.4, wall=23310
2022-03-25 05:47:35 - progress_bar.py[line:272] - INFO: epoch 003:    349 / 518 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=1380, lr=1.18275e-05, gnorm=0.56, clip=10, loss_scale=8, train_wall=130, gb_free=8, wall=23471
2022-03-25 05:50:16 - progress_bar.py[line:272] - INFO: epoch 003:    359 / 518 loss=0.188, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=127.6, ups=0.06, wpb=2048, bsz=1024, num_updates=1390, lr=1.17591e-05, gnorm=0.579, clip=0, loss_scale=8, train_wall=130, gb_free=8.2, wall=23631
2022-03-25 05:52:56 - progress_bar.py[line:272] - INFO: epoch 003:    369 / 518 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.7, ups=0.06, wpb=2048, bsz=1024, num_updates=1400, lr=1.16906e-05, gnorm=0.51, clip=0, loss_scale=8, train_wall=130, gb_free=8.4, wall=23791
2022-03-25 05:55:38 - progress_bar.py[line:272] - INFO: epoch 003:    379 / 518 loss=0.18, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=126.8, ups=0.06, wpb=2048, bsz=1024, num_updates=1410, lr=1.16222e-05, gnorm=0.526, clip=0, loss_scale=8, train_wall=131, gb_free=8.1, wall=23953
2022-03-25 05:58:18 - progress_bar.py[line:272] - INFO: epoch 003:    389 / 518 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.6, ups=0.06, wpb=2048, bsz=1024, num_updates=1420, lr=1.15537e-05, gnorm=0.493, clip=0, loss_scale=8, train_wall=130, gb_free=8.6, wall=24113
2022-03-25 06:00:58 - progress_bar.py[line:272] - INFO: epoch 003:    399 / 518 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=1430, lr=1.14853e-05, gnorm=0.492, clip=0, loss_scale=8, train_wall=130, gb_free=8.2, wall=24273
2022-03-25 06:03:39 - progress_bar.py[line:272] - INFO: epoch 003:    409 / 518 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.7, ups=0.06, wpb=2048, bsz=1024, num_updates=1440, lr=1.14168e-05, gnorm=0.496, clip=0, loss_scale=8, train_wall=130, gb_free=8, wall=24434
2022-03-25 06:06:18 - progress_bar.py[line:272] - INFO: epoch 003:    419 / 518 loss=0.176, loss_v1=0, loss_v2=0, nll_loss=0.176, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=128.2, ups=0.06, wpb=2048, bsz=1024, num_updates=1450, lr=1.13484e-05, gnorm=0.536, clip=0, loss_scale=8, train_wall=130, gb_free=8.4, wall=24594
2022-03-25 06:08:58 - progress_bar.py[line:272] - INFO: epoch 003:    429 / 518 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=128.3, ups=0.06, wpb=2048, bsz=1024, num_updates=1460, lr=1.12799e-05, gnorm=0.526, clip=0, loss_scale=8, train_wall=130, gb_free=8, wall=24753
2022-03-25 06:11:38 - progress_bar.py[line:272] - INFO: epoch 003:    439 / 518 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=1470, lr=1.12115e-05, gnorm=0.5, clip=0, loss_scale=8, train_wall=130, gb_free=8.3, wall=24914
2022-03-25 06:14:18 - progress_bar.py[line:272] - INFO: epoch 003:    449 / 518 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=128.2, ups=0.06, wpb=2048, bsz=1024, num_updates=1480, lr=1.11431e-05, gnorm=0.537, clip=0, loss_scale=8, train_wall=129, gb_free=8.3, wall=25073
2022-03-25 06:16:58 - progress_bar.py[line:272] - INFO: epoch 003:    459 / 518 loss=0.174, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=1490, lr=1.10746e-05, gnorm=0.57, clip=0, loss_scale=8, train_wall=130, gb_free=8.4, wall=25234
2022-03-25 06:19:39 - progress_bar.py[line:272] - INFO: epoch 003:    469 / 518 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=1500, lr=1.10062e-05, gnorm=0.532, clip=0, loss_scale=8, train_wall=129, gb_free=8.2, wall=25394
slice_id 2 seek offset 8930
slice_id 3 seek offset 13394
slice_id 1 seek offset 4465
2022-03-25 06:19:39 - train.py[line:435] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 3 seek offset 13394
slice_id 2 seek offset 8930
slice_id 1 seek offset 4465
2022-03-25 06:23:52 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 0.173 | loss_v1 0 | loss_v2 0 | nll_loss 0.173 | ntokens 63.893 | nsentences 31.946 | sample_size 63.893 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.13 | snli_score 0.874 | wps 140.9 | wpb 63.9 | bsz 31.9 | num_updates 1500 | best_snli_score 0.874
2022-03-25 06:23:52 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 1500 updates
2022-03-25 06:23:52 - trainer.py[line:432] - INFO: Saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint_3_1500.pt
2022-03-25 06:24:02 - trainer.py[line:442] - INFO: Finished saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint_3_1500.pt
2022-03-25 06:24:17 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./dyn_scale_checkpoints/6_2e-5/checkpoint_3_1500.pt (epoch 3 @ 1500 updates, score 0.874) (writing took 24.795608827960677 seconds)
2022-03-25 06:26:58 - progress_bar.py[line:272] - INFO: epoch 003:    479 / 518 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=46.6, ups=0.02, wpb=2048, bsz=1024, num_updates=1510, lr=1.09377e-05, gnorm=0.465, clip=0, loss_scale=16, train_wall=129, gb_free=8.1, wall=25833
2022-03-25 06:29:39 - progress_bar.py[line:272] - INFO: epoch 003:    489 / 518 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.2, ups=0.06, wpb=2048, bsz=1024, num_updates=1520, lr=1.08693e-05, gnorm=0.478, clip=0, loss_scale=16, train_wall=130, gb_free=7.8, wall=25994
2022-03-25 06:32:20 - progress_bar.py[line:272] - INFO: epoch 003:    499 / 518 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.3, ups=0.06, wpb=2048, bsz=1024, num_updates=1530, lr=1.08008e-05, gnorm=0.5, clip=0, loss_scale=16, train_wall=130, gb_free=8, wall=26155
2022-03-25 06:35:01 - progress_bar.py[line:272] - INFO: epoch 003:    509 / 518 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127, ups=0.06, wpb=2048, bsz=1024, num_updates=1540, lr=1.07324e-05, gnorm=0.496, clip=0, loss_scale=16, train_wall=131, gb_free=8.1, wall=26316
slice_id 2 seek offset 8930slice_id 3 seek offset 13394

slice_id 1 seek offset 44652022-03-25 06:37:11 - train.py[line:435] - INFO: begin validation on "valid" subset

slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 3 seek offset 13394
slice_id 2 seek offset 8930
slice_id 1 seek offset 4465
2022-03-25 06:41:25 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 0.176 | loss_v1 0 | loss_v2 0 | nll_loss 0.176 | ntokens 63.893 | nsentences 31.946 | sample_size 63.893 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.13 | snli_score 0.8712 | wps 140.8 | wpb 63.9 | bsz 31.9 | num_updates 1549 | best_snli_score 0.874
2022-03-25 06:41:25 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 1549 updates
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
2022-03-25 06:41:25 - trainer.py[line:432] - INFO: Saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint3.pt
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
2022-03-25 06:41:34 - trainer.py[line:442] - INFO: Finished saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint3.pt
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 row count 132382 total row count 529527
slice_id 1 seek offset 132382
2022-03-25 06:41:41 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./dyn_scale_checkpoints/6_2e-5/checkpoint3.pt (epoch 3 @ 1549 updates, score 0.8712) (writing took 16.50669253000524 seconds)
2022-03-25 06:41:41 - train.py[line:322] - INFO: end of epoch 3 (average epoch stats below)
2022-03-25 06:41:41 - progress_bar.py[line:282] - INFO: epoch 003 | loss 0.176 | loss_v1 0 | loss_v2 0 | nll_loss 0.176 | ntokens 2044.51 | nsentences 1022.25 | sample_size 2044.51 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.13 | wps 119.6 | ups 0.06 | wpb 2044.5 | bsz 1022.3 | num_updates 1549 | lr 1.06708e-05 | gnorm 0.523 | clip 0.4 | loss_scale 16 | train_wall 6708 | gb_free 8.2 | wall 26717
2022-03-25 06:41:41 - trainer.py[line:640] - INFO: loading train data for epoch 4
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping

file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 row count 132382 total row count 529527file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 row count 132381 total row count 529527

slice_id 2 seek offset 264764
slice_id 3 seek offset 397146
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 row count 132382 total row count 529527
slice_id 0 seek offset 0
2022-03-25 06:41:58 - trainer.py[line:704] - INFO: begin training epoch 4
2022-03-25 06:41:58 - train.py[line:295] - INFO: Start iterating over samples
2022-03-25 06:42:16 - progress_bar.py[line:272] - INFO: epoch 004:      1 / 518 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=1868.8, nsentences=934.4, sample_size=1868.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=43, ups=0.02, wpb=1868.8, bsz=934.4, num_updates=1550, lr=1.06639e-05, gnorm=0.559, clip=10, loss_scale=16, train_wall=118, gb_free=8.4, wall=26751
2022-03-25 06:44:55 - progress_bar.py[line:272] - INFO: epoch 004:     11 / 518 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=128.3, ups=0.06, wpb=2048, bsz=1024, num_updates=1560, lr=1.05955e-05, gnorm=0.506, clip=0, loss_scale=16, train_wall=129, gb_free=8.3, wall=26910
2022-03-25 06:47:35 - progress_bar.py[line:272] - INFO: epoch 004:     21 / 518 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=1570, lr=1.0527e-05, gnorm=0.456, clip=0, loss_scale=16, train_wall=130, gb_free=8.4, wall=27070
2022-03-25 06:50:16 - progress_bar.py[line:272] - INFO: epoch 004:     31 / 518 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=1580, lr=1.04586e-05, gnorm=0.481, clip=0, loss_scale=16, train_wall=131, gb_free=8.2, wall=27231
2022-03-25 06:52:56 - progress_bar.py[line:272] - INFO: epoch 004:     41 / 518 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=1590, lr=1.03901e-05, gnorm=0.498, clip=0, loss_scale=16, train_wall=130, gb_free=8.3, wall=27391
2022-03-25 06:55:35 - progress_bar.py[line:272] - INFO: epoch 004:     51 / 518 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128.3, ups=0.06, wpb=2048, bsz=1024, num_updates=1600, lr=1.03217e-05, gnorm=0.491, clip=0, loss_scale=16, train_wall=130, gb_free=8, wall=27551
2022-03-25 06:58:16 - progress_bar.py[line:272] - INFO: epoch 004:     61 / 518 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.7, ups=0.06, wpb=2048, bsz=1024, num_updates=1610, lr=1.02533e-05, gnorm=0.502, clip=0, loss_scale=16, train_wall=130, gb_free=8.4, wall=27711
2022-03-25 07:00:57 - progress_bar.py[line:272] - INFO: epoch 004:     71 / 518 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.3, ups=0.06, wpb=2048, bsz=1024, num_updates=1620, lr=1.01848e-05, gnorm=0.489, clip=0, loss_scale=16, train_wall=131, gb_free=8.2, wall=27872
2022-03-25 07:03:37 - progress_bar.py[line:272] - INFO: epoch 004:     81 / 518 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.6, ups=0.06, wpb=2048, bsz=1024, num_updates=1630, lr=1.01164e-05, gnorm=0.497, clip=0, loss_scale=16, train_wall=130, gb_free=7.5, wall=28033
2022-03-25 07:06:19 - progress_bar.py[line:272] - INFO: epoch 004:     91 / 518 loss=0.178, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=126.2, ups=0.06, wpb=2048, bsz=1024, num_updates=1640, lr=1.00479e-05, gnorm=0.509, clip=0, loss_scale=16, train_wall=132, gb_free=8.2, wall=28195
2022-03-25 07:09:00 - progress_bar.py[line:272] - INFO: epoch 004:    101 / 518 loss=0.179, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.4, ups=0.06, wpb=2048, bsz=1024, num_updates=1650, lr=9.97947e-06, gnorm=0.493, clip=0, loss_scale=16, train_wall=130, gb_free=8, wall=28356
2022-03-25 07:11:41 - progress_bar.py[line:272] - INFO: epoch 004:    111 / 518 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=1660, lr=9.91102e-06, gnorm=0.479, clip=0, loss_scale=16, train_wall=130, gb_free=8.2, wall=28516
2022-03-25 07:14:22 - progress_bar.py[line:272] - INFO: epoch 004:    121 / 518 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=1670, lr=9.84257e-06, gnorm=0.555, clip=0, loss_scale=16, train_wall=130, gb_free=8.3, wall=28677
2022-03-25 07:17:02 - progress_bar.py[line:272] - INFO: epoch 004:    131 / 518 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=1680, lr=9.77413e-06, gnorm=0.526, clip=0, loss_scale=16, train_wall=129, gb_free=8.1, wall=28837
2022-03-25 07:19:42 - progress_bar.py[line:272] - INFO: epoch 004:    141 / 518 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.4, ups=0.06, wpb=2048, bsz=1024, num_updates=1690, lr=9.70568e-06, gnorm=0.501, clip=0, loss_scale=16, train_wall=130, gb_free=8.3, wall=28998
2022-03-25 07:22:23 - progress_bar.py[line:272] - INFO: epoch 004:    151 / 518 loss=0.177, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=1700, lr=9.63723e-06, gnorm=0.547, clip=0, loss_scale=16, train_wall=129, gb_free=8.2, wall=29158
2022-03-25 07:25:02 - progress_bar.py[line:272] - INFO: epoch 004:    161 / 518 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=128.3, ups=0.06, wpb=2048, bsz=1024, num_updates=1710, lr=9.56879e-06, gnorm=0.482, clip=0, loss_scale=16, train_wall=129, gb_free=8.2, wall=29317
2022-03-25 07:27:43 - progress_bar.py[line:272] - INFO: epoch 004:    171 / 518 loss=0.173, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.3, ups=0.06, wpb=2048, bsz=1024, num_updates=1720, lr=9.50034e-06, gnorm=0.482, clip=0, loss_scale=16, train_wall=129, gb_free=8.5, wall=29478
2022-03-25 07:30:24 - progress_bar.py[line:272] - INFO: epoch 004:    181 / 518 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=1730, lr=9.4319e-06, gnorm=0.519, clip=0, loss_scale=16, train_wall=130, gb_free=8.3, wall=29639
2022-03-25 07:33:04 - progress_bar.py[line:272] - INFO: epoch 004:    191 / 518 loss=0.171, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=1740, lr=9.36345e-06, gnorm=0.568, clip=0, loss_scale=16, train_wall=130, gb_free=8.2, wall=29799
2022-03-25 07:35:44 - progress_bar.py[line:272] - INFO: epoch 004:    201 / 518 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.6, ups=0.06, wpb=2048, bsz=1024, num_updates=1750, lr=9.295e-06, gnorm=0.47, clip=0, loss_scale=16, train_wall=130, gb_free=8.2, wall=29960
2022-03-25 07:38:24 - progress_bar.py[line:272] - INFO: epoch 004:    211 / 518 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128.3, ups=0.06, wpb=2048, bsz=1024, num_updates=1760, lr=9.22656e-06, gnorm=0.471, clip=0, loss_scale=16, train_wall=130, gb_free=8.3, wall=30119
2022-03-25 07:41:03 - progress_bar.py[line:272] - INFO: epoch 004:    221 / 518 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128.6, ups=0.06, wpb=2048, bsz=1024, num_updates=1770, lr=9.15811e-06, gnorm=0.531, clip=0, loss_scale=16, train_wall=129, gb_free=8.1, wall=30278
2022-03-25 07:43:43 - progress_bar.py[line:272] - INFO: epoch 004:    231 / 518 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=1780, lr=9.08966e-06, gnorm=0.512, clip=0, loss_scale=16, train_wall=130, gb_free=8.2, wall=30439
2022-03-25 07:46:23 - progress_bar.py[line:272] - INFO: epoch 004:    241 / 518 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128.5, ups=0.06, wpb=2048, bsz=1024, num_updates=1790, lr=9.02122e-06, gnorm=0.463, clip=0, loss_scale=16, train_wall=130, gb_free=8.6, wall=30598
2022-03-25 07:49:02 - progress_bar.py[line:272] - INFO: epoch 004:    251 / 518 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=128.2, ups=0.06, wpb=2048, bsz=1024, num_updates=1800, lr=8.95277e-06, gnorm=0.533, clip=0, loss_scale=16, train_wall=129, gb_free=8.2, wall=30758
2022-03-25 07:51:42 - progress_bar.py[line:272] - INFO: epoch 004:    261 / 518 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=128.4, ups=0.06, wpb=2048, bsz=1024, num_updates=1810, lr=8.88433e-06, gnorm=0.507, clip=0, loss_scale=16, train_wall=129, gb_free=8.3, wall=30917
2022-03-25 07:54:22 - progress_bar.py[line:272] - INFO: epoch 004:    271 / 518 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=1820, lr=8.81588e-06, gnorm=0.473, clip=0, loss_scale=16, train_wall=130, gb_free=8.1, wall=31077
2022-03-25 07:57:02 - progress_bar.py[line:272] - INFO: epoch 004:    281 / 518 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=1830, lr=8.74743e-06, gnorm=0.463, clip=0, loss_scale=16, train_wall=129, gb_free=8.2, wall=31237
2022-03-25 07:59:42 - progress_bar.py[line:272] - INFO: epoch 004:    291 / 518 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=1840, lr=8.67899e-06, gnorm=0.544, clip=0, loss_scale=16, train_wall=130, gb_free=8.3, wall=31398
2022-03-25 08:02:22 - progress_bar.py[line:272] - INFO: epoch 004:    301 / 518 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=1850, lr=8.61054e-06, gnorm=0.507, clip=0, loss_scale=16, train_wall=130, gb_free=7.9, wall=31558
2022-03-25 08:05:02 - progress_bar.py[line:272] - INFO: epoch 004:    311 / 518 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=1860, lr=8.54209e-06, gnorm=0.524, clip=0, loss_scale=16, train_wall=129, gb_free=8.3, wall=31718
2022-03-25 08:07:43 - progress_bar.py[line:272] - INFO: epoch 004:    321 / 518 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.2, ups=0.06, wpb=2048, bsz=1024, num_updates=1870, lr=8.47365e-06, gnorm=0.539, clip=0, loss_scale=16, train_wall=131, gb_free=8.4, wall=31879
2022-03-25 08:10:24 - progress_bar.py[line:272] - INFO: epoch 004:    331 / 518 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=1880, lr=8.4052e-06, gnorm=0.513, clip=0, loss_scale=16, train_wall=130, gb_free=8.2, wall=32039
2022-03-25 08:13:04 - progress_bar.py[line:272] - INFO: epoch 004:    341 / 518 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.7, ups=0.06, wpb=2048, bsz=1024, num_updates=1890, lr=8.33676e-06, gnorm=0.497, clip=0, loss_scale=16, train_wall=130, gb_free=7.9, wall=32199
2022-03-25 08:15:44 - progress_bar.py[line:272] - INFO: epoch 004:    351 / 518 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=1900, lr=8.26831e-06, gnorm=0.548, clip=0, loss_scale=16, train_wall=130, gb_free=8.3, wall=32359
2022-03-25 08:18:24 - progress_bar.py[line:272] - INFO: epoch 004:    361 / 518 loss=0.181, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.7, ups=0.06, wpb=2048, bsz=1024, num_updates=1910, lr=8.19986e-06, gnorm=0.542, clip=0, loss_scale=16, train_wall=130, gb_free=8.5, wall=32520
2022-03-25 08:21:05 - progress_bar.py[line:272] - INFO: epoch 004:    371 / 518 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=2046.2, nsentences=1023.1, sample_size=2046.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.4, ups=0.06, wpb=2046.2, bsz=1023.1, num_updates=1920, lr=8.13142e-06, gnorm=0.495, clip=0, loss_scale=16, train_wall=131, gb_free=8.2, wall=32680
2022-03-25 08:23:46 - progress_bar.py[line:272] - INFO: epoch 004:    381 / 518 loss=0.17, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.6, ups=0.06, wpb=2048, bsz=1024, num_updates=1930, lr=8.06297e-06, gnorm=0.508, clip=0, loss_scale=16, train_wall=131, gb_free=8.1, wall=32841
2022-03-25 08:26:26 - progress_bar.py[line:272] - INFO: epoch 004:    391 / 518 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=1940, lr=7.99452e-06, gnorm=0.484, clip=0, loss_scale=16, train_wall=130, gb_free=8.5, wall=33001
2022-03-25 08:29:06 - progress_bar.py[line:272] - INFO: epoch 004:    401 / 518 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128.3, ups=0.06, wpb=2048, bsz=1024, num_updates=1950, lr=7.92608e-06, gnorm=0.483, clip=0, loss_scale=16, train_wall=130, gb_free=8.4, wall=33161
2022-03-25 08:31:46 - progress_bar.py[line:272] - INFO: epoch 004:    411 / 518 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=1960, lr=7.85763e-06, gnorm=0.511, clip=0, loss_scale=16, train_wall=130, gb_free=8.3, wall=33321
2022-03-25 08:34:25 - progress_bar.py[line:272] - INFO: epoch 004:    421 / 518 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128.5, ups=0.06, wpb=2048, bsz=1024, num_updates=1970, lr=7.78919e-06, gnorm=0.528, clip=0, loss_scale=16, train_wall=129, gb_free=8.1, wall=33481
2022-03-25 08:37:05 - progress_bar.py[line:272] - INFO: epoch 004:    431 / 518 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128.1, ups=0.06, wpb=2048, bsz=1024, num_updates=1980, lr=7.72074e-06, gnorm=0.489, clip=0, loss_scale=16, train_wall=130, gb_free=8.1, wall=33640
2022-03-25 08:39:45 - progress_bar.py[line:272] - INFO: epoch 004:    441 / 518 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=1990, lr=7.65229e-06, gnorm=0.509, clip=0, loss_scale=16, train_wall=130, gb_free=8.2, wall=33800
2022-03-25 08:42:25 - progress_bar.py[line:272] - INFO: epoch 004:    451 / 518 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128.1, ups=0.06, wpb=2048, bsz=1024, num_updates=2000, lr=7.58385e-06, gnorm=0.565, clip=0, loss_scale=16, train_wall=130, gb_free=8.2, wall=33960
slice_id 2 seek offset 8930
slice_id 3 seek offset 13394
slice_id 1 seek offset 4465
2022-03-25 08:42:25 - train.py[line:435] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 3 seek offset 13394
slice_id 2 seek offset 8930
slice_id 1 seek offset 4465
2022-03-25 08:46:43 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 0.171 | loss_v1 0 | loss_v2 0 | nll_loss 0.171 | ntokens 63.893 | nsentences 31.946 | sample_size 63.893 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.13 | snli_score 0.8762 | wps 138.5 | wpb 63.9 | bsz 31.9 | num_updates 2000 | best_snli_score 0.8762
2022-03-25 08:46:43 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 2000 updates
2022-03-25 08:46:43 - trainer.py[line:432] - INFO: Saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint_4_2000.pt
2022-03-25 08:46:53 - trainer.py[line:442] - INFO: Finished saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint_4_2000.pt
2022-03-25 08:47:07 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./dyn_scale_checkpoints/6_2e-5/checkpoint_4_2000.pt (epoch 4 @ 2000 updates, score 0.8762) (writing took 24.19788673496805 seconds)
2022-03-25 08:49:15 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-25 08:50:03 - progress_bar.py[line:272] - INFO: epoch 004:    462 / 518 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=44.7, ups=0.02, wpb=2048, bsz=1024, num_updates=2010, lr=7.5154e-06, gnorm=0.538, clip=0, loss_scale=8, train_wall=142, gb_free=7.8, wall=34419
2022-03-25 08:52:44 - progress_bar.py[line:272] - INFO: epoch 004:    472 / 518 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=2020, lr=7.44695e-06, gnorm=0.499, clip=0, loss_scale=8, train_wall=130, gb_free=7, wall=34579
2022-03-25 08:55:24 - progress_bar.py[line:272] - INFO: epoch 004:    482 / 518 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=2030, lr=7.37851e-06, gnorm=0.499, clip=0, loss_scale=8, train_wall=130, gb_free=8.4, wall=34739
2022-03-25 08:58:04 - progress_bar.py[line:272] - INFO: epoch 004:    492 / 518 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=2040, lr=7.31006e-06, gnorm=0.491, clip=0, loss_scale=8, train_wall=130, gb_free=8, wall=34899
2022-03-25 09:00:44 - progress_bar.py[line:272] - INFO: epoch 004:    502 / 518 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=2050, lr=7.24162e-06, gnorm=0.538, clip=0, loss_scale=8, train_wall=130, gb_free=8, wall=35060
2022-03-25 09:03:25 - progress_bar.py[line:272] - INFO: epoch 004:    512 / 518 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=2060, lr=7.17317e-06, gnorm=0.48, clip=0, loss_scale=8, train_wall=131, gb_free=8.2, wall=35220
slice_id 1 seek offset 4465
slice_id 2 seek offset 8930
2022-03-25 09:04:47 - train.py[line:435] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 3 seek offset 13394
slice_id 0 seek offset 0
slice_id 2 seek offset 8930
slice_id 3 seek offset 13394
slice_id 1 seek offset 4465
2022-03-25 09:09:00 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 0.173 | loss_v1 0 | loss_v2 0 | nll_loss 0.173 | ntokens 63.893 | nsentences 31.946 | sample_size 63.893 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.13 | snli_score 0.8749 | wps 141.5 | wpb 63.9 | bsz 31.9 | num_updates 2066 | best_snli_score 0.8762
2022-03-25 09:09:00 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 2066 updates
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
2022-03-25 09:09:00 - trainer.py[line:432] - INFO: Saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint4.pt
2022-03-25 09:09:09 - trainer.py[line:442] - INFO: Finished saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint4.pt
2022-03-25 09:09:16 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./dyn_scale_checkpoints/6_2e-5/checkpoint4.pt (epoch 4 @ 2066 updates, score 0.8749) (writing took 16.752502497984096 seconds)
2022-03-25 09:09:16 - train.py[line:322] - INFO: end of epoch 4 (average epoch stats below)
2022-03-25 09:09:16 - progress_bar.py[line:282] - INFO: epoch 004 | loss 0.165 | loss_v1 0 | loss_v2 0 | nll_loss 0.165 | ntokens 2044.5 | nsentences 1022.25 | sample_size 2044.5 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.12 | wps 119.4 | ups 0.06 | wpb 2044.5 | bsz 1022.2 | num_updates 2066 | lr 7.1321e-06 | gnorm 0.508 | clip 0.2 | loss_scale 8 | train_wall 6718 | gb_free 8.2 | wall 35572
2022-03-25 09:09:16 - trainer.py[line:640] - INFO: loading train data for epoch 5
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 row count 132382 total row count 529527
slice_id 1 seek offset 132382
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping

file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 row count 132381 total row count 529527
file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 row count 132382 total row count 529527
slice_id 3 seek offset 397146
slice_id 2 seek offset 264764
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 row count 132382 total row count 529527
slice_id 0 seek offset 0
2022-03-25 09:09:34 - trainer.py[line:704] - INFO: begin training epoch 5
2022-03-25 09:09:34 - train.py[line:295] - INFO: Start iterating over samples
2022-03-25 09:10:39 - progress_bar.py[line:272] - INFO: epoch 005:      4 / 518 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=1868.8, nsentences=934.4, sample_size=1868.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=43, ups=0.02, wpb=1868.8, bsz=934.4, num_updates=2070, lr=7.10472e-06, gnorm=0.598, clip=10, loss_scale=8, train_wall=118, gb_free=8.1, wall=35655
2022-03-25 09:13:20 - progress_bar.py[line:272] - INFO: epoch 005:     14 / 518 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=2080, lr=7.03628e-06, gnorm=0.497, clip=0, loss_scale=8, train_wall=130, gb_free=8.4, wall=35815
2022-03-25 09:16:00 - progress_bar.py[line:272] - INFO: epoch 005:     24 / 518 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=2090, lr=6.96783e-06, gnorm=0.494, clip=0, loss_scale=8, train_wall=130, gb_free=8.4, wall=35975
2022-03-25 09:18:40 - progress_bar.py[line:272] - INFO: epoch 005:     34 / 518 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128.1, ups=0.06, wpb=2048, bsz=1024, num_updates=2100, lr=6.89938e-06, gnorm=0.524, clip=0, loss_scale=8, train_wall=130, gb_free=8.1, wall=36135
2022-03-25 09:21:20 - progress_bar.py[line:272] - INFO: epoch 005:     44 / 518 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=2110, lr=6.83094e-06, gnorm=0.479, clip=0, loss_scale=8, train_wall=130, gb_free=8.3, wall=36295
2022-03-25 09:24:00 - progress_bar.py[line:272] - INFO: epoch 005:     54 / 518 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.7, ups=0.06, wpb=2048, bsz=1024, num_updates=2120, lr=6.76249e-06, gnorm=0.486, clip=0, loss_scale=8, train_wall=130, gb_free=8, wall=36455
2022-03-25 09:26:41 - progress_bar.py[line:272] - INFO: epoch 005:     64 / 518 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=2130, lr=6.69405e-06, gnorm=0.562, clip=0, loss_scale=8, train_wall=130, gb_free=8.2, wall=36616
2022-03-25 09:29:22 - progress_bar.py[line:272] - INFO: epoch 005:     74 / 518 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.2, ups=0.06, wpb=2048, bsz=1024, num_updates=2140, lr=6.6256e-06, gnorm=0.511, clip=0, loss_scale=8, train_wall=130, gb_free=8.3, wall=36777
2022-03-25 09:32:02 - progress_bar.py[line:272] - INFO: epoch 005:     84 / 518 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.3, ups=0.06, wpb=2048, bsz=1024, num_updates=2150, lr=6.55715e-06, gnorm=0.513, clip=0, loss_scale=8, train_wall=131, gb_free=8.3, wall=36938
2022-03-25 09:34:43 - progress_bar.py[line:272] - INFO: epoch 005:     94 / 518 loss=0.172, loss_v1=0, loss_v2=0, nll_loss=0.172, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=2160, lr=6.48871e-06, gnorm=0.507, clip=0, loss_scale=8, train_wall=130, gb_free=7.9, wall=37098
2022-03-25 09:37:23 - progress_bar.py[line:272] - INFO: epoch 005:    104 / 518 loss=0.168, loss_v1=0, loss_v2=0, nll_loss=0.168, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.7, ups=0.06, wpb=2048, bsz=1024, num_updates=2170, lr=6.42026e-06, gnorm=0.505, clip=0, loss_scale=8, train_wall=130, gb_free=8.4, wall=37258
2022-03-25 09:40:03 - progress_bar.py[line:272] - INFO: epoch 005:    114 / 518 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=2180, lr=6.35181e-06, gnorm=0.505, clip=0, loss_scale=8, train_wall=130, gb_free=7.8, wall=37419
2022-03-25 09:42:44 - progress_bar.py[line:272] - INFO: epoch 005:    124 / 518 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=2190, lr=6.28337e-06, gnorm=0.553, clip=0, loss_scale=8, train_wall=129, gb_free=8.4, wall=37579
2022-03-25 09:45:23 - progress_bar.py[line:272] - INFO: epoch 005:    134 / 518 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=128.2, ups=0.06, wpb=2048, bsz=1024, num_updates=2200, lr=6.21492e-06, gnorm=0.511, clip=0, loss_scale=8, train_wall=129, gb_free=7.9, wall=37739
2022-03-25 09:48:04 - progress_bar.py[line:272] - INFO: epoch 005:    144 / 518 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.3, ups=0.06, wpb=2048, bsz=1024, num_updates=2210, lr=6.14648e-06, gnorm=0.514, clip=0, loss_scale=8, train_wall=130, gb_free=7.9, wall=37899
2022-03-25 09:50:44 - progress_bar.py[line:272] - INFO: epoch 005:    154 / 518 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=2220, lr=6.07803e-06, gnorm=0.522, clip=0, loss_scale=8, train_wall=129, gb_free=8.2, wall=38059
2022-03-25 09:53:24 - progress_bar.py[line:272] - INFO: epoch 005:    164 / 518 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128.1, ups=0.06, wpb=2048, bsz=1024, num_updates=2230, lr=6.00958e-06, gnorm=0.536, clip=0, loss_scale=8, train_wall=129, gb_free=8.4, wall=38219
2022-03-25 09:56:05 - progress_bar.py[line:272] - INFO: epoch 005:    174 / 518 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=126.9, ups=0.06, wpb=2048, bsz=1024, num_updates=2240, lr=5.94114e-06, gnorm=0.544, clip=0, loss_scale=8, train_wall=130, gb_free=8.3, wall=38381
2022-03-25 09:58:46 - progress_bar.py[line:272] - INFO: epoch 005:    184 / 518 loss=0.166, loss_v1=0, loss_v2=0, nll_loss=0.166, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.4, ups=0.06, wpb=2048, bsz=1024, num_updates=2250, lr=5.87269e-06, gnorm=0.567, clip=0, loss_scale=8, train_wall=131, gb_free=8.4, wall=38541
2022-03-25 10:01:27 - progress_bar.py[line:272] - INFO: epoch 005:    194 / 518 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.2, ups=0.06, wpb=2048, bsz=1024, num_updates=2260, lr=5.80424e-06, gnorm=0.573, clip=0, loss_scale=8, train_wall=131, gb_free=7.9, wall=38702
2022-03-25 10:04:07 - progress_bar.py[line:272] - INFO: epoch 005:    204 / 518 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=2270, lr=5.7358e-06, gnorm=0.513, clip=0, loss_scale=8, train_wall=130, gb_free=8.1, wall=38862
2022-03-25 10:06:48 - progress_bar.py[line:272] - INFO: epoch 005:    214 / 518 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.6, ups=0.06, wpb=2048, bsz=1024, num_updates=2280, lr=5.66735e-06, gnorm=0.515, clip=0, loss_scale=8, train_wall=130, gb_free=7.8, wall=39023
2022-03-25 10:09:27 - progress_bar.py[line:272] - INFO: epoch 005:    224 / 518 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128.4, ups=0.06, wpb=2048, bsz=1024, num_updates=2290, lr=5.5989e-06, gnorm=0.538, clip=0, loss_scale=8, train_wall=130, gb_free=8.3, wall=39182
2022-03-25 10:12:07 - progress_bar.py[line:272] - INFO: epoch 005:    234 / 518 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=2300, lr=5.53046e-06, gnorm=0.494, clip=0, loss_scale=8, train_wall=130, gb_free=8.4, wall=39342
2022-03-25 10:14:47 - progress_bar.py[line:272] - INFO: epoch 005:    244 / 518 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=2310, lr=5.46201e-06, gnorm=0.505, clip=0, loss_scale=8, train_wall=130, gb_free=8.2, wall=39503
2022-03-25 10:17:28 - progress_bar.py[line:272] - INFO: epoch 005:    254 / 518 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.4, ups=0.06, wpb=2048, bsz=1024, num_updates=2320, lr=5.39357e-06, gnorm=0.505, clip=0, loss_scale=8, train_wall=130, gb_free=7.6, wall=39663
2022-03-25 10:20:08 - progress_bar.py[line:272] - INFO: epoch 005:    264 / 518 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=128.2, ups=0.06, wpb=2048, bsz=1024, num_updates=2330, lr=5.32512e-06, gnorm=0.528, clip=0, loss_scale=8, train_wall=129, gb_free=8.3, wall=39823
2022-03-25 10:22:49 - progress_bar.py[line:272] - INFO: epoch 005:    274 / 518 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.1, ups=0.06, wpb=2048, bsz=1024, num_updates=2340, lr=5.25667e-06, gnorm=0.476, clip=0, loss_scale=8, train_wall=131, gb_free=8, wall=39984
2022-03-25 10:25:29 - progress_bar.py[line:272] - INFO: epoch 005:    284 / 518 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=2350, lr=5.18823e-06, gnorm=0.512, clip=0, loss_scale=8, train_wall=129, gb_free=8.4, wall=40144
2022-03-25 10:28:09 - progress_bar.py[line:272] - INFO: epoch 005:    294 / 518 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=2360, lr=5.11978e-06, gnorm=0.534, clip=0, loss_scale=8, train_wall=130, gb_free=7.1, wall=40304
2022-03-25 10:30:50 - progress_bar.py[line:272] - INFO: epoch 005:    304 / 518 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.7, ups=0.06, wpb=2048, bsz=1024, num_updates=2370, lr=5.05133e-06, gnorm=0.524, clip=0, loss_scale=8, train_wall=130, gb_free=8, wall=40465
2022-03-25 10:33:30 - progress_bar.py[line:272] - INFO: epoch 005:    314 / 518 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=2380, lr=4.98289e-06, gnorm=0.543, clip=0, loss_scale=8, train_wall=130, gb_free=8.2, wall=40625
2022-03-25 10:36:11 - progress_bar.py[line:272] - INFO: epoch 005:    324 / 518 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.1, ups=0.06, wpb=2048, bsz=1024, num_updates=2390, lr=4.91444e-06, gnorm=0.524, clip=0, loss_scale=8, train_wall=130, gb_free=7.8, wall=40787
2022-03-25 10:38:52 - progress_bar.py[line:272] - INFO: epoch 005:    334 / 518 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.2, ups=0.06, wpb=2048, bsz=1024, num_updates=2400, lr=4.846e-06, gnorm=0.539, clip=0, loss_scale=8, train_wall=130, gb_free=8.2, wall=40948
2022-03-25 10:41:32 - progress_bar.py[line:272] - INFO: epoch 005:    344 / 518 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=2410, lr=4.77755e-06, gnorm=0.53, clip=0, loss_scale=8, train_wall=130, gb_free=8.3, wall=41108
2022-03-25 10:44:13 - progress_bar.py[line:272] - INFO: epoch 005:    354 / 518 loss=0.169, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=2420, lr=4.7091e-06, gnorm=0.52, clip=0, loss_scale=8, train_wall=130, gb_free=7.8, wall=41268
2022-03-25 10:46:54 - progress_bar.py[line:272] - INFO: epoch 005:    364 / 518 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.4, ups=0.06, wpb=2048, bsz=1024, num_updates=2430, lr=4.64066e-06, gnorm=0.501, clip=0, loss_scale=8, train_wall=130, gb_free=8.2, wall=41429
2022-03-25 10:49:35 - progress_bar.py[line:272] - INFO: epoch 005:    374 / 518 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.4, ups=0.06, wpb=2048, bsz=1024, num_updates=2440, lr=4.57221e-06, gnorm=0.468, clip=0, loss_scale=8, train_wall=131, gb_free=8.4, wall=41590
2022-03-25 10:52:16 - progress_bar.py[line:272] - INFO: epoch 005:    384 / 518 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127, ups=0.06, wpb=2048, bsz=1024, num_updates=2450, lr=4.50376e-06, gnorm=0.506, clip=0, loss_scale=8, train_wall=131, gb_free=8.2, wall=41751
2022-03-25 10:54:56 - progress_bar.py[line:272] - INFO: epoch 005:    394 / 518 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=2460, lr=4.43532e-06, gnorm=0.523, clip=0, loss_scale=8, train_wall=130, gb_free=8.2, wall=41911
2022-03-25 10:57:36 - progress_bar.py[line:272] - INFO: epoch 005:    404 / 518 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=2470, lr=4.36687e-06, gnorm=0.493, clip=0, loss_scale=8, train_wall=130, gb_free=8.3, wall=42071
2022-03-25 11:00:17 - progress_bar.py[line:272] - INFO: epoch 005:    414 / 518 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.7, ups=0.06, wpb=2048, bsz=1024, num_updates=2480, lr=4.29843e-06, gnorm=0.477, clip=0, loss_scale=8, train_wall=131, gb_free=8.3, wall=42232
2022-03-25 11:02:56 - progress_bar.py[line:272] - INFO: epoch 005:    424 / 518 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128.2, ups=0.06, wpb=2048, bsz=1024, num_updates=2490, lr=4.22998e-06, gnorm=0.546, clip=0, loss_scale=8, train_wall=130, gb_free=8.5, wall=42392
2022-03-25 11:05:37 - progress_bar.py[line:272] - INFO: epoch 005:    434 / 518 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=2500, lr=4.16153e-06, gnorm=0.5, clip=0, loss_scale=8, train_wall=130, gb_free=8.3, wall=42552
slice_id 2 seek offset 8930
slice_id 3 seek offset 13394
slice_id 1 seek offset 4465
2022-03-25 11:05:37 - train.py[line:435] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 2 seek offset 8930
slice_id 3 seek offset 13394
slice_id 1 seek offset 4465
2022-03-25 11:09:48 - progress_bar.py[line:282] - INFO: epoch 005 | valid on 'valid' subset | loss 0.169 | loss_v1 0 | loss_v2 0 | nll_loss 0.169 | ntokens 63.893 | nsentences 31.946 | sample_size 63.893 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.12 | snli_score 0.8796 | wps 142.2 | wpb 63.9 | bsz 31.9 | num_updates 2500 | best_snli_score 0.8796
2022-03-25 11:09:48 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 2500 updates
2022-03-25 11:09:48 - trainer.py[line:432] - INFO: Saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint_5_2500.pt
2022-03-25 11:09:55 - trainer.py[line:442] - INFO: Finished saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint_5_2500.pt
2022-03-25 11:10:11 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./dyn_scale_checkpoints/6_2e-5/checkpoint_5_2500.pt (epoch 5 @ 2500 updates, score 0.8796) (writing took 22.672708173980936 seconds)
2022-03-25 11:12:51 - progress_bar.py[line:272] - INFO: epoch 005:    444 / 518 loss=0.162, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=47.1, ups=0.02, wpb=2048, bsz=1024, num_updates=2510, lr=4.09309e-06, gnorm=0.562, clip=0, loss_scale=8, train_wall=130, gb_free=8.2, wall=42986
2022-03-25 11:15:31 - progress_bar.py[line:272] - INFO: epoch 005:    454 / 518 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=128.4, ups=0.06, wpb=2048, bsz=1024, num_updates=2520, lr=4.02464e-06, gnorm=0.516, clip=0, loss_scale=16, train_wall=129, gb_free=7.8, wall=43146
2022-03-25 11:18:11 - progress_bar.py[line:272] - INFO: epoch 005:    464 / 518 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=2046.2, nsentences=1023.1, sample_size=2046.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.8, ups=0.06, wpb=2046.2, bsz=1023.1, num_updates=2530, lr=3.95619e-06, gnorm=0.5, clip=0, loss_scale=16, train_wall=130, gb_free=8, wall=43306
2022-03-25 11:20:52 - progress_bar.py[line:272] - INFO: epoch 005:    474 / 518 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.4, ups=0.06, wpb=2048, bsz=1024, num_updates=2540, lr=3.88775e-06, gnorm=0.509, clip=0, loss_scale=16, train_wall=130, gb_free=8.1, wall=43467
2022-03-25 11:23:32 - progress_bar.py[line:272] - INFO: epoch 005:    484 / 518 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=2550, lr=3.8193e-06, gnorm=0.527, clip=0, loss_scale=16, train_wall=130, gb_free=8.4, wall=43627
2022-03-25 11:26:12 - progress_bar.py[line:272] - INFO: epoch 005:    494 / 518 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=2560, lr=3.75086e-06, gnorm=0.526, clip=0, loss_scale=16, train_wall=131, gb_free=8.2, wall=43788
2022-03-25 11:28:53 - progress_bar.py[line:272] - INFO: epoch 005:    504 / 518 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.3, ups=0.06, wpb=2048, bsz=1024, num_updates=2570, lr=3.68241e-06, gnorm=0.501, clip=0, loss_scale=16, train_wall=130, gb_free=8.3, wall=43949
2022-03-25 11:31:35 - progress_bar.py[line:272] - INFO: epoch 005:    514 / 518 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=126.8, ups=0.06, wpb=2048, bsz=1024, num_updates=2580, lr=3.61396e-06, gnorm=0.513, clip=0, loss_scale=16, train_wall=131, gb_free=8.2, wall=44110
slice_id 3 seek offset 13394
slice_id 1 seek offset 4465
slice_id 2 seek offset 8930
2022-03-25 11:32:24 - train.py[line:435] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 2 seek offset 8930
slice_id 3 seek offset 13394
slice_id 1 seek offset 4465
2022-03-25 11:36:38 - progress_bar.py[line:282] - INFO: epoch 005 | valid on 'valid' subset | loss 0.171 | loss_v1 0 | loss_v2 0 | nll_loss 0.171 | ntokens 63.893 | nsentences 31.946 | sample_size 63.893 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.13 | snli_score 0.8784 | wps 141.1 | wpb 63.9 | bsz 31.9 | num_updates 2584 | best_snli_score 0.8796
2022-03-25 11:36:38 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 2584 updates
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping

2022-03-25 11:36:38 - trainer.py[line:432] - INFO: Saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint5.pt
2022-03-25 11:36:47 - trainer.py[line:442] - INFO: Finished saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint5.pt
2022-03-25 11:36:54 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./dyn_scale_checkpoints/6_2e-5/checkpoint5.pt (epoch 5 @ 2584 updates, score 0.8784) (writing took 15.853584698983468 seconds)
2022-03-25 11:36:54 - train.py[line:322] - INFO: end of epoch 5 (average epoch stats below)
2022-03-25 11:36:54 - progress_bar.py[line:282] - INFO: epoch 005 | loss 0.158 | loss_v1 0 | loss_v2 0 | nll_loss 0.158 | ntokens 2044.51 | nsentences 1022.25 | sample_size 2044.51 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.12 | wps 119.6 | ups 0.06 | wpb 2044.5 | bsz 1022.3 | num_updates 2584 | lr 3.58658e-06 | gnorm 0.518 | clip 0 | loss_scale 16 | train_wall 6721 | gb_free 8.2 | wall 44429
2022-03-25 11:36:54 - trainer.py[line:640] - INFO: loading train data for epoch 6
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 row count 132382 total row count 529527
slice_id 1 seek offset 132382
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping

file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 row count 132382 total row count 529527file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 row count 132381 total row count 529527

slice_id 2 seek offset 264764
slice_id 3 seek offset 397146
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 row count 132382 total row count 529527
slice_id 0 seek offset 0
2022-03-25 11:37:11 - trainer.py[line:704] - INFO: begin training epoch 6
2022-03-25 11:37:11 - train.py[line:295] - INFO: Start iterating over samples
2022-03-25 11:38:48 - progress_bar.py[line:272] - INFO: epoch 006:      6 / 518 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=1868.8, nsentences=934.4, sample_size=1868.8, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=43.1, ups=0.02, wpb=1868.8, bsz=934.4, num_updates=2590, lr=3.54552e-06, gnorm=0.571, clip=0, loss_scale=16, train_wall=118, gb_free=8.1, wall=44544
2022-03-25 11:41:28 - progress_bar.py[line:272] - INFO: epoch 006:     16 / 518 loss=0.154, loss_v1=0, loss_v2=0, nll_loss=0.154, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=2600, lr=3.47707e-06, gnorm=0.517, clip=0, loss_scale=16, train_wall=130, gb_free=8.4, wall=44704
2022-03-25 11:44:10 - progress_bar.py[line:272] - INFO: epoch 006:     26 / 518 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=2046.2, nsentences=1023.1, sample_size=2046.2, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=126.9, ups=0.06, wpb=2046.2, bsz=1023.1, num_updates=2610, lr=3.40862e-06, gnorm=0.499, clip=0, loss_scale=16, train_wall=131, gb_free=8.4, wall=44865
2022-03-25 11:46:50 - progress_bar.py[line:272] - INFO: epoch 006:     36 / 518 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=2620, lr=3.34018e-06, gnorm=0.527, clip=0, loss_scale=16, train_wall=130, gb_free=8.3, wall=45025
2022-03-25 11:49:31 - progress_bar.py[line:272] - INFO: epoch 006:     46 / 518 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=126.7, ups=0.06, wpb=2048, bsz=1024, num_updates=2630, lr=3.27173e-06, gnorm=0.483, clip=0, loss_scale=16, train_wall=131, gb_free=8.5, wall=45187
2022-03-25 11:52:12 - progress_bar.py[line:272] - INFO: epoch 006:     56 / 518 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.6, ups=0.06, wpb=2048, bsz=1024, num_updates=2640, lr=3.20329e-06, gnorm=0.499, clip=0, loss_scale=16, train_wall=130, gb_free=8.4, wall=45347
2022-03-25 11:54:53 - progress_bar.py[line:272] - INFO: epoch 006:     66 / 518 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.3, ups=0.06, wpb=2048, bsz=1024, num_updates=2650, lr=3.13484e-06, gnorm=0.508, clip=0, loss_scale=16, train_wall=130, gb_free=8.2, wall=45508
2022-03-25 11:57:34 - progress_bar.py[line:272] - INFO: epoch 006:     76 / 518 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.3, ups=0.06, wpb=2048, bsz=1024, num_updates=2660, lr=3.06639e-06, gnorm=0.486, clip=0, loss_scale=16, train_wall=130, gb_free=8.1, wall=45669
2022-03-25 12:00:15 - progress_bar.py[line:272] - INFO: epoch 006:     86 / 518 loss=0.164, loss_v1=0, loss_v2=0, nll_loss=0.164, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.2, ups=0.06, wpb=2048, bsz=1024, num_updates=2670, lr=2.99795e-06, gnorm=0.561, clip=0, loss_scale=16, train_wall=130, gb_free=7.9, wall=45830
2022-03-25 12:02:55 - progress_bar.py[line:272] - INFO: epoch 006:     96 / 518 loss=0.165, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.6, ups=0.06, wpb=2048, bsz=1024, num_updates=2680, lr=2.9295e-06, gnorm=0.531, clip=0, loss_scale=16, train_wall=130, gb_free=7.2, wall=45990
2022-03-25 12:05:36 - progress_bar.py[line:272] - INFO: epoch 006:    106 / 518 loss=0.167, loss_v1=0, loss_v2=0, nll_loss=0.167, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=2690, lr=2.86105e-06, gnorm=0.512, clip=0, loss_scale=16, train_wall=130, gb_free=7.8, wall=46151
2022-03-25 12:08:16 - progress_bar.py[line:272] - INFO: epoch 006:    116 / 518 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=2700, lr=2.79261e-06, gnorm=0.507, clip=0, loss_scale=16, train_wall=130, gb_free=7.9, wall=46311
2022-03-25 12:10:57 - progress_bar.py[line:272] - INFO: epoch 006:    126 / 518 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=2710, lr=2.72416e-06, gnorm=0.515, clip=0, loss_scale=16, train_wall=130, gb_free=7.7, wall=46472
2022-03-25 12:13:37 - progress_bar.py[line:272] - INFO: epoch 006:    136 / 518 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.6, ups=0.06, wpb=2048, bsz=1024, num_updates=2720, lr=2.65572e-06, gnorm=0.51, clip=0, loss_scale=16, train_wall=130, gb_free=7.9, wall=46632
2022-03-25 12:16:18 - progress_bar.py[line:272] - INFO: epoch 006:    146 / 518 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=2730, lr=2.58727e-06, gnorm=0.542, clip=0, loss_scale=16, train_wall=130, gb_free=8.4, wall=46793
2022-03-25 12:18:58 - progress_bar.py[line:272] - INFO: epoch 006:    156 / 518 loss=0.161, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=2740, lr=2.51882e-06, gnorm=0.52, clip=0, loss_scale=16, train_wall=130, gb_free=8.2, wall=46953
2022-03-25 12:21:39 - progress_bar.py[line:272] - INFO: epoch 006:    166 / 518 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.2, ups=0.06, wpb=2048, bsz=1024, num_updates=2750, lr=2.45038e-06, gnorm=0.496, clip=0, loss_scale=16, train_wall=130, gb_free=7.1, wall=47114
2022-03-25 12:24:20 - progress_bar.py[line:272] - INFO: epoch 006:    176 / 518 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.1, ups=0.06, wpb=2048, bsz=1024, num_updates=2760, lr=2.38193e-06, gnorm=0.527, clip=0, loss_scale=16, train_wall=130, gb_free=8.3, wall=47275
2022-03-25 12:27:01 - progress_bar.py[line:272] - INFO: epoch 006:    186 / 518 loss=0.16, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.1, ups=0.06, wpb=2048, bsz=1024, num_updates=2770, lr=2.31348e-06, gnorm=0.498, clip=0, loss_scale=16, train_wall=131, gb_free=8.2, wall=47436
2022-03-25 12:29:41 - progress_bar.py[line:272] - INFO: epoch 006:    196 / 518 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=2780, lr=2.24504e-06, gnorm=0.54, clip=0, loss_scale=16, train_wall=130, gb_free=8.2, wall=47596
2022-03-25 12:32:21 - progress_bar.py[line:272] - INFO: epoch 006:    206 / 518 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=128.4, ups=0.06, wpb=2048, bsz=1024, num_updates=2790, lr=2.17659e-06, gnorm=0.459, clip=0, loss_scale=16, train_wall=129, gb_free=8.2, wall=47756
2022-03-25 12:35:01 - progress_bar.py[line:272] - INFO: epoch 006:    216 / 518 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=2800, lr=2.10815e-06, gnorm=0.52, clip=0, loss_scale=16, train_wall=130, gb_free=8.1, wall=47916
2022-03-25 12:37:41 - progress_bar.py[line:272] - INFO: epoch 006:    226 / 518 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=2810, lr=2.0397e-06, gnorm=0.546, clip=0, loss_scale=16, train_wall=130, gb_free=8.2, wall=48076
2022-03-25 12:40:21 - progress_bar.py[line:272] - INFO: epoch 006:    236 / 518 loss=0.159, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=128.1, ups=0.06, wpb=2048, bsz=1024, num_updates=2820, lr=1.97125e-06, gnorm=0.543, clip=0, loss_scale=16, train_wall=130, gb_free=8.2, wall=48236
2022-03-25 12:43:00 - progress_bar.py[line:272] - INFO: epoch 006:    246 / 518 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=128.4, ups=0.06, wpb=2048, bsz=1024, num_updates=2830, lr=1.90281e-06, gnorm=0.505, clip=0, loss_scale=16, train_wall=130, gb_free=8.2, wall=48396
2022-03-25 12:43:16 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-25 12:45:56 - progress_bar.py[line:272] - INFO: epoch 006:    257 / 518 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=116.4, ups=0.06, wpb=2048, bsz=1024, num_updates=2840, lr=1.83436e-06, gnorm=0.506, clip=0, loss_scale=8, train_wall=142, gb_free=8.1, wall=48572
2022-03-25 12:48:36 - progress_bar.py[line:272] - INFO: epoch 006:    267 / 518 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=2850, lr=1.76591e-06, gnorm=0.5, clip=0, loss_scale=8, train_wall=129, gb_free=7.5, wall=48732
2022-03-25 12:51:16 - progress_bar.py[line:272] - INFO: epoch 006:    277 / 518 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=128.1, ups=0.06, wpb=2048, bsz=1024, num_updates=2860, lr=1.69747e-06, gnorm=0.487, clip=0, loss_scale=8, train_wall=129, gb_free=8, wall=48891
2022-03-25 12:53:57 - progress_bar.py[line:272] - INFO: epoch 006:    287 / 518 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=2870, lr=1.62902e-06, gnorm=0.498, clip=0, loss_scale=8, train_wall=130, gb_free=7.8, wall=49052
2022-03-25 12:56:37 - progress_bar.py[line:272] - INFO: epoch 006:    297 / 518 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.8, ups=0.06, wpb=2048, bsz=1024, num_updates=2880, lr=1.56057e-06, gnorm=0.537, clip=0, loss_scale=8, train_wall=130, gb_free=7.6, wall=49212
2022-03-25 12:59:18 - progress_bar.py[line:272] - INFO: epoch 006:    307 / 518 loss=0.152, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=2890, lr=1.49213e-06, gnorm=0.534, clip=0, loss_scale=8, train_wall=130, gb_free=8.3, wall=49373
2022-03-25 13:01:59 - progress_bar.py[line:272] - INFO: epoch 006:    317 / 518 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.1, ups=0.06, wpb=2048, bsz=1024, num_updates=2900, lr=1.42368e-06, gnorm=0.503, clip=0, loss_scale=8, train_wall=131, gb_free=8.1, wall=49534
2022-03-25 13:04:40 - progress_bar.py[line:272] - INFO: epoch 006:    327 / 518 loss=0.148, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.4, ups=0.06, wpb=2048, bsz=1024, num_updates=2910, lr=1.35524e-06, gnorm=0.486, clip=0, loss_scale=8, train_wall=130, gb_free=8.2, wall=49695
2022-03-25 13:07:20 - progress_bar.py[line:272] - INFO: epoch 006:    337 / 518 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.4, ups=0.06, wpb=2048, bsz=1024, num_updates=2920, lr=1.28679e-06, gnorm=0.511, clip=0, loss_scale=8, train_wall=130, gb_free=8, wall=49856
2022-03-25 13:10:01 - progress_bar.py[line:272] - INFO: epoch 006:    347 / 518 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.6, ups=0.06, wpb=2048, bsz=1024, num_updates=2930, lr=1.21834e-06, gnorm=0.532, clip=0, loss_scale=8, train_wall=130, gb_free=8.2, wall=50016
2022-03-25 13:12:42 - progress_bar.py[line:272] - INFO: epoch 006:    357 / 518 loss=0.163, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127, ups=0.06, wpb=2048, bsz=1024, num_updates=2940, lr=1.1499e-06, gnorm=0.559, clip=0, loss_scale=8, train_wall=130, gb_free=8, wall=50177
2022-03-25 13:15:23 - progress_bar.py[line:272] - INFO: epoch 006:    367 / 518 loss=0.158, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.3, ups=0.06, wpb=2048, bsz=1024, num_updates=2950, lr=1.08145e-06, gnorm=0.53, clip=0, loss_scale=8, train_wall=131, gb_free=8.2, wall=50338
2022-03-25 13:18:04 - progress_bar.py[line:272] - INFO: epoch 006:    377 / 518 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=127.6, ups=0.06, wpb=2048, bsz=1024, num_updates=2960, lr=1.013e-06, gnorm=0.509, clip=0, loss_scale=8, train_wall=130, gb_free=7.8, wall=50499
2022-03-25 13:20:45 - progress_bar.py[line:272] - INFO: epoch 006:    387 / 518 loss=0.156, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.2, ups=0.06, wpb=2048, bsz=1024, num_updates=2970, lr=9.44559e-07, gnorm=0.51, clip=0, loss_scale=8, train_wall=131, gb_free=8, wall=50660
2022-03-25 13:23:25 - progress_bar.py[line:272] - INFO: epoch 006:    397 / 518 loss=0.149, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=2980, lr=8.76112e-07, gnorm=0.475, clip=0, loss_scale=8, train_wall=130, gb_free=8.5, wall=50820
2022-03-25 13:26:04 - progress_bar.py[line:272] - INFO: epoch 006:    407 / 518 loss=0.155, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=128.4, ups=0.06, wpb=2048, bsz=1024, num_updates=2990, lr=8.07666e-07, gnorm=0.5, clip=0, loss_scale=8, train_wall=130, gb_free=8.2, wall=50979
2022-03-25 13:28:45 - progress_bar.py[line:272] - INFO: epoch 006:    417 / 518 loss=0.157, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.6, ups=0.06, wpb=2048, bsz=1024, num_updates=3000, lr=7.3922e-07, gnorm=0.497, clip=0, loss_scale=8, train_wall=131, gb_free=7.8, wall=51140
slice_id 2 seek offset 8930
slice_id 3 seek offset 13394
2022-03-25 13:28:45 - train.py[line:435] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0slice_id 1 seek offset 4465

slice_id 0 seek offset 0
slice_id 2 seek offset 8930
slice_id 3 seek offset 13394
slice_id 1 seek offset 4465
2022-03-25 13:33:00 - progress_bar.py[line:282] - INFO: epoch 006 | valid on 'valid' subset | loss 0.169 | loss_v1 0 | loss_v2 0 | nll_loss 0.169 | ntokens 63.893 | nsentences 31.946 | sample_size 63.893 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.12 | snli_score 0.8791 | wps 139.9 | wpb 63.9 | bsz 31.9 | num_updates 3000 | best_snli_score 0.8796
2022-03-25 13:33:00 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 3000 updates
2022-03-25 13:33:00 - trainer.py[line:432] - INFO: Saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint_6_3000.pt
2022-03-25 13:33:09 - trainer.py[line:442] - INFO: Finished saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint_6_3000.pt
2022-03-25 13:33:17 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./dyn_scale_checkpoints/6_2e-5/checkpoint_6_3000.pt (epoch 6 @ 3000 updates, score 0.8791) (writing took 16.936687670997344 seconds)
2022-03-25 13:35:57 - progress_bar.py[line:272] - INFO: epoch 006:    427 / 518 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=47.4, ups=0.02, wpb=2048, bsz=1024, num_updates=3010, lr=6.70773e-07, gnorm=0.532, clip=0, loss_scale=8, train_wall=130, gb_free=7.9, wall=51572
2022-03-25 13:38:37 - progress_bar.py[line:272] - INFO: epoch 006:    437 / 518 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=128, ups=0.06, wpb=2048, bsz=1024, num_updates=3020, lr=6.02327e-07, gnorm=0.525, clip=0, loss_scale=8, train_wall=130, gb_free=8, wall=51732
2022-03-25 13:41:17 - progress_bar.py[line:272] - INFO: epoch 006:    447 / 518 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.9, ups=0.06, wpb=2048, bsz=1024, num_updates=3030, lr=5.33881e-07, gnorm=0.501, clip=0, loss_scale=8, train_wall=130, gb_free=8.4, wall=51892
2022-03-25 13:43:56 - progress_bar.py[line:272] - INFO: epoch 006:    457 / 518 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=128.4, ups=0.06, wpb=2048, bsz=1024, num_updates=3040, lr=4.65435e-07, gnorm=0.505, clip=0, loss_scale=8, train_wall=129, gb_free=7.9, wall=52051
2022-03-25 13:44:28 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-25 13:46:52 - progress_bar.py[line:272] - INFO: epoch 006:    468 / 518 loss=0.151, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=116.1, ups=0.06, wpb=2048, bsz=1024, num_updates=3050, lr=3.96988e-07, gnorm=0.58, clip=10, loss_scale=4, train_wall=143, gb_free=8.3, wall=52228
2022-03-25 13:49:33 - progress_bar.py[line:272] - INFO: epoch 006:    478 / 518 loss=0.147, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.5, ups=0.06, wpb=2048, bsz=1024, num_updates=3060, lr=3.28542e-07, gnorm=0.517, clip=0, loss_scale=4, train_wall=130, gb_free=8.1, wall=52388
2022-03-25 13:52:13 - progress_bar.py[line:272] - INFO: epoch 006:    488 / 518 loss=0.146, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.7, ups=0.06, wpb=2048, bsz=1024, num_updates=3070, lr=2.60096e-07, gnorm=0.481, clip=0, loss_scale=4, train_wall=130, gb_free=8.1, wall=52549
2022-03-25 13:54:54 - progress_bar.py[line:272] - INFO: epoch 006:    498 / 518 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.3, ups=0.06, wpb=2048, bsz=1024, num_updates=3080, lr=1.9165e-07, gnorm=0.491, clip=0, loss_scale=4, train_wall=131, gb_free=7.8, wall=52709
2022-03-25 13:57:35 - progress_bar.py[line:272] - INFO: epoch 006:    508 / 518 loss=0.15, loss_v1=0, loss_v2=0, nll_loss=0.15, ntokens=2048, nsentences=1024, sample_size=2048, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=127.1, ups=0.06, wpb=2048, bsz=1024, num_updates=3090, lr=1.23203e-07, gnorm=0.524, clip=0, loss_scale=4, train_wall=131, gb_free=8.3, wall=52871
2022-03-25 14:00:01 - progress_bar.py[line:272] - INFO: epoch 006:    518 / 518 loss=0.153, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=1868.8, nsentences=934.4, sample_size=1868.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=128.3, ups=0.07, wpb=1868.8, bsz=934.4, num_updates=3100, lr=5.4757e-08, gnorm=0.576, clip=0, loss_scale=4, train_wall=118, gb_free=8.2, wall=53016
slice_id 1 seek offset 4465
slice_id 2 seek offset 8930
2022-03-25 14:00:01 - train.py[line:435] - INFO: begin validation on "valid" subset
slice_id 3 seek offset 13394slice_id 0 seek offset 0

slice_id 0 seek offset 0
slice_id 3 seek offset 13394
slice_id 2 seek offset 8930
slice_id 1 seek offset 4465
2022-03-25 14:04:17 - progress_bar.py[line:282] - INFO: epoch 006 | valid on 'valid' subset | loss 0.169 | loss_v1 0 | loss_v2 0 | nll_loss 0.169 | ntokens 63.893 | nsentences 31.946 | sample_size 63.893 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.12 | snli_score 0.8795 | wps 139.5 | wpb 63.9 | bsz 31.9 | num_updates 3100 | best_snli_score 0.8796
2022-03-25 14:04:17 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 3100 updates
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2022-03-25 14:04:17 - trainer.py[line:432] - INFO: Saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint6.pt
2022-03-25 14:04:26 - trainer.py[line:442] - INFO: Finished saving checkpoint to ./dyn_scale_checkpoints/6_2e-5/checkpoint6.pt
2022-03-25 14:04:34 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./dyn_scale_checkpoints/6_2e-5/checkpoint6.pt (epoch 6 @ 3100 updates, score 0.8795) (writing took 16.62622477801051 seconds)
2022-03-25 14:04:34 - train.py[line:322] - INFO: end of epoch 6 (average epoch stats below)
2022-03-25 14:04:34 - progress_bar.py[line:282] - INFO: epoch 006 | loss 0.154 | loss_v1 0 | loss_v2 0 | nll_loss 0.154 | ntokens 2044.49 | nsentences 1022.25 | sample_size 2044.49 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.11 | wps 119.1 | ups 0.06 | wpb 2044.5 | bsz 1022.2 | num_updates 3100 | lr 5.4757e-08 | gnorm 0.515 | clip 0.2 | loss_scale 4 | train_wall 6726 | gb_free 8.2 | wall 53289
2022-03-25 14:04:34 - trainer.py[line:640] - INFO: loading train data for epoch 7
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 1 row count 132382 total row count 529527
slice_id 1 seek offset 132382
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping

file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 2 row count 132382 total row count 529527file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 3 row count 132381 total row count 529527

slice_id 2 seek offset 264764
slice_id 3 seek offset 397146
local datafile ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/snli_ve_data/snli_ve_train.tsv slice_id 0 row count 132382 total row count 529527
slice_id 0 seek offset 0
2022-03-25 14:04:51 - train.py[line:204] - INFO: done training in 53280.3 seconds
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
