2022-04-25 09:41:14 - utils.py[line:255] - INFO: distributed init (rank 0): env://
2022-04-25 09:41:14 - utils.py[line:261] - INFO: Start init
2022-04-25 09:41:14 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-04-25 09:41:14 - utils.py[line:271] - INFO: initialized host heming-ng1 as rank 0
single-machine distributed training is initialized.
2022-04-25 09:41:58 - train.py[line:76] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 16, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 1000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [4], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './fairseq_checkpoints/mnli/5_1e-5_4', 'restore_file': '../../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1000, 'save_interval_updates': 1000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'acc', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_resmo', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"maybe": 0, "yes": 1, "no": 2}', arch='ofa_resmo', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=16, batch_size_valid=16, best_checkpoint_metric='acc', bf16=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../dataset/glue_data/mnli_train.tsv,../../dataset/glue_data/mnli_dev.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=16, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.0, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=5, max_source_positions=1024, max_src_length=512, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, moe_gate_loss_combine_method='average', moe_gate_loss_transform='none', moe_gate_loss_wt=1.0, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_bins=1000, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='src', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='../../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./fairseq_checkpoints/mnli/5_1e-5_4', save_interval=1000, save_interval_updates=1000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,1,2', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='mnli', tensorboard_logdir=None, threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[4], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=1000, wandb_project=None, warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'mnli', 'data': '../../dataset/glue_data/mnli_train.tsv,../../dataset/glue_data/mnli_dev.tsv', 'selected_cols': '0,1,2', 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 512, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'ans2label_dict': '{"maybe": 0, "yes": 1, "no": 2}', 'prompt_type': 'src'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.0, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None, 'moe_gate_loss_wt': 1.0, 'moe_gate_loss_combine_method': 'average', 'moe_gate_loss_transform': 'none'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [1e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-04-25 09:41:58 - ofa_task.py[line:103] - INFO: source dictionary: 59457 types
2022-04-25 09:41:58 - ofa_task.py[line:104] - INFO: target dictionary: 59457 types
2022-04-25 09:42:00 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-04-25 09:42:00 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:3 to store for rank: 0
2022-04-25 09:42:00 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:4 to store for rank: 0
2022-04-25 09:42:06 - train.py[line:100] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): FusedLayerNorm(torch.Size([3072]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (moe_layer): MOELayer(
          (gate): Top1Gate(
            (wg): Linear(in_features=768, out_features=4, bias=False)
          )
          (experts): ModuleList(
            (0): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (1): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (2): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
            (3): FeedForwardNetwork(
              (activation_dropout_module): FairseqDropout()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (dropout_module): FairseqDropout()
            )
          )
        )
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-04-25 09:42:06 - train.py[line:101] - INFO: task: MNLITask
2022-04-25 09:42:06 - train.py[line:102] - INFO: model: OFAModel
2022-04-25 09:42:06 - train.py[line:103] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-04-25 09:42:06 - train.py[line:104] - INFO: num. shared model params: 182,275,400 (num. trained: 182,275,400)
2022-04-25 09:42:06 - train.py[line:111] - INFO: num. expert model params: 226676736 (num. trained: 226676736)
local datafile ../../dataset/glue_data/mnli_dev.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/glue_data/mnli_dev.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/glue_data/mnli_dev.tsv slice_id 0 row count 19647 total row count 19647
2022-04-25 09:42:06 - trainer.py[line:110] - INFO: Debugging
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.layers.0.moe_layer.gate.wg.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.layers.1.moe_layer.gate.wg.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.layers.2.moe_layer.gate.wg.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.layers.3.moe_layer.gate.wg.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.layers.4.moe_layer.gate.wg.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.layers.5.moe_layer.gate.wg.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.layers.0.moe_layer.gate.wg.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.layers.1.moe_layer.gate.wg.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.layers.2.moe_layer.gate.wg.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.layers.3.moe_layer.gate.wg.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.layers.4.moe_layer.gate.wg.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.layers.5.moe_layer.gate.wg.bias
2022-04-25 09:42:06 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-04-25 09:42:06 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 1 workers***********************
2022-04-25 09:42:06 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2022-04-25 09:42:06 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 1 workers***********************
2022-04-25 09:42:06 - train.py[line:142] - INFO: training on 1 devices (GPUs/TPUs)
2022-04-25 09:42:06 - train.py[line:147] - INFO: max tokens per device = None and max sentences per device = 16
2022-04-25 09:42:06 - trainer.py[line:459] - INFO: Preparing to load checkpoint ../../checkpoints/ofa_base.pt
self_attn.c_attn
self_attn.k_proj.weight
self_attn.k_proj.bias
self_attn.v_proj.weight
self_attn.v_proj.bias
self_attn.q_proj.weight
self_attn.q_proj.bias
self_attn.out_proj.weight
self_attn.out_proj.bias
self_attn_layer_norm.weight
self_attn_layer_norm.bias
fc1.weight
fc1.bias
fc2.weight
fc2.bias
attn_ln.weight
attn_ln.bias
ffn_layernorm.weight
ffn_layernorm.bias
moe_layer.gate.wg.weight
moe_layer.experts.0.fc1.weight
moe_layer.experts.0.fc1.bias
moe_layer.experts.0.fc2.weight
moe_layer.experts.0.fc2.bias
moe_layer.experts.1.fc1.weight
moe_layer.experts.1.fc1.bias
moe_layer.experts.1.fc2.weight
moe_layer.experts.1.fc2.bias
moe_layer.experts.2.fc1.weight
moe_layer.experts.2.fc1.bias
moe_layer.experts.2.fc2.weight
moe_layer.experts.2.fc2.bias
moe_layer.experts.3.fc1.weight
moe_layer.experts.3.fc1.bias
moe_layer.experts.3.fc2.weight
moe_layer.experts.3.fc2.bias
final_layer_norm.weight
final_layer_norm.bias
self_attn.c_attn
self_attn.k_proj.weight
self_attn.k_proj.bias
self_attn.v_proj.weight
self_attn.v_proj.bias
self_attn.q_proj.weight
self_attn.q_proj.bias
self_attn.out_proj.weight
self_attn.out_proj.bias
self_attn_layer_norm.weight
self_attn_layer_norm.bias
fc1.weight
fc1.bias
fc2.weight
fc2.bias
attn_ln.weight
attn_ln.bias
ffn_layernorm.weight
ffn_layernorm.bias
moe_layer.gate.wg.weight
moe_layer.experts.0.fc1.weight
moe_layer.experts.0.fc1.bias
moe_layer.experts.0.fc2.weight
moe_layer.experts.0.fc2.bias
moe_layer.experts.1.fc1.weight
moe_layer.experts.1.fc1.bias
moe_layer.experts.1.fc2.weight
moe_layer.experts.1.fc2.bias
moe_layer.experts.2.fc1.weight
moe_layer.experts.2.fc1.bias
moe_layer.experts.2.fc2.weight
moe_layer.experts.2.fc2.bias
moe_layer.experts.3.fc1.weight
moe_layer.experts.3.fc1.bias
moe_layer.experts.3.fc2.weight
moe_layer.experts.3.fc2.bias
final_layer_norm.weight
final_layer_norm.bias
self_attn.c_attn
self_attn.k_proj.weight
self_attn.k_proj.bias
self_attn.v_proj.weight
self_attn.v_proj.bias
self_attn.q_proj.weight
self_attn.q_proj.bias
self_attn.out_proj.weight
self_attn.out_proj.bias
self_attn_layer_norm.weight
self_attn_layer_norm.bias
fc1.weight
fc1.bias
fc2.weight
fc2.bias
attn_ln.weight
attn_ln.bias
ffn_layernorm.weight
ffn_layernorm.bias
moe_layer.gate.wg.weight
moe_layer.experts.0.fc1.weight
moe_layer.experts.0.fc1.bias
moe_layer.experts.0.fc2.weight
moe_layer.experts.0.fc2.bias
moe_layer.experts.1.fc1.weight
moe_layer.experts.1.fc1.bias
moe_layer.experts.1.fc2.weight
moe_layer.experts.1.fc2.bias
moe_layer.experts.2.fc1.weight
moe_layer.experts.2.fc1.bias
moe_layer.experts.2.fc2.weight
moe_layer.experts.2.fc2.bias
moe_layer.experts.3.fc1.weight
moe_layer.experts.3.fc1.bias
moe_layer.experts.3.fc2.weight
moe_layer.experts.3.fc2.bias
final_layer_norm.weight
final_layer_norm.bias
self_attn.c_attn
self_attn.k_proj.weight
self_attn.k_proj.bias
self_attn.v_proj.weight
self_attn.v_proj.bias
self_attn.q_proj.weight
self_attn.q_proj.bias
self_attn.out_proj.weight
self_attn.out_proj.bias
self_attn_layer_norm.weight
self_attn_layer_norm.bias
fc1.weight
fc1.bias
fc2.weight
fc2.bias
attn_ln.weight
attn_ln.bias
ffn_layernorm.weight
ffn_layernorm.bias
moe_layer.gate.wg.weight
moe_layer.experts.0.fc1.weight
moe_layer.experts.0.fc1.bias
moe_layer.experts.0.fc2.weight
moe_layer.experts.0.fc2.bias
moe_layer.experts.1.fc1.weight
moe_layer.experts.1.fc1.bias
moe_layer.experts.1.fc2.weight
moe_layer.experts.1.fc2.bias
moe_layer.experts.2.fc1.weight
moe_layer.experts.2.fc1.bias
moe_layer.experts.2.fc2.weight
moe_layer.experts.2.fc2.bias
moe_layer.experts.3.fc1.weight
moe_layer.experts.3.fc1.bias
moe_layer.experts.3.fc2.weight
moe_layer.experts.3.fc2.bias
final_layer_norm.weight
final_layer_norm.bias
self_attn.c_attn
self_attn.k_proj.weight
self_attn.k_proj.bias
self_attn.v_proj.weight
self_attn.v_proj.bias
self_attn.q_proj.weight
self_attn.q_proj.bias
self_attn.out_proj.weight
self_attn.out_proj.bias
self_attn_layer_norm.weight
self_attn_layer_norm.bias
fc1.weight
fc1.bias
fc2.weight
fc2.bias
attn_ln.weight
attn_ln.bias
ffn_layernorm.weight
ffn_layernorm.bias
moe_layer.gate.wg.weight
moe_layer.experts.0.fc1.weight
moe_layer.experts.0.fc1.bias
moe_layer.experts.0.fc2.weight
moe_layer.experts.0.fc2.bias
moe_layer.experts.1.fc1.weight
moe_layer.experts.1.fc1.bias
moe_layer.experts.1.fc2.weight
moe_layer.experts.1.fc2.bias
moe_layer.experts.2.fc1.weight
moe_layer.experts.2.fc1.bias
moe_layer.experts.2.fc2.weight
moe_layer.experts.2.fc2.bias
moe_layer.experts.3.fc1.weight
moe_layer.experts.3.fc1.bias
moe_layer.experts.3.fc2.weight
moe_layer.experts.3.fc2.bias
final_layer_norm.weight
final_layer_norm.bias
self_attn.c_attn
self_attn.k_proj.weight
self_attn.k_proj.bias
self_attn.v_proj.weight
self_attn.v_proj.bias
self_attn.q_proj.weight
self_attn.q_proj.bias
self_attn.out_proj.weight
self_attn.out_proj.bias
self_attn_layer_norm.weight
self_attn_layer_norm.bias
fc1.weight
fc1.bias
fc2.weight
fc2.bias
attn_ln.weight
attn_ln.bias
ffn_layernorm.weight
ffn_layernorm.bias
moe_layer.gate.wg.weight
moe_layer.experts.0.fc1.weight
moe_layer.experts.0.fc1.bias
moe_layer.experts.0.fc2.weight
moe_layer.experts.0.fc2.bias
moe_layer.experts.1.fc1.weight
moe_layer.experts.1.fc1.bias
moe_layer.experts.1.fc2.weight
moe_layer.experts.1.fc2.bias
moe_layer.experts.2.fc1.weight
moe_layer.experts.2.fc1.bias
moe_layer.experts.2.fc2.weight
moe_layer.experts.2.fc2.bias
moe_layer.experts.3.fc1.weight
moe_layer.experts.3.fc1.bias
moe_layer.experts.3.fc2.weight
moe_layer.experts.3.fc2.bias
final_layer_norm.weight
final_layer_norm.bias
self_attn.c_attn
self_attn.k_proj.weight
self_attn.k_proj.bias
self_attn.v_proj.weight
self_attn.v_proj.bias
self_attn.q_proj.weight
self_attn.q_proj.bias
self_attn.out_proj.weight
self_attn.out_proj.bias
self_attn_layer_norm.weight
self_attn_layer_norm.bias
fc1.weight
fc1.bias
fc2.weight
fc2.bias
attn_ln.weight
attn_ln.bias
ffn_layernorm.weight
ffn_layernorm.bias
moe_layer.gate.wg.weight
moe_layer.experts.0.fc1.weight
moe_layer.experts.0.fc1.bias
moe_layer.experts.0.fc2.weight
moe_layer.experts.0.fc2.bias
moe_layer.experts.1.fc1.weight
moe_layer.experts.1.fc1.bias
moe_layer.experts.1.fc2.weight
moe_layer.experts.1.fc2.bias
moe_layer.experts.2.fc1.weight
moe_layer.experts.2.fc1.bias
moe_layer.experts.2.fc2.weight
moe_layer.experts.2.fc2.bias
moe_layer.experts.3.fc1.weight
moe_layer.experts.3.fc1.bias
moe_layer.experts.3.fc2.weight
moe_layer.experts.3.fc2.bias
final_layer_norm.weight
final_layer_norm.bias
self_attn.c_attn
self_attn.k_proj.weight
self_attn.k_proj.bias
self_attn.v_proj.weight
self_attn.v_proj.bias
self_attn.q_proj.weight
self_attn.q_proj.bias
self_attn.out_proj.weight
self_attn.out_proj.bias
self_attn_layer_norm.weight
self_attn_layer_norm.bias
fc1.weight
fc1.bias
fc2.weight
fc2.bias
attn_ln.weight
attn_ln.bias
ffn_layernorm.weight
ffn_layernorm.bias
moe_layer.gate.wg.weight
moe_layer.experts.0.fc1.weight
moe_layer.experts.0.fc1.bias
moe_layer.experts.0.fc2.weight
moe_layer.experts.0.fc2.bias
moe_layer.experts.1.fc1.weight
moe_layer.experts.1.fc1.bias
moe_layer.experts.1.fc2.weight
moe_layer.experts.1.fc2.bias
moe_layer.experts.2.fc1.weight
moe_layer.experts.2.fc1.bias
moe_layer.experts.2.fc2.weight
moe_layer.experts.2.fc2.bias
moe_layer.experts.3.fc1.weight
moe_layer.experts.3.fc1.bias
moe_layer.experts.3.fc2.weight
moe_layer.experts.3.fc2.bias
final_layer_norm.weight
final_layer_norm.bias
self_attn.c_attn
self_attn.k_proj.weight
self_attn.k_proj.bias
self_attn.v_proj.weight
self_attn.v_proj.bias
self_attn.q_proj.weight
self_attn.q_proj.bias
self_attn.out_proj.weight
self_attn.out_proj.bias
self_attn_layer_norm.weight
self_attn_layer_norm.bias
fc1.weight
fc1.bias
fc2.weight
fc2.bias
attn_ln.weight
attn_ln.bias
ffn_layernorm.weight
ffn_layernorm.bias
moe_layer.gate.wg.weight
moe_layer.experts.0.fc1.weight
moe_layer.experts.0.fc1.bias
moe_layer.experts.0.fc2.weight
moe_layer.experts.0.fc2.bias
moe_layer.experts.1.fc1.weight
moe_layer.experts.1.fc1.bias
moe_layer.experts.1.fc2.weight
moe_layer.experts.1.fc2.bias
moe_layer.experts.2.fc1.weight
moe_layer.experts.2.fc1.bias
moe_layer.experts.2.fc2.weight
moe_layer.experts.2.fc2.bias
moe_layer.experts.3.fc1.weight
moe_layer.experts.3.fc1.bias
moe_layer.experts.3.fc2.weight
moe_layer.experts.3.fc2.bias
final_layer_norm.weight
final_layer_norm.bias
self_attn.c_attn
self_attn.k_proj.weight
self_attn.k_proj.bias
self_attn.v_proj.weight
self_attn.v_proj.bias
self_attn.q_proj.weight
self_attn.q_proj.bias
self_attn.out_proj.weight
self_attn.out_proj.bias
self_attn_layer_norm.weight
self_attn_layer_norm.bias
fc1.weight
fc1.bias
fc2.weight
fc2.bias
attn_ln.weight
attn_ln.bias
ffn_layernorm.weight
ffn_layernorm.bias
moe_layer.gate.wg.weight
moe_layer.experts.0.fc1.weight
moe_layer.experts.0.fc1.bias
moe_layer.experts.0.fc2.weight
moe_layer.experts.0.fc2.bias
moe_layer.experts.1.fc1.weight
moe_layer.experts.1.fc1.bias
moe_layer.experts.1.fc2.weight
moe_layer.experts.1.fc2.bias
moe_layer.experts.2.fc1.weight
moe_layer.experts.2.fc1.bias
moe_layer.experts.2.fc2.weight
moe_layer.experts.2.fc2.bias
moe_layer.experts.3.fc1.weight
moe_layer.experts.3.fc1.bias
moe_layer.experts.3.fc2.weight
moe_layer.experts.3.fc2.bias
final_layer_norm.weight
final_layer_norm.bias
self_attn.c_attn
self_attn.k_proj.weight
self_attn.k_proj.bias
self_attn.v_proj.weight
self_attn.v_proj.bias
self_attn.q_proj.weight
self_attn.q_proj.bias
self_attn.out_proj.weight
self_attn.out_proj.bias
self_attn_layer_norm.weight
self_attn_layer_norm.bias
fc1.weight
fc1.bias
fc2.weight
fc2.bias
attn_ln.weight
attn_ln.bias
ffn_layernorm.weight
ffn_layernorm.bias
moe_layer.gate.wg.weight
moe_layer.experts.0.fc1.weight
moe_layer.experts.0.fc1.bias
moe_layer.experts.0.fc2.weight
moe_layer.experts.0.fc2.bias
moe_layer.experts.1.fc1.weight
moe_layer.experts.1.fc1.bias
moe_layer.experts.1.fc2.weight
moe_layer.experts.1.fc2.bias
moe_layer.experts.2.fc1.weight
moe_layer.experts.2.fc1.bias
moe_layer.experts.2.fc2.weight
moe_layer.experts.2.fc2.bias
moe_layer.experts.3.fc1.weight
moe_layer.experts.3.fc1.bias
moe_layer.experts.3.fc2.weight
moe_layer.experts.3.fc2.bias
final_layer_norm.weight
final_layer_norm.bias
self_attn.c_attn
self_attn.k_proj.weight
self_attn.k_proj.bias
self_attn.v_proj.weight
self_attn.v_proj.bias
self_attn.q_proj.weight
self_attn.q_proj.bias
self_attn.out_proj.weight
self_attn.out_proj.bias
self_attn_layer_norm.weight
self_attn_layer_norm.bias
fc1.weight
fc1.bias
fc2.weight
fc2.bias
attn_ln.weight
attn_ln.bias
ffn_layernorm.weight
ffn_layernorm.bias
moe_layer.gate.wg.weight
moe_layer.experts.0.fc1.weight
moe_layer.experts.0.fc1.bias
moe_layer.experts.0.fc2.weight
moe_layer.experts.0.fc2.bias
moe_layer.experts.1.fc1.weight
moe_layer.experts.1.fc1.bias
moe_layer.experts.1.fc2.weight
moe_layer.experts.1.fc2.bias
moe_layer.experts.2.fc1.weight
moe_layer.experts.2.fc1.bias
moe_layer.experts.2.fc2.weight
moe_layer.experts.2.fc2.bias
moe_layer.experts.3.fc1.weight
moe_layer.experts.3.fc1.bias
moe_layer.experts.3.fc2.weight
moe_layer.experts.3.fc2.bias
final_layer_norm.weight
final_layer_norm.bias
2022-04-25 09:42:11 - adam.py[line:68] - INFO: using FusedAdam
2022-04-25 09:42:11 - trainer.py[line:618] - INFO: Loaded checkpoint ../../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2022-04-25 09:42:11 - trainer.py[line:640] - INFO: loading train data for epoch 1
local datafile ../../dataset/glue_data/mnli_train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/glue_data/mnli_train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/glue_data/mnli_train.tsv slice_id 0 row count 392702 total row count 392702
slice_id 0 seek offset 0
Total steps 30680, warmup steps 1840, warmup_factor 0.0005434782608695652
2022-04-25 09:42:11 - trainer.py[line:704] - INFO: begin training epoch 1
2022-04-25 09:42:11 - train.py[line:295] - INFO: Start iterating over samples
2022-04-25 09:42:48 - progress_bar.py[line:272] - INFO: epoch 001:     10 / 6136 loss=2.85, loss_v1=0, loss_v2=0, nll_loss=1.721, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=3.3, wps=20.6, ups=0.32, wpb=64, bsz=64, num_updates=10, lr=5.43478e-08, gnorm=16.847, loss_scale=16, train_wall=36, gb_free=7.7, wall=41
2022-04-25 09:43:10 - progress_bar.py[line:272] - INFO: epoch 001:     20 / 6136 loss=2.898, loss_v1=0, loss_v2=0, nll_loss=1.769, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=3.41, wps=28.1, ups=0.44, wpb=64, bsz=64, num_updates=20, lr=1.08696e-07, gnorm=17.826, loss_scale=16, train_wall=23, gb_free=13, wall=64
2022-04-25 09:43:28 - progress_bar.py[line:272] - INFO: epoch 001:     30 / 6136 loss=2.897, loss_v1=0, loss_v2=0, nll_loss=1.77, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=3.41, wps=37, ups=0.58, wpb=64, bsz=64, num_updates=30, lr=1.63043e-07, gnorm=17.5, loss_scale=16, train_wall=17, gb_free=14.1, wall=81
2022-04-25 09:43:41 - progress_bar.py[line:272] - INFO: epoch 001:     40 / 6136 loss=3.002, loss_v1=0, loss_v2=0, nll_loss=1.875, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=3.67, wps=47, ups=0.74, wpb=64, bsz=64, num_updates=40, lr=2.17391e-07, gnorm=19.592, loss_scale=16, train_wall=14, gb_free=13.6, wall=95
2022-04-25 09:43:52 - progress_bar.py[line:272] - INFO: epoch 001:     50 / 6136 loss=2.81, loss_v1=0, loss_v2=0, nll_loss=1.68, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=3.2, wps=57.3, ups=0.89, wpb=64, bsz=64, num_updates=50, lr=2.71739e-07, gnorm=16.666, loss_scale=16, train_wall=11, gb_free=13.6, wall=106
2022-04-25 09:44:06 - progress_bar.py[line:272] - INFO: epoch 001:     60 / 6136 loss=2.893, loss_v1=0, loss_v2=0, nll_loss=1.764, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=3.4, wps=48.2, ups=0.75, wpb=64, bsz=64, num_updates=60, lr=3.26087e-07, gnorm=16.386, loss_scale=16, train_wall=13, gb_free=13.4, wall=119
2022-04-25 09:44:17 - progress_bar.py[line:272] - INFO: epoch 001:     70 / 6136 loss=2.921, loss_v1=0, loss_v2=0, nll_loss=1.794, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=3.47, wps=58.7, ups=0.92, wpb=64, bsz=64, num_updates=70, lr=3.80435e-07, gnorm=17.645, loss_scale=16, train_wall=11, gb_free=12.3, wall=130
2022-04-25 09:44:29 - progress_bar.py[line:272] - INFO: epoch 001:     80 / 6136 loss=2.782, loss_v1=0, loss_v2=0, nll_loss=1.655, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=3.15, wps=52.9, ups=0.83, wpb=64, bsz=64, num_updates=80, lr=4.34783e-07, gnorm=14.882, loss_scale=16, train_wall=12, gb_free=13.4, wall=142
2022-04-25 09:44:39 - progress_bar.py[line:272] - INFO: epoch 001:     90 / 6136 loss=2.71, loss_v1=0, loss_v2=0, nll_loss=1.585, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=3, wps=59.9, ups=0.94, wpb=64, bsz=64, num_updates=90, lr=4.8913e-07, gnorm=10.812, loss_scale=16, train_wall=11, gb_free=13.7, wall=153
2022-04-25 09:44:51 - trainer.py[line:1304] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 1.54 GiB (GPU 0; 23.70 GiB total capacity; 20.68 GiB already allocated; 1.16 GiB free; 21.43 GiB reserved in total by PyTorch)
2022-04-25 09:44:51 - trainer.py[line:1307] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   19607 MB |   21261 MB |    3143 GB |    3124 GB |
|       from large pool |   19567 MB |   21220 MB |    3084 GB |    3065 GB |
|       from small pool |      39 MB |      52 MB |      59 GB |      59 GB |
|---------------------------------------------------------------------------|
| Active memory         |   19607 MB |   21261 MB |    3143 GB |    3124 GB |
|       from large pool |   19567 MB |   21220 MB |    3084 GB |    3065 GB |
|       from small pool |      39 MB |      52 MB |      59 GB |      59 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   21942 MB |   22060 MB |   28418 MB |    6476 MB |
|       from large pool |   21892 MB |   21974 MB |   28300 MB |    6408 MB |
|       from small pool |      50 MB |      86 MB |     118 MB |      68 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  780954 KB |    1589 MB |    2948 GB |    2947 GB |
|       from large pool |  770075 KB |    1569 MB |    2887 GB |    2886 GB |
|       from small pool |   10878 KB |      29 MB |      60 GB |      60 GB |
|---------------------------------------------------------------------------|
| Allocations           |    2425    |    2461    |    1453 K  |    1451 K  |
|       from large pool |     843    |     857    |     728 K  |     727 K  |
|       from small pool |    1582    |    1604    |     725 K  |     723 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    2425    |    2461    |    1453 K  |    1451 K  |
|       from large pool |     843    |     857    |     728 K  |     727 K  |
|       from small pool |    1582    |    1604    |     725 K  |     723 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     173    |     193    |     296    |     123    |
|       from large pool |     148    |     150    |     237    |      89    |
|       from small pool |      25    |      43    |      59    |      34    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     214    |     214    |     960 K  |     960 K  |
|       from large pool |     133    |     133    |     554 K  |     554 K  |
|       from small pool |      81    |     127    |     406 K  |     406 K  |
|===========================================================================|

2022-04-25 09:44:51 - trainer.py[line:797] - WARNING: attempting to recover from OOM in forward/backward pass
2022-04-25 09:44:53 - progress_bar.py[line:272] - INFO: epoch 001:    101 / 6136 loss=2.605, loss_v1=0, loss_v2=0, nll_loss=1.48, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.79, wps=47.4, ups=0.74, wpb=64, bsz=64, num_updates=100, lr=5.43478e-07, gnorm=9.579, loss_scale=16, train_wall=12, gb_free=13.1, wall=167
2022-04-25 09:45:04 - progress_bar.py[line:272] - INFO: epoch 001:    111 / 6136 loss=2.53, loss_v1=0, loss_v2=0, nll_loss=1.407, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=57.8, ups=0.9, wpb=64, bsz=64, num_updates=110, lr=5.97826e-07, gnorm=8.607, loss_scale=16, train_wall=11, gb_free=11.9, wall=178
2022-04-25 09:45:14 - progress_bar.py[line:272] - INFO: epoch 001:    121 / 6136 loss=2.588, loss_v1=0, loss_v2=0, nll_loss=1.465, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.76, wps=61.9, ups=0.97, wpb=64, bsz=64, num_updates=120, lr=6.52174e-07, gnorm=8.87, loss_scale=16, train_wall=10, gb_free=13.6, wall=188
2022-04-25 09:45:24 - progress_bar.py[line:272] - INFO: epoch 001:    131 / 6136 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.365, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=63.6, ups=0.99, wpb=64, bsz=64, num_updates=130, lr=7.06522e-07, gnorm=9.035, loss_scale=16, train_wall=10, gb_free=14, wall=198
2022-04-25 09:45:35 - progress_bar.py[line:272] - INFO: epoch 001:    141 / 6136 loss=2.574, loss_v1=0, loss_v2=0, nll_loss=1.456, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.74, wps=58, ups=0.91, wpb=64, bsz=64, num_updates=140, lr=7.6087e-07, gnorm=9.424, loss_scale=16, train_wall=11, gb_free=13.5, wall=209
2022-04-25 09:45:45 - progress_bar.py[line:272] - INFO: epoch 001:    151 / 6136 loss=2.493, loss_v1=0, loss_v2=0, nll_loss=1.374, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=69.5, ups=1.09, wpb=64, bsz=64, num_updates=150, lr=8.15217e-07, gnorm=7.035, loss_scale=16, train_wall=9, gb_free=13.7, wall=218
2022-04-25 09:45:53 - progress_bar.py[line:272] - INFO: epoch 001:    161 / 6136 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.347, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=72.5, ups=1.13, wpb=64, bsz=64, num_updates=160, lr=8.69565e-07, gnorm=7.121, loss_scale=16, train_wall=9, gb_free=13.7, wall=227
2022-04-25 09:46:04 - progress_bar.py[line:272] - INFO: epoch 001:    171 / 6136 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.361, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=58.4, ups=0.91, wpb=64, bsz=64, num_updates=170, lr=9.23913e-07, gnorm=7.47, loss_scale=16, train_wall=11, gb_free=13.5, wall=238
2022-04-25 09:46:14 - progress_bar.py[line:272] - INFO: epoch 001:    181 / 6136 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.363, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=66.8, ups=1.04, wpb=64, bsz=64, num_updates=180, lr=9.78261e-07, gnorm=7.336, loss_scale=16, train_wall=10, gb_free=13.8, wall=248
2022-04-25 09:46:25 - progress_bar.py[line:272] - INFO: epoch 001:    191 / 6136 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.365, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=59.9, ups=0.94, wpb=64, bsz=64, num_updates=190, lr=1.03261e-06, gnorm=6.505, loss_scale=16, train_wall=11, gb_free=8.9, wall=258
2022-04-25 09:46:34 - progress_bar.py[line:272] - INFO: epoch 001:    201 / 6136 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.333, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=68.3, ups=1.07, wpb=64, bsz=64, num_updates=200, lr=1.08696e-06, gnorm=6.473, loss_scale=16, train_wall=9, gb_free=13.1, wall=268
2022-04-25 09:46:43 - progress_bar.py[line:272] - INFO: epoch 001:    211 / 6136 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.38, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=68.9, ups=1.08, wpb=64, bsz=64, num_updates=210, lr=1.1413e-06, gnorm=6.188, loss_scale=16, train_wall=9, gb_free=13.4, wall=277
2022-04-25 09:46:53 - progress_bar.py[line:272] - INFO: epoch 001:    221 / 6136 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=67.9, ups=1.06, wpb=64, bsz=64, num_updates=220, lr=1.19565e-06, gnorm=6.318, loss_scale=16, train_wall=9, gb_free=13.5, wall=286
2022-04-25 09:47:03 - progress_bar.py[line:272] - INFO: epoch 001:    231 / 6136 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=64.4, ups=1.01, wpb=64, bsz=64, num_updates=230, lr=1.25e-06, gnorm=5.952, loss_scale=16, train_wall=10, gb_free=13.1, wall=296
2022-04-25 09:47:12 - progress_bar.py[line:272] - INFO: epoch 001:    241 / 6136 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=71, ups=1.11, wpb=64, bsz=64, num_updates=240, lr=1.30435e-06, gnorm=5.811, loss_scale=16, train_wall=9, gb_free=13.3, wall=305
2022-04-25 09:47:21 - progress_bar.py[line:272] - INFO: epoch 001:    251 / 6136 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=64.9, ups=1.01, wpb=64, bsz=64, num_updates=250, lr=1.3587e-06, gnorm=5.492, loss_scale=16, train_wall=10, gb_free=14, wall=315
2022-04-25 09:47:32 - progress_bar.py[line:272] - INFO: epoch 001:    261 / 6136 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=58.9, ups=0.92, wpb=64, bsz=64, num_updates=260, lr=1.41304e-06, gnorm=5.521, loss_scale=16, train_wall=11, gb_free=13.8, wall=326
2022-04-25 09:47:43 - progress_bar.py[line:272] - INFO: epoch 001:    271 / 6136 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=61.9, ups=0.97, wpb=64, bsz=64, num_updates=270, lr=1.46739e-06, gnorm=5.492, loss_scale=16, train_wall=10, gb_free=13.2, wall=336
2022-04-25 09:47:53 - progress_bar.py[line:272] - INFO: epoch 001:    281 / 6136 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=62.4, ups=0.98, wpb=64, bsz=64, num_updates=280, lr=1.52174e-06, gnorm=6.44, loss_scale=16, train_wall=10, gb_free=13.7, wall=347
2022-04-25 09:48:03 - progress_bar.py[line:272] - INFO: epoch 001:    291 / 6136 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=64.3, ups=1, wpb=64, bsz=64, num_updates=290, lr=1.57609e-06, gnorm=5.317, loss_scale=16, train_wall=10, gb_free=13.6, wall=357
2022-04-25 09:48:12 - progress_bar.py[line:272] - INFO: epoch 001:    301 / 6136 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=74, ups=1.16, wpb=64, bsz=64, num_updates=300, lr=1.63043e-06, gnorm=4.712, loss_scale=16, train_wall=9, gb_free=13.2, wall=365
2022-04-25 09:48:20 - progress_bar.py[line:272] - INFO: epoch 001:    311 / 6136 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=74.9, ups=1.17, wpb=64, bsz=64, num_updates=310, lr=1.68478e-06, gnorm=4.889, loss_scale=16, train_wall=8, gb_free=12.9, wall=374
2022-04-25 09:48:30 - progress_bar.py[line:272] - INFO: epoch 001:    321 / 6136 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=63.1, ups=0.99, wpb=64, bsz=64, num_updates=320, lr=1.73913e-06, gnorm=5.146, loss_scale=16, train_wall=10, gb_free=13.3, wall=384
2022-04-25 09:48:41 - progress_bar.py[line:272] - INFO: epoch 001:    331 / 6136 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=59.1, ups=0.92, wpb=64, bsz=64, num_updates=330, lr=1.79348e-06, gnorm=4.689, loss_scale=16, train_wall=11, gb_free=13.2, wall=395
2022-04-25 09:48:50 - progress_bar.py[line:272] - INFO: epoch 001:    341 / 6136 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=69.5, ups=1.09, wpb=64, bsz=64, num_updates=340, lr=1.84783e-06, gnorm=5.171, loss_scale=16, train_wall=9, gb_free=13.5, wall=404
2022-04-25 09:48:59 - progress_bar.py[line:272] - INFO: epoch 001:    351 / 6136 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=70, ups=1.09, wpb=64, bsz=64, num_updates=350, lr=1.90217e-06, gnorm=5.404, loss_scale=16, train_wall=9, gb_free=13.1, wall=413
2022-04-25 09:49:08 - progress_bar.py[line:272] - INFO: epoch 001:    361 / 6136 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=71.7, ups=1.12, wpb=64, bsz=64, num_updates=360, lr=1.95652e-06, gnorm=4.85, loss_scale=16, train_wall=9, gb_free=12.8, wall=422
2022-04-25 09:49:19 - progress_bar.py[line:272] - INFO: epoch 001:    371 / 6136 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=62.3, ups=0.97, wpb=64, bsz=64, num_updates=370, lr=2.01087e-06, gnorm=5.301, loss_scale=16, train_wall=10, gb_free=11.5, wall=432
2022-04-25 09:49:27 - progress_bar.py[line:272] - INFO: epoch 001:    381 / 6136 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=75.8, ups=1.18, wpb=64, bsz=64, num_updates=380, lr=2.06522e-06, gnorm=5.553, loss_scale=16, train_wall=8, gb_free=13.5, wall=441
2022-04-25 09:49:36 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-04-25 09:49:37 - progress_bar.py[line:272] - INFO: epoch 001:    392 / 6136 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=67.2, ups=1.05, wpb=64, bsz=64, num_updates=390, lr=2.11957e-06, gnorm=4.398, loss_scale=8, train_wall=9, gb_free=7.7, wall=450
2022-04-25 09:49:47 - progress_bar.py[line:272] - INFO: epoch 001:    402 / 6136 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=59.2, ups=0.93, wpb=64, bsz=64, num_updates=400, lr=2.17391e-06, gnorm=6.178, loss_scale=8, train_wall=11, gb_free=13.9, wall=461
2022-04-25 09:49:57 - progress_bar.py[line:272] - INFO: epoch 001:    412 / 6136 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=65.8, ups=1.03, wpb=64, bsz=64, num_updates=410, lr=2.22826e-06, gnorm=4.85, loss_scale=8, train_wall=10, gb_free=13.6, wall=471
2022-04-25 09:50:08 - progress_bar.py[line:272] - INFO: epoch 001:    422 / 6136 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=60.4, ups=0.94, wpb=64, bsz=64, num_updates=420, lr=2.28261e-06, gnorm=4.82, loss_scale=8, train_wall=11, gb_free=13.5, wall=481
2022-04-25 09:50:16 - progress_bar.py[line:272] - INFO: epoch 001:    432 / 6136 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=78.1, ups=1.22, wpb=64, bsz=64, num_updates=430, lr=2.33696e-06, gnorm=4.275, loss_scale=8, train_wall=8, gb_free=13.9, wall=490
2022-04-25 09:50:27 - progress_bar.py[line:272] - INFO: epoch 001:    442 / 6136 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=55.4, ups=0.87, wpb=64, bsz=64, num_updates=440, lr=2.3913e-06, gnorm=5.701, loss_scale=8, train_wall=11, gb_free=12.5, wall=501
2022-04-25 09:50:36 - progress_bar.py[line:272] - INFO: epoch 001:    452 / 6136 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=75.7, ups=1.18, wpb=64, bsz=64, num_updates=450, lr=2.44565e-06, gnorm=5.077, loss_scale=8, train_wall=8, gb_free=13.5, wall=510
2022-04-25 09:50:46 - progress_bar.py[line:272] - INFO: epoch 001:    462 / 6136 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=65.7, ups=1.03, wpb=64, bsz=64, num_updates=460, lr=2.5e-06, gnorm=5.275, loss_scale=8, train_wall=10, gb_free=13.3, wall=519
2022-04-25 09:50:54 - progress_bar.py[line:272] - INFO: epoch 001:    472 / 6136 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=74.6, ups=1.17, wpb=64, bsz=64, num_updates=470, lr=2.55435e-06, gnorm=4.209, loss_scale=8, train_wall=9, gb_free=13.8, wall=528
2022-04-25 09:51:03 - progress_bar.py[line:272] - INFO: epoch 001:    482 / 6136 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=73.3, ups=1.15, wpb=64, bsz=64, num_updates=480, lr=2.6087e-06, gnorm=4.294, loss_scale=8, train_wall=9, gb_free=13.5, wall=537
2022-04-25 09:51:12 - progress_bar.py[line:272] - INFO: epoch 001:    492 / 6136 loss=2.234, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=69.1, ups=1.08, wpb=64, bsz=64, num_updates=490, lr=2.66304e-06, gnorm=4.183, loss_scale=8, train_wall=9, gb_free=13.6, wall=546
2022-04-25 09:51:21 - progress_bar.py[line:272] - INFO: epoch 001:    502 / 6136 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=74.3, ups=1.16, wpb=64, bsz=64, num_updates=500, lr=2.71739e-06, gnorm=5.238, loss_scale=8, train_wall=9, gb_free=11.6, wall=555
2022-04-25 09:51:29 - progress_bar.py[line:272] - INFO: epoch 001:    512 / 6136 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=78.2, ups=1.22, wpb=64, bsz=64, num_updates=510, lr=2.77174e-06, gnorm=3.884, loss_scale=8, train_wall=8, gb_free=13.3, wall=563
2022-04-25 09:51:39 - progress_bar.py[line:272] - INFO: epoch 001:    522 / 6136 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=63.9, ups=1, wpb=64, bsz=64, num_updates=520, lr=2.82609e-06, gnorm=4.199, loss_scale=8, train_wall=10, gb_free=13.3, wall=573
2022-04-25 09:51:48 - progress_bar.py[line:272] - INFO: epoch 001:    532 / 6136 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=75, ups=1.17, wpb=64, bsz=64, num_updates=530, lr=2.88043e-06, gnorm=4.735, loss_scale=8, train_wall=8, gb_free=12.3, wall=581
2022-04-25 09:51:58 - progress_bar.py[line:272] - INFO: epoch 001:    542 / 6136 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=63.4, ups=0.99, wpb=64, bsz=64, num_updates=540, lr=2.93478e-06, gnorm=4.612, loss_scale=8, train_wall=10, gb_free=13.9, wall=591
2022-04-25 09:52:06 - progress_bar.py[line:272] - INFO: epoch 001:    552 / 6136 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=76.8, ups=1.2, wpb=64, bsz=64, num_updates=550, lr=2.98913e-06, gnorm=3.997, loss_scale=8, train_wall=8, gb_free=12.8, wall=600
2022-04-25 09:52:14 - progress_bar.py[line:272] - INFO: epoch 001:    562 / 6136 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=75.9, ups=1.19, wpb=64, bsz=64, num_updates=560, lr=3.04348e-06, gnorm=3.6, loss_scale=8, train_wall=8, gb_free=13.7, wall=608
2022-04-25 09:52:25 - progress_bar.py[line:272] - INFO: epoch 001:    572 / 6136 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=62.3, ups=0.97, wpb=64, bsz=64, num_updates=570, lr=3.09783e-06, gnorm=3.98, loss_scale=8, train_wall=10, gb_free=11.6, wall=618
2022-04-25 09:52:34 - progress_bar.py[line:272] - INFO: epoch 001:    582 / 6136 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=69.1, ups=1.08, wpb=64, bsz=64, num_updates=580, lr=3.15217e-06, gnorm=4.195, loss_scale=8, train_wall=9, gb_free=12.7, wall=628
2022-04-25 09:52:43 - progress_bar.py[line:272] - INFO: epoch 001:    592 / 6136 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=70.8, ups=1.11, wpb=64, bsz=64, num_updates=590, lr=3.20652e-06, gnorm=4.279, loss_scale=8, train_wall=9, gb_free=13, wall=637
2022-04-25 09:52:53 - progress_bar.py[line:272] - INFO: epoch 001:    602 / 6136 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=67.2, ups=1.05, wpb=64, bsz=64, num_updates=600, lr=3.26087e-06, gnorm=4.797, loss_scale=8, train_wall=9, gb_free=11.6, wall=646
2022-04-25 09:53:02 - progress_bar.py[line:272] - INFO: epoch 001:    612 / 6136 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=69.5, ups=1.09, wpb=64, bsz=64, num_updates=610, lr=3.31522e-06, gnorm=4.187, loss_scale=8, train_wall=9, gb_free=13.6, wall=656
2022-04-25 09:53:10 - progress_bar.py[line:272] - INFO: epoch 001:    622 / 6136 loss=2.192, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=75.9, ups=1.19, wpb=64, bsz=64, num_updates=620, lr=3.36957e-06, gnorm=3.65, loss_scale=8, train_wall=8, gb_free=14, wall=664
2022-04-25 09:53:19 - progress_bar.py[line:272] - INFO: epoch 001:    632 / 6136 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=74.7, ups=1.17, wpb=64, bsz=64, num_updates=630, lr=3.42391e-06, gnorm=4.376, loss_scale=8, train_wall=9, gb_free=13, wall=673
2022-04-25 09:53:27 - progress_bar.py[line:272] - INFO: epoch 001:    642 / 6136 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=76.5, ups=1.2, wpb=64, bsz=64, num_updates=640, lr=3.47826e-06, gnorm=3.769, loss_scale=8, train_wall=8, gb_free=13.8, wall=681
2022-04-25 09:53:36 - progress_bar.py[line:272] - INFO: epoch 001:    652 / 6136 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=72.5, ups=1.13, wpb=64, bsz=64, num_updates=650, lr=3.53261e-06, gnorm=4.094, loss_scale=8, train_wall=9, gb_free=13.2, wall=690
2022-04-25 09:53:45 - progress_bar.py[line:272] - INFO: epoch 001:    662 / 6136 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=69.3, ups=1.08, wpb=64, bsz=64, num_updates=660, lr=3.58696e-06, gnorm=3.66, loss_scale=8, train_wall=9, gb_free=14.1, wall=699
2022-04-25 09:53:54 - progress_bar.py[line:272] - INFO: epoch 001:    672 / 6136 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=74.7, ups=1.17, wpb=64, bsz=64, num_updates=670, lr=3.6413e-06, gnorm=3.781, loss_scale=8, train_wall=9, gb_free=13.8, wall=707
2022-04-25 09:54:02 - progress_bar.py[line:272] - INFO: epoch 001:    682 / 6136 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=75.6, ups=1.18, wpb=64, bsz=64, num_updates=680, lr=3.69565e-06, gnorm=4.035, loss_scale=8, train_wall=8, gb_free=12.7, wall=716
2022-04-25 09:54:11 - progress_bar.py[line:272] - INFO: epoch 001:    692 / 6136 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=74.9, ups=1.17, wpb=64, bsz=64, num_updates=690, lr=3.75e-06, gnorm=16.635, loss_scale=8, train_wall=8, gb_free=13.3, wall=725
2022-04-25 09:54:22 - progress_bar.py[line:272] - INFO: epoch 001:    702 / 6136 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=58.3, ups=0.91, wpb=64, bsz=64, num_updates=700, lr=3.80435e-06, gnorm=3.439, loss_scale=8, train_wall=11, gb_free=13.4, wall=735
2022-04-25 09:54:30 - progress_bar.py[line:272] - INFO: epoch 001:    712 / 6136 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=75.2, ups=1.18, wpb=64, bsz=64, num_updates=710, lr=3.8587e-06, gnorm=3.56, loss_scale=8, train_wall=8, gb_free=13.6, wall=744
2022-04-25 09:54:39 - progress_bar.py[line:272] - INFO: epoch 001:    722 / 6136 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=74.7, ups=1.17, wpb=64, bsz=64, num_updates=720, lr=3.91304e-06, gnorm=3.998, loss_scale=8, train_wall=9, gb_free=12.6, wall=753
2022-04-25 09:54:48 - progress_bar.py[line:272] - INFO: epoch 001:    732 / 6136 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=67.9, ups=1.06, wpb=64, bsz=64, num_updates=730, lr=3.96739e-06, gnorm=2.76, loss_scale=8, train_wall=9, gb_free=13.1, wall=762
2022-04-25 09:54:57 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-04-25 09:54:59 - progress_bar.py[line:272] - INFO: epoch 001:    743 / 6136 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=62.2, ups=0.97, wpb=64, bsz=64, num_updates=740, lr=4.02174e-06, gnorm=3.76, loss_scale=4, train_wall=10, gb_free=12, wall=772
2022-04-25 09:55:07 - progress_bar.py[line:272] - INFO: epoch 001:    753 / 6136 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=76.7, ups=1.2, wpb=64, bsz=64, num_updates=750, lr=4.07609e-06, gnorm=3.538, loss_scale=4, train_wall=8, gb_free=13.4, wall=781
2022-04-25 09:55:16 - progress_bar.py[line:272] - INFO: epoch 001:    763 / 6136 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=68, ups=1.06, wpb=64, bsz=64, num_updates=760, lr=4.13043e-06, gnorm=3.621, loss_scale=4, train_wall=9, gb_free=13.5, wall=790
2022-04-25 09:55:26 - progress_bar.py[line:272] - INFO: epoch 001:    773 / 6136 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=68.7, ups=1.07, wpb=64, bsz=64, num_updates=770, lr=4.18478e-06, gnorm=3.479, loss_scale=4, train_wall=9, gb_free=13.9, wall=799
2022-04-25 09:55:34 - progress_bar.py[line:272] - INFO: epoch 001:    783 / 6136 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=74.5, ups=1.16, wpb=64, bsz=64, num_updates=780, lr=4.23913e-06, gnorm=3.662, loss_scale=4, train_wall=9, gb_free=13.1, wall=808
2022-04-25 09:55:43 - progress_bar.py[line:272] - INFO: epoch 001:    793 / 6136 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=69.3, ups=1.08, wpb=64, bsz=64, num_updates=790, lr=4.29348e-06, gnorm=3.491, loss_scale=4, train_wall=9, gb_free=13.8, wall=817
2022-04-25 09:55:52 - progress_bar.py[line:272] - INFO: epoch 001:    803 / 6136 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=72.1, ups=1.13, wpb=64, bsz=64, num_updates=800, lr=4.34783e-06, gnorm=3.867, loss_scale=4, train_wall=9, gb_free=13.3, wall=826
2022-04-25 09:56:01 - progress_bar.py[line:272] - INFO: epoch 001:    813 / 6136 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=76.3, ups=1.19, wpb=64, bsz=64, num_updates=810, lr=4.40217e-06, gnorm=3.37, loss_scale=4, train_wall=8, gb_free=13.7, wall=834
2022-04-25 09:56:09 - progress_bar.py[line:272] - INFO: epoch 001:    823 / 6136 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=73.5, ups=1.15, wpb=64, bsz=64, num_updates=820, lr=4.45652e-06, gnorm=4.066, loss_scale=4, train_wall=9, gb_free=13.8, wall=843
2022-04-25 09:56:19 - progress_bar.py[line:272] - INFO: epoch 001:    833 / 6136 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=66.6, ups=1.04, wpb=64, bsz=64, num_updates=830, lr=4.51087e-06, gnorm=3.308, loss_scale=4, train_wall=10, gb_free=9.4, wall=853
2022-04-25 09:56:28 - progress_bar.py[line:272] - INFO: epoch 001:    843 / 6136 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=70.4, ups=1.1, wpb=64, bsz=64, num_updates=840, lr=4.56522e-06, gnorm=3.385, loss_scale=4, train_wall=9, gb_free=13.7, wall=862
2022-04-25 09:56:37 - progress_bar.py[line:272] - INFO: epoch 001:    853 / 6136 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=74.2, ups=1.16, wpb=64, bsz=64, num_updates=850, lr=4.61957e-06, gnorm=3.429, loss_scale=4, train_wall=9, gb_free=13.5, wall=870
2022-04-25 09:56:45 - progress_bar.py[line:272] - INFO: epoch 001:    863 / 6136 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=74.3, ups=1.16, wpb=64, bsz=64, num_updates=860, lr=4.67391e-06, gnorm=3.801, loss_scale=4, train_wall=9, gb_free=13.2, wall=879
2022-04-25 09:56:54 - progress_bar.py[line:272] - INFO: epoch 001:    873 / 6136 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=72.3, ups=1.13, wpb=64, bsz=64, num_updates=870, lr=4.72826e-06, gnorm=3.562, loss_scale=4, train_wall=9, gb_free=13.6, wall=888
2022-04-25 09:57:03 - progress_bar.py[line:272] - INFO: epoch 001:    883 / 6136 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=74, ups=1.16, wpb=64, bsz=64, num_updates=880, lr=4.78261e-06, gnorm=3.362, loss_scale=4, train_wall=9, gb_free=13.2, wall=897
2022-04-25 09:57:06 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2022-04-25 09:57:13 - progress_bar.py[line:272] - INFO: epoch 001:    894 / 6136 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=64, ups=1, wpb=64, bsz=64, num_updates=890, lr=4.83696e-06, gnorm=3.17, loss_scale=2, train_wall=10, gb_free=13.6, wall=907
2022-04-25 09:57:15 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2022-04-25 09:57:24 - progress_bar.py[line:272] - INFO: epoch 001:    905 / 6136 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=59.5, ups=0.93, wpb=64, bsz=64, num_updates=900, lr=4.8913e-06, gnorm=2.562, loss_scale=1, train_wall=11, gb_free=12.6, wall=917
2022-04-25 09:57:33 - progress_bar.py[line:272] - INFO: epoch 001:    915 / 6136 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=66.2, ups=1.04, wpb=64, bsz=64, num_updates=910, lr=4.94565e-06, gnorm=3.583, loss_scale=1, train_wall=10, gb_free=13.4, wall=927
2022-04-25 09:57:42 - progress_bar.py[line:272] - INFO: epoch 001:    925 / 6136 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=72.3, ups=1.13, wpb=64, bsz=64, num_updates=920, lr=5e-06, gnorm=3.043, loss_scale=1, train_wall=9, gb_free=12.9, wall=936
2022-04-25 09:57:51 - progress_bar.py[line:272] - INFO: epoch 001:    935 / 6136 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=74.7, ups=1.17, wpb=64, bsz=64, num_updates=930, lr=5.05435e-06, gnorm=3.349, loss_scale=1, train_wall=9, gb_free=13.7, wall=944
2022-04-25 09:57:59 - progress_bar.py[line:272] - INFO: epoch 001:    945 / 6136 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=73, ups=1.14, wpb=64, bsz=64, num_updates=940, lr=5.1087e-06, gnorm=3.234, loss_scale=1, train_wall=9, gb_free=13.9, wall=953
2022-04-25 09:58:10 - progress_bar.py[line:272] - INFO: epoch 001:    955 / 6136 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=62.2, ups=0.97, wpb=64, bsz=64, num_updates=950, lr=5.16304e-06, gnorm=3.415, loss_scale=1, train_wall=10, gb_free=13.3, wall=963
2022-04-25 09:58:19 - progress_bar.py[line:272] - INFO: epoch 001:    965 / 6136 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=72.2, ups=1.13, wpb=64, bsz=64, num_updates=960, lr=5.21739e-06, gnorm=3.345, loss_scale=1, train_wall=9, gb_free=12.4, wall=972
2022-04-25 09:58:27 - progress_bar.py[line:272] - INFO: epoch 001:    975 / 6136 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=72.3, ups=1.13, wpb=64, bsz=64, num_updates=970, lr=5.27174e-06, gnorm=3.48, loss_scale=1, train_wall=9, gb_free=13.8, wall=981
2022-04-25 09:58:37 - progress_bar.py[line:272] - INFO: epoch 001:    985 / 6136 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=66, ups=1.03, wpb=64, bsz=64, num_updates=980, lr=5.32609e-06, gnorm=3.3, loss_scale=1, train_wall=10, gb_free=14, wall=991
2022-04-25 09:58:47 - progress_bar.py[line:272] - INFO: epoch 001:    995 / 6136 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=66.2, ups=1.03, wpb=64, bsz=64, num_updates=990, lr=5.38043e-06, gnorm=2.978, loss_scale=1, train_wall=10, gb_free=11.7, wall=1001
2022-04-25 09:58:55 - progress_bar.py[line:272] - INFO: epoch 001:   1005 / 6136 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=74.2, ups=1.16, wpb=64, bsz=64, num_updates=1000, lr=5.43478e-06, gnorm=3.008, loss_scale=1, train_wall=9, gb_free=12.8, wall=1009
2022-04-25 09:58:55 - train.py[line:435] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:03:21 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 2.102 | loss_v1 0 | loss_v2 0 | nll_loss 1.098 | ntokens 15.999 | nsentences 15.999 | sample_size 15.999 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.14 | acc 0.3719 | wps 74 | wpb 16 | bsz 16 | num_updates 1000
2022-04-25 10:03:21 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 1000 updates
2022-04-25 10:03:21 - trainer.py[line:432] - INFO: Saving checkpoint to ./fairseq_checkpoints/mnli/5_1e-5_4/checkpoint_1_1000.pt
2022-04-25 10:03:37 - trainer.py[line:442] - INFO: Finished saving checkpoint to ./fairseq_checkpoints/mnli/5_1e-5_4/checkpoint_1_1000.pt
2022-04-25 10:03:58 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./fairseq_checkpoints/mnli/5_1e-5_4/checkpoint_1_1000.pt (epoch 1 @ 1000 updates, score 0.3719) (writing took 36.89184469310567 seconds)
2022-04-25 10:04:07 - progress_bar.py[line:272] - INFO: epoch 001:   1015 / 6136 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=2.1, ups=0.03, wpb=64, bsz=64, num_updates=1010, lr=5.48913e-06, gnorm=3.655, loss_scale=1, train_wall=8, gb_free=13.3, wall=1321
2022-04-25 10:04:15 - progress_bar.py[line:272] - INFO: epoch 001:   1025 / 6136 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=76.2, ups=1.19, wpb=64, bsz=64, num_updates=1020, lr=5.54348e-06, gnorm=3.63, loss_scale=1, train_wall=8, gb_free=12.7, wall=1329
2022-04-25 10:04:24 - progress_bar.py[line:272] - INFO: epoch 001:   1035 / 6136 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=72.4, ups=1.13, wpb=64, bsz=64, num_updates=1030, lr=5.59783e-06, gnorm=3.098, loss_scale=1, train_wall=9, gb_free=12.4, wall=1338
2022-04-25 10:04:33 - progress_bar.py[line:272] - INFO: epoch 001:   1045 / 6136 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=72.9, ups=1.14, wpb=64, bsz=64, num_updates=1040, lr=5.65217e-06, gnorm=3.821, loss_scale=1, train_wall=9, gb_free=13.9, wall=1347
2022-04-25 10:04:42 - progress_bar.py[line:272] - INFO: epoch 001:   1055 / 6136 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=74, ups=1.16, wpb=64, bsz=64, num_updates=1050, lr=5.70652e-06, gnorm=3.222, loss_scale=1, train_wall=9, gb_free=13.7, wall=1355
2022-04-25 10:04:51 - progress_bar.py[line:272] - INFO: epoch 001:   1065 / 6136 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=71.2, ups=1.11, wpb=64, bsz=64, num_updates=1060, lr=5.76087e-06, gnorm=2.987, loss_scale=1, train_wall=9, gb_free=13.9, wall=1364
2022-04-25 10:05:00 - progress_bar.py[line:272] - INFO: epoch 001:   1075 / 6136 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=72.1, ups=1.13, wpb=64, bsz=64, num_updates=1070, lr=5.81522e-06, gnorm=2.72, loss_scale=1, train_wall=9, gb_free=13.3, wall=1373
2022-04-25 10:05:10 - progress_bar.py[line:272] - INFO: epoch 001:   1085 / 6136 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=62.9, ups=0.98, wpb=64, bsz=64, num_updates=1080, lr=5.86957e-06, gnorm=3.756, loss_scale=1, train_wall=10, gb_free=10.4, wall=1384
2022-04-25 10:05:19 - progress_bar.py[line:272] - INFO: epoch 001:   1095 / 6136 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=72.7, ups=1.14, wpb=64, bsz=64, num_updates=1090, lr=5.92391e-06, gnorm=2.996, loss_scale=1, train_wall=9, gb_free=12.8, wall=1392
2022-04-25 10:05:27 - progress_bar.py[line:272] - INFO: epoch 001:   1105 / 6136 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=72.1, ups=1.13, wpb=64, bsz=64, num_updates=1100, lr=5.97826e-06, gnorm=3.171, loss_scale=1, train_wall=9, gb_free=13, wall=1401
2022-04-25 10:05:36 - progress_bar.py[line:272] - INFO: epoch 001:   1115 / 6136 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=71.4, ups=1.12, wpb=64, bsz=64, num_updates=1110, lr=6.03261e-06, gnorm=3.35, loss_scale=1, train_wall=9, gb_free=11.5, wall=1410
2022-04-25 10:05:45 - progress_bar.py[line:272] - INFO: epoch 001:   1125 / 6136 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=73.8, ups=1.15, wpb=64, bsz=64, num_updates=1120, lr=6.08696e-06, gnorm=2.91, loss_scale=1, train_wall=9, gb_free=14.1, wall=1419
2022-04-25 10:05:54 - progress_bar.py[line:272] - INFO: epoch 001:   1135 / 6136 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=74.1, ups=1.16, wpb=64, bsz=64, num_updates=1130, lr=6.1413e-06, gnorm=3.048, loss_scale=1, train_wall=9, gb_free=13.5, wall=1427
2022-04-25 10:06:03 - progress_bar.py[line:272] - INFO: epoch 001:   1145 / 6136 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=72.4, ups=1.13, wpb=64, bsz=64, num_updates=1140, lr=6.19565e-06, gnorm=2.789, loss_scale=1, train_wall=9, gb_free=13.6, wall=1436
2022-04-25 10:06:11 - progress_bar.py[line:272] - INFO: epoch 001:   1155 / 6136 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=73.6, ups=1.15, wpb=64, bsz=64, num_updates=1150, lr=6.25e-06, gnorm=3.056, loss_scale=1, train_wall=9, gb_free=14, wall=1445
2022-04-25 10:06:20 - progress_bar.py[line:272] - INFO: epoch 001:   1165 / 6136 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=74.2, ups=1.16, wpb=64, bsz=64, num_updates=1160, lr=6.30435e-06, gnorm=3.055, loss_scale=1, train_wall=9, gb_free=11.9, wall=1454
2022-04-25 10:06:29 - progress_bar.py[line:272] - INFO: epoch 001:   1175 / 6136 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=73.1, ups=1.14, wpb=64, bsz=64, num_updates=1170, lr=6.3587e-06, gnorm=3.36, loss_scale=1, train_wall=9, gb_free=13.7, wall=1462
2022-04-25 10:06:39 - progress_bar.py[line:272] - INFO: epoch 001:   1185 / 6136 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=64.1, ups=1, wpb=64, bsz=64, num_updates=1180, lr=6.41304e-06, gnorm=3.418, loss_scale=1, train_wall=10, gb_free=13.1, wall=1472
2022-04-25 10:06:47 - progress_bar.py[line:272] - INFO: epoch 001:   1195 / 6136 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=72.4, ups=1.13, wpb=64, bsz=64, num_updates=1190, lr=6.46739e-06, gnorm=3.264, loss_scale=1, train_wall=9, gb_free=13.2, wall=1481
2022-04-25 10:06:56 - progress_bar.py[line:272] - INFO: epoch 001:   1205 / 6136 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=74.1, ups=1.16, wpb=64, bsz=64, num_updates=1200, lr=6.52174e-06, gnorm=3.732, loss_scale=1, train_wall=9, gb_free=13.7, wall=1490
2022-04-25 10:07:05 - progress_bar.py[line:272] - INFO: epoch 001:   1215 / 6136 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=70.7, ups=1.1, wpb=64, bsz=64, num_updates=1210, lr=6.57609e-06, gnorm=2.837, loss_scale=1, train_wall=9, gb_free=12.8, wall=1499
2022-04-25 10:07:14 - progress_bar.py[line:272] - INFO: epoch 001:   1225 / 6136 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=74.3, ups=1.16, wpb=64, bsz=64, num_updates=1220, lr=6.63043e-06, gnorm=3.086, loss_scale=1, train_wall=9, gb_free=14.3, wall=1508
2022-04-25 10:07:23 - progress_bar.py[line:272] - INFO: epoch 001:   1235 / 6136 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=73.2, ups=1.14, wpb=64, bsz=64, num_updates=1230, lr=6.68478e-06, gnorm=3.125, loss_scale=1, train_wall=9, gb_free=13.7, wall=1516
2022-04-25 10:07:32 - progress_bar.py[line:272] - INFO: epoch 001:   1245 / 6136 loss=2.1, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=66.6, ups=1.04, wpb=64, bsz=64, num_updates=1240, lr=6.73913e-06, gnorm=3.048, loss_scale=1, train_wall=10, gb_free=13.9, wall=1526
2022-04-25 10:07:41 - progress_bar.py[line:272] - INFO: epoch 001:   1255 / 6136 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=72, ups=1.12, wpb=64, bsz=64, num_updates=1250, lr=6.79348e-06, gnorm=2.821, loss_scale=1, train_wall=9, gb_free=12.6, wall=1535
2022-04-25 10:07:50 - progress_bar.py[line:272] - INFO: epoch 001:   1265 / 6136 loss=2.086, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=71.1, ups=1.11, wpb=64, bsz=64, num_updates=1260, lr=6.84783e-06, gnorm=3.584, loss_scale=1, train_wall=9, gb_free=14.2, wall=1544
2022-04-25 10:07:59 - progress_bar.py[line:272] - INFO: epoch 001:   1275 / 6136 loss=2.103, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=70.8, ups=1.11, wpb=64, bsz=64, num_updates=1270, lr=6.90217e-06, gnorm=3.095, loss_scale=1, train_wall=9, gb_free=13.6, wall=1553
2022-04-25 10:08:08 - progress_bar.py[line:272] - INFO: epoch 001:   1285 / 6136 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=72.4, ups=1.13, wpb=64, bsz=64, num_updates=1280, lr=6.95652e-06, gnorm=2.792, loss_scale=1, train_wall=9, gb_free=13.9, wall=1562
2022-04-25 10:08:17 - progress_bar.py[line:272] - INFO: epoch 001:   1295 / 6136 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=67.9, ups=1.06, wpb=64, bsz=64, num_updates=1290, lr=7.01087e-06, gnorm=2.816, loss_scale=1, train_wall=9, gb_free=9.3, wall=1571
2022-04-25 10:08:26 - progress_bar.py[line:272] - INFO: epoch 001:   1305 / 6136 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=72.8, ups=1.14, wpb=64, bsz=64, num_updates=1300, lr=7.06522e-06, gnorm=3.572, loss_scale=1, train_wall=9, gb_free=13.8, wall=1580
2022-04-25 10:08:35 - progress_bar.py[line:272] - INFO: epoch 001:   1315 / 6136 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=72.2, ups=1.13, wpb=64, bsz=64, num_updates=1310, lr=7.11957e-06, gnorm=2.958, loss_scale=1, train_wall=9, gb_free=13.2, wall=1589
2022-04-25 10:08:44 - progress_bar.py[line:272] - INFO: epoch 001:   1325 / 6136 loss=2.07, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=73.1, ups=1.14, wpb=64, bsz=64, num_updates=1320, lr=7.17391e-06, gnorm=2.686, loss_scale=1, train_wall=9, gb_free=13.7, wall=1597
2022-04-25 10:08:53 - progress_bar.py[line:272] - INFO: epoch 001:   1335 / 6136 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=66.1, ups=1.03, wpb=64, bsz=64, num_updates=1330, lr=7.22826e-06, gnorm=4.381, loss_scale=1, train_wall=10, gb_free=13.5, wall=1607
2022-04-25 10:09:02 - progress_bar.py[line:272] - INFO: epoch 001:   1345 / 6136 loss=2.078, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=73.2, ups=1.14, wpb=64, bsz=64, num_updates=1340, lr=7.28261e-06, gnorm=3.28, loss_scale=1, train_wall=9, gb_free=13.4, wall=1616
2022-04-25 10:09:11 - progress_bar.py[line:272] - INFO: epoch 001:   1355 / 6136 loss=2.07, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=71.4, ups=1.12, wpb=64, bsz=64, num_updates=1350, lr=7.33696e-06, gnorm=3.142, loss_scale=1, train_wall=9, gb_free=13.8, wall=1625
2022-04-25 10:09:21 - progress_bar.py[line:272] - INFO: epoch 001:   1365 / 6136 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=64.7, ups=1.01, wpb=64, bsz=64, num_updates=1360, lr=7.3913e-06, gnorm=3.783, loss_scale=1, train_wall=10, gb_free=6.4, wall=1635
2022-04-25 10:09:30 - progress_bar.py[line:272] - INFO: epoch 001:   1375 / 6136 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=71.8, ups=1.12, wpb=64, bsz=64, num_updates=1370, lr=7.44565e-06, gnorm=3.06, loss_scale=1, train_wall=9, gb_free=13.5, wall=1644
2022-04-25 10:09:39 - progress_bar.py[line:272] - INFO: epoch 001:   1385 / 6136 loss=2.065, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=72.2, ups=1.13, wpb=64, bsz=64, num_updates=1380, lr=7.5e-06, gnorm=3.215, loss_scale=1, train_wall=9, gb_free=14.1, wall=1653
2022-04-25 10:09:48 - progress_bar.py[line:272] - INFO: epoch 001:   1395 / 6136 loss=2.089, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=71.4, ups=1.12, wpb=64, bsz=64, num_updates=1390, lr=7.55435e-06, gnorm=3.451, loss_scale=1, train_wall=9, gb_free=12.4, wall=1662
2022-04-25 10:09:57 - progress_bar.py[line:272] - INFO: epoch 001:   1405 / 6136 loss=2.077, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=71.1, ups=1.11, wpb=64, bsz=64, num_updates=1400, lr=7.6087e-06, gnorm=2.693, loss_scale=1, train_wall=9, gb_free=13.1, wall=1671
2022-04-25 10:10:06 - progress_bar.py[line:272] - INFO: epoch 001:   1415 / 6136 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=72, ups=1.12, wpb=64, bsz=64, num_updates=1410, lr=7.66304e-06, gnorm=3.651, loss_scale=2, train_wall=9, gb_free=13.3, wall=1679
2022-04-25 10:10:15 - progress_bar.py[line:272] - INFO: epoch 001:   1425 / 6136 loss=2.058, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=65.7, ups=1.03, wpb=64, bsz=64, num_updates=1420, lr=7.71739e-06, gnorm=2.926, loss_scale=2, train_wall=10, gb_free=13.8, wall=1689
2022-04-25 10:10:25 - progress_bar.py[line:272] - INFO: epoch 001:   1435 / 6136 loss=2.063, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=65.6, ups=1.03, wpb=64, bsz=64, num_updates=1430, lr=7.77174e-06, gnorm=4.064, loss_scale=2, train_wall=10, gb_free=13.7, wall=1699
2022-04-25 10:10:35 - progress_bar.py[line:272] - INFO: epoch 001:   1445 / 6136 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=65.3, ups=1.02, wpb=64, bsz=64, num_updates=1440, lr=7.82609e-06, gnorm=3.643, loss_scale=2, train_wall=10, gb_free=7.6, wall=1709
2022-04-25 10:10:44 - progress_bar.py[line:272] - INFO: epoch 001:   1455 / 6136 loss=2.059, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=72.3, ups=1.13, wpb=64, bsz=64, num_updates=1450, lr=7.88043e-06, gnorm=3.224, loss_scale=2, train_wall=9, gb_free=12.6, wall=1718
2022-04-25 10:10:53 - progress_bar.py[line:272] - INFO: epoch 001:   1465 / 6136 loss=2.085, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=73.4, ups=1.15, wpb=64, bsz=64, num_updates=1460, lr=7.93478e-06, gnorm=4.024, loss_scale=2, train_wall=9, gb_free=13.8, wall=1726
2022-04-25 10:11:01 - progress_bar.py[line:272] - INFO: epoch 001:   1475 / 6136 loss=2.072, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=73.7, ups=1.15, wpb=64, bsz=64, num_updates=1470, lr=7.98913e-06, gnorm=3.508, loss_scale=2, train_wall=9, gb_free=13.8, wall=1735
2022-04-25 10:11:10 - progress_bar.py[line:272] - INFO: epoch 001:   1485 / 6136 loss=2.05, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=73.2, ups=1.14, wpb=64, bsz=64, num_updates=1480, lr=8.04348e-06, gnorm=2.911, loss_scale=2, train_wall=9, gb_free=14.1, wall=1744
2022-04-25 10:11:19 - progress_bar.py[line:272] - INFO: epoch 001:   1495 / 6136 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=71.6, ups=1.12, wpb=64, bsz=64, num_updates=1490, lr=8.09783e-06, gnorm=3.647, loss_scale=2, train_wall=9, gb_free=13.4, wall=1753
2022-04-25 10:11:29 - progress_bar.py[line:272] - INFO: epoch 001:   1505 / 6136 loss=2.075, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=66.4, ups=1.04, wpb=64, bsz=64, num_updates=1500, lr=8.15217e-06, gnorm=3.178, loss_scale=2, train_wall=10, gb_free=13.9, wall=1762
2022-04-25 10:11:39 - progress_bar.py[line:272] - INFO: epoch 001:   1515 / 6136 loss=2.049, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=58.9, ups=0.92, wpb=64, bsz=64, num_updates=1510, lr=8.20652e-06, gnorm=3.146, loss_scale=2, train_wall=11, gb_free=10.7, wall=1773
2022-04-25 10:11:48 - progress_bar.py[line:272] - INFO: epoch 001:   1525 / 6136 loss=2.056, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=73.6, ups=1.15, wpb=64, bsz=64, num_updates=1520, lr=8.26087e-06, gnorm=4.309, loss_scale=2, train_wall=9, gb_free=13.8, wall=1782
2022-04-25 10:11:57 - progress_bar.py[line:272] - INFO: epoch 001:   1535 / 6136 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=71.9, ups=1.12, wpb=64, bsz=64, num_updates=1530, lr=8.31522e-06, gnorm=3.007, loss_scale=2, train_wall=9, gb_free=13.8, wall=1791
2022-04-25 10:12:06 - progress_bar.py[line:272] - INFO: epoch 001:   1545 / 6136 loss=2.002, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=69.2, ups=1.08, wpb=64, bsz=64, num_updates=1540, lr=8.36957e-06, gnorm=2.916, loss_scale=2, train_wall=9, gb_free=12, wall=1800
2022-04-25 10:12:15 - progress_bar.py[line:272] - INFO: epoch 001:   1555 / 6136 loss=2.031, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=72.3, ups=1.13, wpb=64, bsz=64, num_updates=1550, lr=8.42391e-06, gnorm=3.076, loss_scale=2, train_wall=9, gb_free=13.5, wall=1809
2022-04-25 10:12:24 - progress_bar.py[line:272] - INFO: epoch 001:   1565 / 6136 loss=2.058, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=73.5, ups=1.15, wpb=64, bsz=64, num_updates=1560, lr=8.47826e-06, gnorm=4.085, loss_scale=2, train_wall=9, gb_free=13.6, wall=1818
2022-04-25 10:12:33 - progress_bar.py[line:272] - INFO: epoch 001:   1575 / 6136 loss=2.013, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=70.7, ups=1.1, wpb=64, bsz=64, num_updates=1570, lr=8.53261e-06, gnorm=3.077, loss_scale=2, train_wall=9, gb_free=14, wall=1827
2022-04-25 10:12:42 - progress_bar.py[line:272] - INFO: epoch 001:   1585 / 6136 loss=2.032, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=72.4, ups=1.13, wpb=64, bsz=64, num_updates=1580, lr=8.58696e-06, gnorm=3.668, loss_scale=2, train_wall=9, gb_free=12, wall=1835
2022-04-25 10:12:51 - progress_bar.py[line:272] - INFO: epoch 001:   1595 / 6136 loss=2.002, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=71.4, ups=1.12, wpb=64, bsz=64, num_updates=1590, lr=8.6413e-06, gnorm=3.067, loss_scale=2, train_wall=9, gb_free=13.5, wall=1844
2022-04-25 10:13:00 - progress_bar.py[line:272] - INFO: epoch 001:   1605 / 6136 loss=2.011, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=71.7, ups=1.12, wpb=64, bsz=64, num_updates=1600, lr=8.69565e-06, gnorm=3.775, loss_scale=2, train_wall=9, gb_free=13.5, wall=1853
2022-04-25 10:13:09 - progress_bar.py[line:272] - INFO: epoch 001:   1615 / 6136 loss=1.987, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=67.5, ups=1.05, wpb=64, bsz=64, num_updates=1610, lr=8.75e-06, gnorm=3.583, loss_scale=2, train_wall=9, gb_free=13.9, wall=1863
2022-04-25 10:13:18 - progress_bar.py[line:272] - INFO: epoch 001:   1625 / 6136 loss=2.001, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=71.8, ups=1.12, wpb=64, bsz=64, num_updates=1620, lr=8.80435e-06, gnorm=3.016, loss_scale=2, train_wall=9, gb_free=13.7, wall=1872
2022-04-25 10:13:27 - progress_bar.py[line:272] - INFO: epoch 001:   1635 / 6136 loss=2.006, loss_v1=0, loss_v2=0, nll_loss=1.004, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=73.7, ups=1.15, wpb=64, bsz=64, num_updates=1630, lr=8.8587e-06, gnorm=3.052, loss_scale=2, train_wall=9, gb_free=13.1, wall=1880
2022-04-25 10:13:36 - progress_bar.py[line:272] - INFO: epoch 001:   1645 / 6136 loss=1.996, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=67.9, ups=1.06, wpb=64, bsz=64, num_updates=1640, lr=8.91304e-06, gnorm=3.646, loss_scale=2, train_wall=9, gb_free=12.8, wall=1890
2022-04-25 10:13:45 - progress_bar.py[line:272] - INFO: epoch 001:   1655 / 6136 loss=2.018, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=75, ups=1.17, wpb=64, bsz=64, num_updates=1650, lr=8.96739e-06, gnorm=4.301, loss_scale=2, train_wall=8, gb_free=14, wall=1898
2022-04-25 10:13:54 - progress_bar.py[line:272] - INFO: epoch 001:   1665 / 6136 loss=2.027, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=71.4, ups=1.12, wpb=64, bsz=64, num_updates=1660, lr=9.02174e-06, gnorm=4.02, loss_scale=2, train_wall=9, gb_free=13.8, wall=1907
2022-04-25 10:14:02 - progress_bar.py[line:272] - INFO: epoch 001:   1675 / 6136 loss=2.008, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=74.4, ups=1.16, wpb=64, bsz=64, num_updates=1670, lr=9.07609e-06, gnorm=4.102, loss_scale=2, train_wall=9, gb_free=13.2, wall=1916
2022-04-25 10:14:11 - progress_bar.py[line:272] - INFO: epoch 001:   1685 / 6136 loss=2.003, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=74.1, ups=1.16, wpb=64, bsz=64, num_updates=1680, lr=9.13043e-06, gnorm=3.975, loss_scale=2, train_wall=9, gb_free=13.6, wall=1925
2022-04-25 10:14:19 - progress_bar.py[line:272] - INFO: epoch 001:   1695 / 6136 loss=1.986, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=74.5, ups=1.16, wpb=64, bsz=64, num_updates=1690, lr=9.18478e-06, gnorm=3.927, loss_scale=2, train_wall=9, gb_free=13.9, wall=1933
2022-04-25 10:14:28 - progress_bar.py[line:272] - INFO: epoch 001:   1705 / 6136 loss=2.002, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=72.8, ups=1.14, wpb=64, bsz=64, num_updates=1700, lr=9.23913e-06, gnorm=3.209, loss_scale=2, train_wall=9, gb_free=13.2, wall=1942
2022-04-25 10:14:38 - progress_bar.py[line:272] - INFO: epoch 001:   1715 / 6136 loss=1.973, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=67.8, ups=1.06, wpb=64, bsz=64, num_updates=1710, lr=9.29348e-06, gnorm=3.811, loss_scale=2, train_wall=9, gb_free=14, wall=1951
2022-04-25 10:14:47 - progress_bar.py[line:272] - INFO: epoch 001:   1725 / 6136 loss=1.954, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=72.7, ups=1.14, wpb=64, bsz=64, num_updates=1720, lr=9.34783e-06, gnorm=3.487, loss_scale=2, train_wall=9, gb_free=14.2, wall=1960
2022-04-25 10:14:56 - progress_bar.py[line:272] - INFO: epoch 001:   1735 / 6136 loss=1.997, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=66.2, ups=1.03, wpb=64, bsz=64, num_updates=1730, lr=9.40217e-06, gnorm=4.097, loss_scale=2, train_wall=10, gb_free=13, wall=1970
2022-04-25 10:15:05 - progress_bar.py[line:272] - INFO: epoch 001:   1745 / 6136 loss=1.957, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=73.8, ups=1.15, wpb=64, bsz=64, num_updates=1740, lr=9.45652e-06, gnorm=4.146, loss_scale=2, train_wall=9, gb_free=14, wall=1979
2022-04-25 10:15:15 - progress_bar.py[line:272] - INFO: epoch 001:   1755 / 6136 loss=1.986, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=65.2, ups=1.02, wpb=64, bsz=64, num_updates=1750, lr=9.51087e-06, gnorm=4.316, loss_scale=2, train_wall=10, gb_free=13.1, wall=1988
2022-04-25 10:15:24 - progress_bar.py[line:272] - INFO: epoch 001:   1765 / 6136 loss=1.958, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=67.4, ups=1.05, wpb=64, bsz=64, num_updates=1760, lr=9.56522e-06, gnorm=3.076, loss_scale=2, train_wall=9, gb_free=14.1, wall=1998
2022-04-25 10:15:33 - progress_bar.py[line:272] - INFO: epoch 001:   1775 / 6136 loss=1.967, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=72.9, ups=1.14, wpb=64, bsz=64, num_updates=1770, lr=9.61957e-06, gnorm=4.261, loss_scale=2, train_wall=9, gb_free=13.1, wall=2007
2022-04-25 10:15:42 - progress_bar.py[line:272] - INFO: epoch 001:   1785 / 6136 loss=1.969, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=72.5, ups=1.13, wpb=64, bsz=64, num_updates=1780, lr=9.67391e-06, gnorm=4.024, loss_scale=2, train_wall=9, gb_free=13.6, wall=2016
2022-04-25 10:15:51 - progress_bar.py[line:272] - INFO: epoch 001:   1795 / 6136 loss=1.961, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=69, ups=1.08, wpb=64, bsz=64, num_updates=1790, lr=9.72826e-06, gnorm=3.249, loss_scale=2, train_wall=9, gb_free=13.6, wall=2025
2022-04-25 10:16:00 - progress_bar.py[line:272] - INFO: epoch 001:   1805 / 6136 loss=2.013, loss_v1=0, loss_v2=0, nll_loss=1.012, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=73.9, ups=1.15, wpb=64, bsz=64, num_updates=1800, lr=9.78261e-06, gnorm=4.057, loss_scale=2, train_wall=9, gb_free=13.9, wall=2033
2022-04-25 10:16:08 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2022-04-25 10:16:09 - progress_bar.py[line:272] - INFO: epoch 001:   1816 / 6136 loss=1.953, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=66.5, ups=1.04, wpb=64, bsz=64, num_updates=1810, lr=9.83696e-06, gnorm=4.238, loss_scale=1, train_wall=10, gb_free=10.8, wall=2043
2022-04-25 10:16:18 - progress_bar.py[line:272] - INFO: epoch 001:   1826 / 6136 loss=1.927, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=73.6, ups=1.15, wpb=64, bsz=64, num_updates=1820, lr=9.8913e-06, gnorm=3.61, loss_scale=1, train_wall=9, gb_free=11.3, wall=2052
2022-04-25 10:16:27 - progress_bar.py[line:272] - INFO: epoch 001:   1836 / 6136 loss=1.937, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=74, ups=1.16, wpb=64, bsz=64, num_updates=1830, lr=9.94565e-06, gnorm=3.588, loss_scale=1, train_wall=9, gb_free=13.6, wall=2060
2022-04-25 10:16:35 - progress_bar.py[line:272] - INFO: epoch 001:   1846 / 6136 loss=1.915, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=74.2, ups=1.16, wpb=64, bsz=64, num_updates=1840, lr=1e-05, gnorm=3.322, loss_scale=1, train_wall=9, gb_free=13, wall=2069
2022-04-25 10:16:44 - progress_bar.py[line:272] - INFO: epoch 001:   1856 / 6136 loss=1.924, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=72.9, ups=1.14, wpb=64, bsz=64, num_updates=1850, lr=9.99653e-06, gnorm=3.253, loss_scale=1, train_wall=9, gb_free=13.5, wall=2078
2022-04-25 10:16:53 - progress_bar.py[line:272] - INFO: epoch 001:   1866 / 6136 loss=1.942, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=75.3, ups=1.18, wpb=64, bsz=64, num_updates=1860, lr=9.99307e-06, gnorm=3.779, loss_scale=1, train_wall=8, gb_free=13.7, wall=2086
2022-04-25 10:17:01 - progress_bar.py[line:272] - INFO: epoch 001:   1876 / 6136 loss=1.942, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=72.5, ups=1.13, wpb=64, bsz=64, num_updates=1870, lr=9.9896e-06, gnorm=3.989, loss_scale=1, train_wall=9, gb_free=13.4, wall=2095
2022-04-25 10:17:10 - progress_bar.py[line:272] - INFO: epoch 001:   1886 / 6136 loss=1.978, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=76.2, ups=1.19, wpb=64, bsz=64, num_updates=1880, lr=9.98613e-06, gnorm=4.004, loss_scale=1, train_wall=8, gb_free=13.2, wall=2104
2022-04-25 10:17:19 - progress_bar.py[line:272] - INFO: epoch 001:   1896 / 6136 loss=1.885, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=72.6, ups=1.13, wpb=64, bsz=64, num_updates=1890, lr=9.98266e-06, gnorm=3.376, loss_scale=1, train_wall=9, gb_free=14, wall=2112
2022-04-25 10:17:27 - progress_bar.py[line:272] - INFO: epoch 001:   1906 / 6136 loss=1.919, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=74.8, ups=1.17, wpb=64, bsz=64, num_updates=1900, lr=9.9792e-06, gnorm=4.355, loss_scale=1, train_wall=8, gb_free=13.4, wall=2121
2022-04-25 10:17:36 - progress_bar.py[line:272] - INFO: epoch 001:   1916 / 6136 loss=1.942, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=73.6, ups=1.15, wpb=64, bsz=64, num_updates=1910, lr=9.97573e-06, gnorm=3.549, loss_scale=1, train_wall=9, gb_free=13.9, wall=2130
2022-04-25 10:17:44 - progress_bar.py[line:272] - INFO: epoch 001:   1926 / 6136 loss=1.872, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=75.6, ups=1.18, wpb=64, bsz=64, num_updates=1920, lr=9.97226e-06, gnorm=3.521, loss_scale=1, train_wall=8, gb_free=13.6, wall=2138
2022-04-25 10:17:53 - progress_bar.py[line:272] - INFO: epoch 001:   1936 / 6136 loss=1.927, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=74.1, ups=1.16, wpb=64, bsz=64, num_updates=1930, lr=9.96879e-06, gnorm=3.356, loss_scale=1, train_wall=9, gb_free=14.1, wall=2147
2022-04-25 10:18:01 - progress_bar.py[line:272] - INFO: epoch 001:   1946 / 6136 loss=1.919, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=75.8, ups=1.18, wpb=64, bsz=64, num_updates=1940, lr=9.96533e-06, gnorm=3.694, loss_scale=1, train_wall=8, gb_free=12.8, wall=2155
2022-04-25 10:18:10 - progress_bar.py[line:272] - INFO: epoch 001:   1956 / 6136 loss=1.919, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=73.6, ups=1.15, wpb=64, bsz=64, num_updates=1950, lr=9.96186e-06, gnorm=3.763, loss_scale=1, train_wall=9, gb_free=13.5, wall=2164
2022-04-25 10:18:19 - progress_bar.py[line:272] - INFO: epoch 001:   1966 / 6136 loss=1.919, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=73.3, ups=1.15, wpb=64, bsz=64, num_updates=1960, lr=9.95839e-06, gnorm=3.381, loss_scale=1, train_wall=9, gb_free=13.1, wall=2173
2022-04-25 10:18:28 - progress_bar.py[line:272] - INFO: epoch 001:   1976 / 6136 loss=1.88, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=72.8, ups=1.14, wpb=64, bsz=64, num_updates=1970, lr=9.95492e-06, gnorm=3.72, loss_scale=1, train_wall=9, gb_free=13, wall=2181
2022-04-25 10:18:36 - progress_bar.py[line:272] - INFO: epoch 001:   1986 / 6136 loss=1.92, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=73.7, ups=1.15, wpb=64, bsz=64, num_updates=1980, lr=9.95146e-06, gnorm=3.467, loss_scale=1, train_wall=9, gb_free=13.7, wall=2190
2022-04-25 10:18:45 - progress_bar.py[line:272] - INFO: epoch 001:   1996 / 6136 loss=1.925, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=72.5, ups=1.13, wpb=64, bsz=64, num_updates=1990, lr=9.94799e-06, gnorm=3.833, loss_scale=1, train_wall=9, gb_free=12.1, wall=2199
2022-04-25 10:18:53 - progress_bar.py[line:272] - INFO: epoch 001:   2006 / 6136 loss=1.894, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=76.9, ups=1.2, wpb=64, bsz=64, num_updates=2000, lr=9.94452e-06, gnorm=4.181, loss_scale=1, train_wall=8, gb_free=13.8, wall=2207
2022-04-25 10:18:53 - train.py[line:435] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2022-04-25 10:23:02 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:02 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:02 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:02 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:02 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:02 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:02 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:02 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:02 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:03 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:03 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:03 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:03 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:03 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:03 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:03 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:03 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:03 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:03 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:03 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:03 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:03 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:03 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:03 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:23:03 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 1.845 | loss_v1 0 | loss_v2 0 | nll_loss 0.842 | ntokens 15.999 | nsentences 15.999 | sample_size 15.999 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.79 | acc 0.6229 | wps 79 | wpb 16 | bsz 16 | num_updates 2000 | best_acc 0.6229
2022-04-25 10:23:03 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 2000 updates
2022-04-25 10:23:03 - trainer.py[line:432] - INFO: Saving checkpoint to ./fairseq_checkpoints/mnli/5_1e-5_4/checkpoint_1_2000.pt
2022-04-25 10:23:21 - trainer.py[line:442] - INFO: Finished saving checkpoint to ./fairseq_checkpoints/mnli/5_1e-5_4/checkpoint_1_2000.pt
2022-04-25 10:23:44 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./fairseq_checkpoints/mnli/5_1e-5_4/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 0.6229) (writing took 41.09064770489931 seconds)
2022-04-25 10:23:53 - progress_bar.py[line:272] - INFO: epoch 001:   2016 / 6136 loss=1.875, loss_v1=0, loss_v2=0, nll_loss=0.873, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=2.1, ups=0.03, wpb=64, bsz=64, num_updates=2010, lr=9.94105e-06, gnorm=4.116, loss_scale=1, train_wall=8, gb_free=12.7, wall=2507
2022-04-25 10:24:02 - progress_bar.py[line:272] - INFO: epoch 001:   2026 / 6136 loss=1.861, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=70.6, ups=1.1, wpb=64, bsz=64, num_updates=2020, lr=9.93759e-06, gnorm=3.471, loss_scale=1, train_wall=9, gb_free=13.8, wall=2516
2022-04-25 10:24:10 - progress_bar.py[line:272] - INFO: epoch 001:   2036 / 6136 loss=1.84, loss_v1=0, loss_v2=0, nll_loss=0.838, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=75.7, ups=1.18, wpb=64, bsz=64, num_updates=2030, lr=9.93412e-06, gnorm=3.259, loss_scale=1, train_wall=8, gb_free=14.1, wall=2524
2022-04-25 10:24:19 - progress_bar.py[line:272] - INFO: epoch 001:   2046 / 6136 loss=1.875, loss_v1=0, loss_v2=0, nll_loss=0.873, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=74.3, ups=1.16, wpb=64, bsz=64, num_updates=2040, lr=9.93065e-06, gnorm=3.533, loss_scale=1, train_wall=9, gb_free=12.1, wall=2533
2022-04-25 10:24:29 - progress_bar.py[line:272] - INFO: epoch 001:   2056 / 6136 loss=1.873, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=63.6, ups=0.99, wpb=64, bsz=64, num_updates=2050, lr=9.92718e-06, gnorm=3.469, loss_scale=1, train_wall=10, gb_free=14.2, wall=2543
2022-04-25 10:24:37 - progress_bar.py[line:272] - INFO: epoch 001:   2066 / 6136 loss=1.867, loss_v1=0, loss_v2=0, nll_loss=0.865, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=75.8, ups=1.18, wpb=64, bsz=64, num_updates=2060, lr=9.92372e-06, gnorm=4.073, loss_scale=1, train_wall=8, gb_free=12, wall=2551
2022-04-25 10:24:46 - progress_bar.py[line:272] - INFO: epoch 001:   2076 / 6136 loss=1.886, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=75.4, ups=1.18, wpb=64, bsz=64, num_updates=2070, lr=9.92025e-06, gnorm=3.469, loss_scale=1, train_wall=8, gb_free=14, wall=2560
2022-04-25 10:24:55 - progress_bar.py[line:272] - INFO: epoch 001:   2086 / 6136 loss=1.862, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=74.1, ups=1.16, wpb=64, bsz=64, num_updates=2080, lr=9.91678e-06, gnorm=3.553, loss_scale=1, train_wall=9, gb_free=13.2, wall=2568
2022-04-25 10:25:03 - progress_bar.py[line:272] - INFO: epoch 001:   2096 / 6136 loss=1.84, loss_v1=0, loss_v2=0, nll_loss=0.838, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=73, ups=1.14, wpb=64, bsz=64, num_updates=2090, lr=9.91331e-06, gnorm=3.039, loss_scale=1, train_wall=9, gb_free=13.7, wall=2577
2022-04-25 10:25:13 - progress_bar.py[line:272] - INFO: epoch 001:   2106 / 6136 loss=1.915, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=68.1, ups=1.06, wpb=64, bsz=64, num_updates=2100, lr=9.90985e-06, gnorm=3.552, loss_scale=1, train_wall=9, gb_free=14, wall=2587
2022-04-25 10:25:21 - progress_bar.py[line:272] - INFO: epoch 001:   2116 / 6136 loss=1.846, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=74, ups=1.16, wpb=64, bsz=64, num_updates=2110, lr=9.90638e-06, gnorm=3.327, loss_scale=1, train_wall=9, gb_free=12.3, wall=2595
2022-04-25 10:25:30 - progress_bar.py[line:272] - INFO: epoch 001:   2126 / 6136 loss=1.86, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=75.7, ups=1.18, wpb=64, bsz=64, num_updates=2120, lr=9.90291e-06, gnorm=3.451, loss_scale=1, train_wall=8, gb_free=13.7, wall=2604
2022-04-25 10:25:39 - progress_bar.py[line:272] - INFO: epoch 001:   2136 / 6136 loss=1.864, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=66.7, ups=1.04, wpb=64, bsz=64, num_updates=2130, lr=9.89945e-06, gnorm=3.823, loss_scale=1, train_wall=10, gb_free=13.3, wall=2613
2022-04-25 10:25:48 - progress_bar.py[line:272] - INFO: epoch 001:   2146 / 6136 loss=1.881, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=73.2, ups=1.14, wpb=64, bsz=64, num_updates=2140, lr=9.89598e-06, gnorm=3.825, loss_scale=1, train_wall=9, gb_free=14.1, wall=2622
2022-04-25 10:25:57 - progress_bar.py[line:272] - INFO: epoch 001:   2156 / 6136 loss=1.874, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=74.9, ups=1.17, wpb=64, bsz=64, num_updates=2150, lr=9.89251e-06, gnorm=3.316, loss_scale=1, train_wall=8, gb_free=13.7, wall=2630
2022-04-25 10:26:05 - progress_bar.py[line:272] - INFO: epoch 001:   2166 / 6136 loss=1.873, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=73.9, ups=1.15, wpb=64, bsz=64, num_updates=2160, lr=9.88904e-06, gnorm=3.322, loss_scale=1, train_wall=9, gb_free=13.4, wall=2639
2022-04-25 10:26:14 - progress_bar.py[line:272] - INFO: epoch 001:   2176 / 6136 loss=1.869, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=73, ups=1.14, wpb=64, bsz=64, num_updates=2170, lr=9.88558e-06, gnorm=3.787, loss_scale=1, train_wall=9, gb_free=13.6, wall=2648
2022-04-25 10:26:23 - progress_bar.py[line:272] - INFO: epoch 001:   2186 / 6136 loss=1.864, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=70.4, ups=1.1, wpb=64, bsz=64, num_updates=2180, lr=9.88211e-06, gnorm=3.109, loss_scale=1, train_wall=9, gb_free=13.1, wall=2657
2022-04-25 10:26:32 - progress_bar.py[line:272] - INFO: epoch 001:   2196 / 6136 loss=1.845, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=72.8, ups=1.14, wpb=64, bsz=64, num_updates=2190, lr=9.87864e-06, gnorm=3.438, loss_scale=1, train_wall=9, gb_free=13.8, wall=2666
2022-04-25 10:26:41 - progress_bar.py[line:272] - INFO: epoch 001:   2206 / 6136 loss=1.877, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=71.8, ups=1.12, wpb=64, bsz=64, num_updates=2200, lr=9.87517e-06, gnorm=3.745, loss_scale=1, train_wall=9, gb_free=13, wall=2675
2022-04-25 10:26:50 - progress_bar.py[line:272] - INFO: epoch 001:   2216 / 6136 loss=1.884, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=72.9, ups=1.14, wpb=64, bsz=64, num_updates=2210, lr=9.87171e-06, gnorm=3.522, loss_scale=1, train_wall=9, gb_free=13.4, wall=2683
2022-04-25 10:26:58 - progress_bar.py[line:272] - INFO: epoch 001:   2226 / 6136 loss=1.883, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=73.9, ups=1.15, wpb=64, bsz=64, num_updates=2220, lr=9.86824e-06, gnorm=4.209, loss_scale=1, train_wall=9, gb_free=12.9, wall=2692
2022-04-25 10:27:07 - progress_bar.py[line:272] - INFO: epoch 001:   2236 / 6136 loss=1.862, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=76.6, ups=1.2, wpb=64, bsz=64, num_updates=2230, lr=9.86477e-06, gnorm=3.051, loss_scale=1, train_wall=8, gb_free=13.8, wall=2701
2022-04-25 10:27:15 - progress_bar.py[line:272] - INFO: epoch 001:   2246 / 6136 loss=1.847, loss_v1=0, loss_v2=0, nll_loss=0.845, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=75.7, ups=1.18, wpb=64, bsz=64, num_updates=2240, lr=9.8613e-06, gnorm=3.129, loss_scale=1, train_wall=8, gb_free=13.3, wall=2709
2022-04-25 10:27:25 - progress_bar.py[line:272] - INFO: epoch 001:   2256 / 6136 loss=1.853, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=66.4, ups=1.04, wpb=64, bsz=64, num_updates=2250, lr=9.85784e-06, gnorm=3.505, loss_scale=1, train_wall=10, gb_free=13.4, wall=2719
2022-04-25 10:27:34 - progress_bar.py[line:272] - INFO: epoch 001:   2266 / 6136 loss=1.851, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=73.3, ups=1.15, wpb=64, bsz=64, num_updates=2260, lr=9.85437e-06, gnorm=3.708, loss_scale=1, train_wall=9, gb_free=12.6, wall=2727
2022-04-25 10:27:42 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2022-04-25 10:27:45 - progress_bar.py[line:272] - INFO: epoch 001:   2277 / 6136 loss=1.855, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=55.7, ups=0.87, wpb=64, bsz=64, num_updates=2270, lr=9.8509e-06, gnorm=3.315, loss_scale=0.5, train_wall=11, gb_free=13, wall=2739
2022-04-25 10:27:54 - progress_bar.py[line:272] - INFO: epoch 001:   2287 / 6136 loss=1.871, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=68.2, ups=1.07, wpb=64, bsz=64, num_updates=2280, lr=9.84743e-06, gnorm=3.84, loss_scale=0.5, train_wall=9, gb_free=13.4, wall=2748
2022-04-25 10:28:03 - progress_bar.py[line:272] - INFO: epoch 001:   2297 / 6136 loss=1.855, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=77.6, ups=1.21, wpb=64, bsz=64, num_updates=2290, lr=9.84397e-06, gnorm=4.356, loss_scale=0.5, train_wall=8, gb_free=13.3, wall=2756
2022-04-25 10:28:11 - progress_bar.py[line:272] - INFO: epoch 001:   2307 / 6136 loss=1.847, loss_v1=0, loss_v2=0, nll_loss=0.845, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=73.8, ups=1.15, wpb=64, bsz=64, num_updates=2300, lr=9.8405e-06, gnorm=3.322, loss_scale=0.5, train_wall=9, gb_free=13.5, wall=2765
2022-04-25 10:28:20 - progress_bar.py[line:272] - INFO: epoch 001:   2317 / 6136 loss=1.853, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=76.2, ups=1.19, wpb=64, bsz=64, num_updates=2310, lr=9.83703e-06, gnorm=3.222, loss_scale=0.5, train_wall=8, gb_free=13.2, wall=2774
2022-04-25 10:28:28 - progress_bar.py[line:272] - INFO: epoch 001:   2327 / 6136 loss=1.856, loss_v1=0, loss_v2=0, nll_loss=0.854, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=78.4, ups=1.22, wpb=64, bsz=64, num_updates=2320, lr=9.83356e-06, gnorm=3.592, loss_scale=0.5, train_wall=8, gb_free=13.5, wall=2782
2022-04-25 10:28:36 - progress_bar.py[line:272] - INFO: epoch 001:   2337 / 6136 loss=1.818, loss_v1=0, loss_v2=0, nll_loss=0.817, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=76.8, ups=1.2, wpb=64, bsz=64, num_updates=2330, lr=9.8301e-06, gnorm=3.745, loss_scale=0.5, train_wall=8, gb_free=13.2, wall=2790
2022-04-25 10:28:45 - progress_bar.py[line:272] - INFO: epoch 001:   2347 / 6136 loss=1.849, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=77.1, ups=1.2, wpb=64, bsz=64, num_updates=2340, lr=9.82663e-06, gnorm=3.566, loss_scale=0.5, train_wall=8, gb_free=12.8, wall=2798
2022-04-25 10:28:53 - progress_bar.py[line:272] - INFO: epoch 001:   2357 / 6136 loss=1.856, loss_v1=0, loss_v2=0, nll_loss=0.854, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=74, ups=1.16, wpb=64, bsz=64, num_updates=2350, lr=9.82316e-06, gnorm=3.821, loss_scale=0.5, train_wall=9, gb_free=13.6, wall=2807
2022-04-25 10:29:02 - progress_bar.py[line:272] - INFO: epoch 001:   2367 / 6136 loss=1.852, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=74.1, ups=1.16, wpb=64, bsz=64, num_updates=2360, lr=9.81969e-06, gnorm=3.851, loss_scale=0.5, train_wall=9, gb_free=12.8, wall=2816
2022-04-25 10:29:10 - progress_bar.py[line:272] - INFO: epoch 001:   2377 / 6136 loss=1.838, loss_v1=0, loss_v2=0, nll_loss=0.836, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=75.8, ups=1.18, wpb=64, bsz=64, num_updates=2370, lr=9.81623e-06, gnorm=3.146, loss_scale=0.5, train_wall=8, gb_free=12.4, wall=2824
2022-04-25 10:29:19 - progress_bar.py[line:272] - INFO: epoch 001:   2387 / 6136 loss=1.882, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=77.5, ups=1.21, wpb=64, bsz=64, num_updates=2380, lr=9.81276e-06, gnorm=3.329, loss_scale=0.5, train_wall=8, gb_free=12.7, wall=2832
2022-04-25 10:29:27 - progress_bar.py[line:272] - INFO: epoch 001:   2397 / 6136 loss=1.831, loss_v1=0, loss_v2=0, nll_loss=0.829, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=77.9, ups=1.22, wpb=64, bsz=64, num_updates=2390, lr=9.80929e-06, gnorm=3.557, loss_scale=0.5, train_wall=8, gb_free=13.2, wall=2841
2022-04-25 10:29:35 - progress_bar.py[line:272] - INFO: epoch 001:   2407 / 6136 loss=1.883, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=78.5, ups=1.23, wpb=64, bsz=64, num_updates=2400, lr=9.80583e-06, gnorm=3.882, loss_scale=0.5, train_wall=8, gb_free=11.6, wall=2849
2022-04-25 10:29:43 - progress_bar.py[line:272] - INFO: epoch 001:   2417 / 6136 loss=1.885, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=77.6, ups=1.21, wpb=64, bsz=64, num_updates=2410, lr=9.80236e-06, gnorm=3.556, loss_scale=0.5, train_wall=8, gb_free=14.2, wall=2857
2022-04-25 10:29:51 - progress_bar.py[line:272] - INFO: epoch 001:   2427 / 6136 loss=1.797, loss_v1=0, loss_v2=0, nll_loss=0.795, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=79.6, ups=1.24, wpb=64, bsz=64, num_updates=2420, lr=9.79889e-06, gnorm=3.422, loss_scale=0.5, train_wall=8, gb_free=13.1, wall=2865
2022-04-25 10:29:59 - progress_bar.py[line:272] - INFO: epoch 001:   2437 / 6136 loss=1.85, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=78.3, ups=1.22, wpb=64, bsz=64, num_updates=2430, lr=9.79542e-06, gnorm=3.4, loss_scale=0.5, train_wall=8, gb_free=13.7, wall=2873
2022-04-25 10:30:08 - progress_bar.py[line:272] - INFO: epoch 001:   2447 / 6136 loss=1.839, loss_v1=0, loss_v2=0, nll_loss=0.838, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=78.1, ups=1.22, wpb=64, bsz=64, num_updates=2440, lr=9.79196e-06, gnorm=3.242, loss_scale=0.5, train_wall=8, gb_free=13.5, wall=2881
2022-04-25 10:30:16 - progress_bar.py[line:272] - INFO: epoch 001:   2457 / 6136 loss=1.841, loss_v1=0, loss_v2=0, nll_loss=0.84, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=79.1, ups=1.24, wpb=64, bsz=64, num_updates=2450, lr=9.78849e-06, gnorm=3.505, loss_scale=0.5, train_wall=8, gb_free=14.1, wall=2889
2022-04-25 10:30:25 - progress_bar.py[line:272] - INFO: epoch 001:   2467 / 6136 loss=1.825, loss_v1=0, loss_v2=0, nll_loss=0.824, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=71.4, ups=1.12, wpb=64, bsz=64, num_updates=2460, lr=9.78502e-06, gnorm=3.088, loss_scale=0.5, train_wall=9, gb_free=6.8, wall=2898
2022-04-25 10:30:33 - progress_bar.py[line:272] - INFO: epoch 001:   2477 / 6136 loss=1.838, loss_v1=0, loss_v2=0, nll_loss=0.836, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=75.8, ups=1.18, wpb=64, bsz=64, num_updates=2470, lr=9.78155e-06, gnorm=3.45, loss_scale=0.5, train_wall=8, gb_free=13.6, wall=2907
2022-04-25 10:30:41 - progress_bar.py[line:272] - INFO: epoch 001:   2487 / 6136 loss=1.794, loss_v1=0, loss_v2=0, nll_loss=0.792, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=78.3, ups=1.22, wpb=64, bsz=64, num_updates=2480, lr=9.77809e-06, gnorm=2.982, loss_scale=0.5, train_wall=8, gb_free=13.5, wall=2915
2022-04-25 10:30:50 - progress_bar.py[line:272] - INFO: epoch 001:   2497 / 6136 loss=1.815, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=69.8, ups=1.09, wpb=64, bsz=64, num_updates=2490, lr=9.77462e-06, gnorm=3.062, loss_scale=0.5, train_wall=9, gb_free=13.7, wall=2924
2022-04-25 10:30:56 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2022-04-25 10:30:58 - trainer.py[line:1304] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 1.51 GiB (GPU 0; 23.70 GiB total capacity; 19.83 GiB already allocated; 516.56 MiB free; 22.08 GiB reserved in total by PyTorch)
2022-04-25 10:30:58 - trainer.py[line:1307] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 4         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   18753 MB |   20384 MB |   90674 GB |   90656 GB |
|       from large pool |   18715 MB |   20345 MB |   88992 GB |   88974 GB |
|       from small pool |      38 MB |      40 MB |    1681 GB |    1681 GB |
|---------------------------------------------------------------------------|
| Active memory         |   18753 MB |   20384 MB |   90674 GB |   90656 GB |
|       from large pool |   18715 MB |   20345 MB |   88992 GB |   88974 GB |
|       from small pool |      38 MB |      40 MB |    1681 GB |    1681 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22608 MB |   22608 MB |   38974 MB |   16366 MB |
|       from large pool |   22556 MB |   22556 MB |   38806 MB |   16250 MB |
|       from small pool |      52 MB |      96 MB |     168 MB |     116 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    2304 MB |    2304 MB |   80047 GB |   80044 GB |
|       from large pool |    2290 MB |    2290 MB |   78321 GB |   78319 GB |
|       from small pool |      13 MB |      25 MB |    1725 GB |    1725 GB |
|---------------------------------------------------------------------------|
| Allocations           |    1920    |    1956    |   43381 K  |   43379 K  |
|       from large pool |     666    |     680    |   21506 K  |   21505 K  |
|       from small pool |    1254    |    1414    |   21875 K  |   21874 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    1920    |    1956    |   43381 K  |   43379 K  |
|       from large pool |     666    |     680    |   21506 K  |   21505 K  |
|       from small pool |    1254    |    1414    |   21875 K  |   21874 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     155    |     178    |     330    |     175    |
|       from large pool |     129    |     130    |     246    |     117    |
|       from small pool |      26    |      48    |      84    |      58    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     147    |     214    |   28838 K  |   28838 K  |
|       from large pool |      85    |      93    |   16794 K  |   16794 K  |
|       from small pool |      62    |     124    |   12043 K  |   12043 K  |
|===========================================================================|

2022-04-25 10:30:58 - trainer.py[line:797] - WARNING: attempting to recover from OOM in forward/backward pass
2022-04-25 10:31:01 - progress_bar.py[line:272] - INFO: epoch 001:   2509 / 6136 loss=1.827, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=60.7, ups=0.95, wpb=64, bsz=64, num_updates=2500, lr=9.77115e-06, gnorm=3.44, loss_scale=0.25, train_wall=9, gb_free=13.3, wall=2935
2022-04-25 10:31:09 - progress_bar.py[line:272] - INFO: epoch 001:   2519 / 6136 loss=1.804, loss_v1=0, loss_v2=0, nll_loss=0.803, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=78.5, ups=1.23, wpb=64, bsz=64, num_updates=2510, lr=9.76768e-06, gnorm=4.213, loss_scale=0.25, train_wall=8, gb_free=12.9, wall=2943
2022-04-25 10:31:18 - progress_bar.py[line:272] - INFO: epoch 001:   2529 / 6136 loss=1.772, loss_v1=0, loss_v2=0, nll_loss=0.77, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=75.1, ups=1.17, wpb=64, bsz=64, num_updates=2520, lr=9.76422e-06, gnorm=3.645, loss_scale=0.25, train_wall=8, gb_free=13.6, wall=2951
2022-04-25 10:31:26 - progress_bar.py[line:272] - INFO: epoch 001:   2539 / 6136 loss=1.801, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=78.1, ups=1.22, wpb=64, bsz=64, num_updates=2530, lr=9.76075e-06, gnorm=4.093, loss_scale=0.25, train_wall=8, gb_free=12.9, wall=2960
2022-04-25 10:31:34 - progress_bar.py[line:272] - INFO: epoch 001:   2549 / 6136 loss=1.801, loss_v1=0, loss_v2=0, nll_loss=0.799, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=78.1, ups=1.22, wpb=64, bsz=64, num_updates=2540, lr=9.75728e-06, gnorm=3.843, loss_scale=0.25, train_wall=8, gb_free=14, wall=2968
2022-04-25 10:31:38 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
2022-04-25 10:31:44 - progress_bar.py[line:272] - INFO: epoch 001:   2560 / 6136 loss=1.855, loss_v1=0, loss_v2=0, nll_loss=0.854, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=63.7, ups=0.99, wpb=64, bsz=64, num_updates=2550, lr=9.75381e-06, gnorm=3.527, loss_scale=0.125, train_wall=10, gb_free=12.1, wall=2978
2022-04-25 10:31:53 - progress_bar.py[line:272] - INFO: epoch 001:   2570 / 6136 loss=1.837, loss_v1=0, loss_v2=0, nll_loss=0.835, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=73.9, ups=1.16, wpb=64, bsz=64, num_updates=2560, lr=9.75035e-06, gnorm=3.216, loss_scale=0.125, train_wall=9, gb_free=11.5, wall=2987
2022-04-25 10:32:01 - progress_bar.py[line:272] - INFO: epoch 001:   2580 / 6136 loss=1.825, loss_v1=0, loss_v2=0, nll_loss=0.823, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=77.9, ups=1.22, wpb=64, bsz=64, num_updates=2570, lr=9.74688e-06, gnorm=3.251, loss_scale=0.125, train_wall=8, gb_free=11.8, wall=2995
2022-04-25 10:32:09 - progress_bar.py[line:272] - INFO: epoch 001:   2590 / 6136 loss=1.845, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=77.8, ups=1.22, wpb=64, bsz=64, num_updates=2580, lr=9.74341e-06, gnorm=3.227, loss_scale=0.125, train_wall=8, gb_free=13.8, wall=3003
2022-04-25 10:32:17 - progress_bar.py[line:272] - INFO: epoch 001:   2600 / 6136 loss=1.823, loss_v1=0, loss_v2=0, nll_loss=0.821, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=77.6, ups=1.21, wpb=64, bsz=64, num_updates=2590, lr=9.73994e-06, gnorm=3.856, loss_scale=0.125, train_wall=8, gb_free=12.5, wall=3011
2022-04-25 10:32:26 - progress_bar.py[line:272] - INFO: epoch 001:   2610 / 6136 loss=1.846, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=77.6, ups=1.21, wpb=64, bsz=64, num_updates=2600, lr=9.73648e-06, gnorm=3.953, loss_scale=0.125, train_wall=8, gb_free=13.5, wall=3019
2022-04-25 10:32:34 - progress_bar.py[line:272] - INFO: epoch 001:   2620 / 6136 loss=1.826, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=77.7, ups=1.21, wpb=64, bsz=64, num_updates=2610, lr=9.73301e-06, gnorm=3.589, loss_scale=0.125, train_wall=8, gb_free=13.4, wall=3028
2022-04-25 10:32:42 - progress_bar.py[line:272] - INFO: epoch 001:   2630 / 6136 loss=1.817, loss_v1=0, loss_v2=0, nll_loss=0.815, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=76.2, ups=1.19, wpb=64, bsz=64, num_updates=2620, lr=9.72954e-06, gnorm=3.635, loss_scale=0.125, train_wall=8, gb_free=12.6, wall=3036
2022-04-25 10:32:51 - progress_bar.py[line:272] - INFO: epoch 001:   2640 / 6136 loss=1.85, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=78.1, ups=1.22, wpb=64, bsz=64, num_updates=2630, lr=9.72607e-06, gnorm=3.407, loss_scale=0.125, train_wall=8, gb_free=13.1, wall=3044
2022-04-25 10:32:59 - progress_bar.py[line:272] - INFO: epoch 001:   2650 / 6136 loss=1.799, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=78.7, ups=1.23, wpb=64, bsz=64, num_updates=2640, lr=9.72261e-06, gnorm=2.83, loss_scale=0.125, train_wall=8, gb_free=13.3, wall=3052
2022-04-25 10:33:07 - progress_bar.py[line:272] - INFO: epoch 001:   2660 / 6136 loss=1.801, loss_v1=0, loss_v2=0, nll_loss=0.799, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=75.1, ups=1.17, wpb=64, bsz=64, num_updates=2650, lr=9.71914e-06, gnorm=3.151, loss_scale=0.125, train_wall=8, gb_free=13.5, wall=3061
2022-04-25 10:33:17 - progress_bar.py[line:272] - INFO: epoch 001:   2670 / 6136 loss=1.825, loss_v1=0, loss_v2=0, nll_loss=0.823, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=63.5, ups=0.99, wpb=64, bsz=64, num_updates=2660, lr=9.71567e-06, gnorm=3.334, loss_scale=0.125, train_wall=10, gb_free=13, wall=3071
2022-04-25 10:33:25 - progress_bar.py[line:272] - INFO: epoch 001:   2680 / 6136 loss=1.813, loss_v1=0, loss_v2=0, nll_loss=0.811, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=77.7, ups=1.21, wpb=64, bsz=64, num_updates=2670, lr=9.71221e-06, gnorm=3.339, loss_scale=0.125, train_wall=8, gb_free=13.3, wall=3079
2022-04-25 10:33:34 - progress_bar.py[line:272] - INFO: epoch 001:   2690 / 6136 loss=1.779, loss_v1=0, loss_v2=0, nll_loss=0.777, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=79.4, ups=1.24, wpb=64, bsz=64, num_updates=2680, lr=9.70874e-06, gnorm=3.34, loss_scale=0.125, train_wall=8, gb_free=13.3, wall=3087
2022-04-25 10:33:42 - progress_bar.py[line:272] - INFO: epoch 001:   2700 / 6136 loss=1.811, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=77.9, ups=1.22, wpb=64, bsz=64, num_updates=2690, lr=9.70527e-06, gnorm=3.482, loss_scale=0.125, train_wall=8, gb_free=13.6, wall=3096
2022-04-25 10:33:50 - progress_bar.py[line:272] - INFO: epoch 001:   2710 / 6136 loss=1.813, loss_v1=0, loss_v2=0, nll_loss=0.812, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=78.3, ups=1.22, wpb=64, bsz=64, num_updates=2700, lr=9.7018e-06, gnorm=3.167, loss_scale=0.125, train_wall=8, gb_free=13.4, wall=3104
2022-04-25 10:33:58 - progress_bar.py[line:272] - INFO: epoch 001:   2720 / 6136 loss=1.793, loss_v1=0, loss_v2=0, nll_loss=0.791, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=78.9, ups=1.23, wpb=64, bsz=64, num_updates=2710, lr=9.69834e-06, gnorm=2.91, loss_scale=0.125, train_wall=8, gb_free=13.5, wall=3112
2022-04-25 10:34:06 - progress_bar.py[line:272] - INFO: epoch 001:   2730 / 6136 loss=1.813, loss_v1=0, loss_v2=0, nll_loss=0.812, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=78.7, ups=1.23, wpb=64, bsz=64, num_updates=2720, lr=9.69487e-06, gnorm=3.366, loss_scale=0.125, train_wall=8, gb_free=13.5, wall=3120
2022-04-25 10:34:14 - progress_bar.py[line:272] - INFO: epoch 001:   2740 / 6136 loss=1.83, loss_v1=0, loss_v2=0, nll_loss=0.829, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=79.6, ups=1.24, wpb=64, bsz=64, num_updates=2730, lr=9.6914e-06, gnorm=3.308, loss_scale=0.125, train_wall=8, gb_free=13.7, wall=3128
2022-04-25 10:34:23 - progress_bar.py[line:272] - INFO: epoch 001:   2750 / 6136 loss=1.815, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=76.3, ups=1.19, wpb=64, bsz=64, num_updates=2740, lr=9.68793e-06, gnorm=3.019, loss_scale=0.125, train_wall=8, gb_free=12.2, wall=3136
2022-04-25 10:34:31 - progress_bar.py[line:272] - INFO: epoch 001:   2760 / 6136 loss=1.785, loss_v1=0, loss_v2=0, nll_loss=0.784, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=77, ups=1.2, wpb=64, bsz=64, num_updates=2750, lr=9.68447e-06, gnorm=2.863, loss_scale=0.125, train_wall=8, gb_free=13.4, wall=3145
2022-04-25 10:34:40 - progress_bar.py[line:272] - INFO: epoch 001:   2770 / 6136 loss=1.79, loss_v1=0, loss_v2=0, nll_loss=0.788, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=68.9, ups=1.08, wpb=64, bsz=64, num_updates=2760, lr=9.681e-06, gnorm=3.973, loss_scale=0.125, train_wall=9, gb_free=13.4, wall=3154
2022-04-25 10:34:49 - progress_bar.py[line:272] - INFO: epoch 001:   2780 / 6136 loss=1.807, loss_v1=0, loss_v2=0, nll_loss=0.805, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=76.7, ups=1.2, wpb=64, bsz=64, num_updates=2770, lr=9.67753e-06, gnorm=3.476, loss_scale=0.125, train_wall=8, gb_free=13.7, wall=3162
2022-04-25 10:34:57 - progress_bar.py[line:272] - INFO: epoch 001:   2790 / 6136 loss=1.792, loss_v1=0, loss_v2=0, nll_loss=0.791, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=75.6, ups=1.18, wpb=64, bsz=64, num_updates=2780, lr=9.67406e-06, gnorm=3.272, loss_scale=0.125, train_wall=8, gb_free=13.4, wall=3171
2022-04-25 10:35:05 - progress_bar.py[line:272] - INFO: epoch 001:   2800 / 6136 loss=1.81, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=78, ups=1.22, wpb=64, bsz=64, num_updates=2790, lr=9.6706e-06, gnorm=3.451, loss_scale=0.125, train_wall=8, gb_free=13.8, wall=3179
2022-04-25 10:35:13 - progress_bar.py[line:272] - INFO: epoch 001:   2810 / 6136 loss=1.801, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=78, ups=1.22, wpb=64, bsz=64, num_updates=2800, lr=9.66713e-06, gnorm=3.821, loss_scale=0.125, train_wall=8, gb_free=13.8, wall=3187
2022-04-25 10:35:22 - progress_bar.py[line:272] - INFO: epoch 001:   2820 / 6136 loss=1.866, loss_v1=0, loss_v2=0, nll_loss=0.865, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=77.5, ups=1.21, wpb=64, bsz=64, num_updates=2810, lr=9.66366e-06, gnorm=3.495, loss_scale=0.125, train_wall=8, gb_free=12.7, wall=3195
2022-04-25 10:35:30 - progress_bar.py[line:272] - INFO: epoch 001:   2830 / 6136 loss=1.82, loss_v1=0, loss_v2=0, nll_loss=0.818, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=79.7, ups=1.25, wpb=64, bsz=64, num_updates=2820, lr=9.66019e-06, gnorm=3.582, loss_scale=0.125, train_wall=8, gb_free=13.6, wall=3203
2022-04-25 10:35:38 - progress_bar.py[line:272] - INFO: epoch 001:   2840 / 6136 loss=1.81, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=78.4, ups=1.22, wpb=64, bsz=64, num_updates=2830, lr=9.65673e-06, gnorm=3.4, loss_scale=0.125, train_wall=8, gb_free=13.5, wall=3212
2022-04-25 10:35:42 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
2022-04-25 10:35:48 - progress_bar.py[line:272] - INFO: epoch 001:   2851 / 6136 loss=1.755, loss_v1=0, loss_v2=0, nll_loss=0.754, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=65.6, ups=1.02, wpb=64, bsz=64, num_updates=2840, lr=9.65326e-06, gnorm=24.479, loss_scale=0.0625, train_wall=10, gb_free=13, wall=3221
2022-04-25 10:35:56 - progress_bar.py[line:272] - INFO: epoch 001:   2861 / 6136 loss=1.769, loss_v1=0, loss_v2=0, nll_loss=0.767, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=77.6, ups=1.21, wpb=64, bsz=64, num_updates=2850, lr=9.64979e-06, gnorm=3.238, loss_scale=0.0625, train_wall=8, gb_free=13.5, wall=3230
2022-04-25 10:36:04 - progress_bar.py[line:272] - INFO: epoch 001:   2871 / 6136 loss=1.762, loss_v1=0, loss_v2=0, nll_loss=0.76, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=76.1, ups=1.19, wpb=64, bsz=64, num_updates=2860, lr=9.64632e-06, gnorm=2.953, loss_scale=0.0625, train_wall=8, gb_free=12.6, wall=3238
2022-04-25 10:36:13 - progress_bar.py[line:272] - INFO: epoch 001:   2881 / 6136 loss=1.738, loss_v1=0, loss_v2=0, nll_loss=0.736, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=78.1, ups=1.22, wpb=64, bsz=64, num_updates=2870, lr=9.64286e-06, gnorm=3.181, loss_scale=0.0625, train_wall=8, gb_free=13.5, wall=3246
2022-04-25 10:36:21 - progress_bar.py[line:272] - INFO: epoch 001:   2891 / 6136 loss=1.802, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=79, ups=1.23, wpb=64, bsz=64, num_updates=2880, lr=9.63939e-06, gnorm=3.117, loss_scale=0.0625, train_wall=8, gb_free=13.6, wall=3254
2022-04-25 10:36:29 - progress_bar.py[line:272] - INFO: epoch 001:   2901 / 6136 loss=1.882, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=76.9, ups=1.2, wpb=64, bsz=64, num_updates=2890, lr=9.63592e-06, gnorm=3.267, loss_scale=0.0625, train_wall=8, gb_free=13.7, wall=3263
2022-04-25 10:36:38 - progress_bar.py[line:272] - INFO: epoch 001:   2911 / 6136 loss=1.787, loss_v1=0, loss_v2=0, nll_loss=0.785, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=73.3, ups=1.15, wpb=64, bsz=64, num_updates=2900, lr=9.63245e-06, gnorm=3.024, loss_scale=0.0625, train_wall=9, gb_free=13.7, wall=3271
2022-04-25 10:36:40 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
2022-04-25 10:36:49 - progress_bar.py[line:272] - INFO: epoch 001:   2922 / 6136 loss=1.821, loss_v1=0, loss_v2=0, nll_loss=0.819, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=58.9, ups=0.92, wpb=64, bsz=64, num_updates=2910, lr=9.62899e-06, gnorm=3.988, loss_scale=0.0312, train_wall=11, gb_free=13.8, wall=3282
2022-04-25 10:36:57 - progress_bar.py[line:272] - INFO: epoch 001:   2932 / 6136 loss=1.726, loss_v1=0, loss_v2=0, nll_loss=0.724, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=79.6, ups=1.24, wpb=64, bsz=64, num_updates=2920, lr=9.62552e-06, gnorm=3.419, loss_scale=0.0312, train_wall=8, gb_free=13.3, wall=3290
2022-04-25 10:37:05 - progress_bar.py[line:272] - INFO: epoch 001:   2942 / 6136 loss=1.786, loss_v1=0, loss_v2=0, nll_loss=0.785, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=79.3, ups=1.24, wpb=64, bsz=64, num_updates=2930, lr=9.62205e-06, gnorm=3.365, loss_scale=0.0312, train_wall=8, gb_free=12.5, wall=3298
2022-04-25 10:37:13 - progress_bar.py[line:272] - INFO: epoch 001:   2952 / 6136 loss=1.843, loss_v1=0, loss_v2=0, nll_loss=0.842, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=74.4, ups=1.16, wpb=64, bsz=64, num_updates=2940, lr=9.61859e-06, gnorm=3.711, loss_scale=0.0312, train_wall=9, gb_free=12.4, wall=3307
2022-04-25 10:37:23 - progress_bar.py[line:272] - INFO: epoch 001:   2962 / 6136 loss=1.821, loss_v1=0, loss_v2=0, nll_loss=0.819, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=68.6, ups=1.07, wpb=64, bsz=64, num_updates=2950, lr=9.61512e-06, gnorm=3.419, loss_scale=0.0312, train_wall=9, gb_free=13.2, wall=3316
2022-04-25 10:37:31 - progress_bar.py[line:272] - INFO: epoch 001:   2972 / 6136 loss=1.819, loss_v1=0, loss_v2=0, nll_loss=0.818, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=75.3, ups=1.18, wpb=64, bsz=64, num_updates=2960, lr=9.61165e-06, gnorm=3.387, loss_scale=0.0312, train_wall=8, gb_free=14, wall=3325
2022-04-25 10:37:39 - progress_bar.py[line:272] - INFO: epoch 001:   2982 / 6136 loss=1.726, loss_v1=0, loss_v2=0, nll_loss=0.724, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=77, ups=1.2, wpb=64, bsz=64, num_updates=2970, lr=9.60818e-06, gnorm=3.482, loss_scale=0.0312, train_wall=8, gb_free=12.5, wall=3333
2022-04-25 10:37:48 - progress_bar.py[line:272] - INFO: epoch 001:   2992 / 6136 loss=1.749, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=78.1, ups=1.22, wpb=64, bsz=64, num_updates=2980, lr=9.60472e-06, gnorm=3.089, loss_scale=0.0312, train_wall=8, gb_free=13.6, wall=3341
2022-04-25 10:37:54 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.015625
2022-04-25 10:37:56 - progress_bar.py[line:272] - INFO: epoch 001:   3003 / 6136 loss=1.738, loss_v1=0, loss_v2=0, nll_loss=0.736, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=72.3, ups=1.13, wpb=64, bsz=64, num_updates=2990, lr=9.60125e-06, gnorm=3.038, loss_scale=0.0156, train_wall=9, gb_free=13.7, wall=3350
2022-04-25 10:38:05 - progress_bar.py[line:272] - INFO: epoch 001:   3013 / 6136 loss=1.707, loss_v1=0, loss_v2=0, nll_loss=0.705, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=78.8, ups=1.23, wpb=64, bsz=64, num_updates=3000, lr=9.59778e-06, gnorm=2.946, loss_scale=0.0156, train_wall=8, gb_free=11.4, wall=3358
2022-04-25 10:38:05 - train.py[line:435] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 10:42:16 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 1.752 | loss_v1 0 | loss_v2 0 | nll_loss 0.749 | ntokens 15.999 | nsentences 15.999 | sample_size 15.999 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.68 | acc 0.6793 | wps 78.2 | wpb 16 | bsz 16 | num_updates 3000 | best_acc 0.6793
2022-04-25 10:42:16 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 3000 updates
2022-04-25 10:42:16 - trainer.py[line:432] - INFO: Saving checkpoint to ./fairseq_checkpoints/mnli/5_1e-5_4/checkpoint_1_3000.pt
2022-04-25 10:42:32 - trainer.py[line:442] - INFO: Finished saving checkpoint to ./fairseq_checkpoints/mnli/5_1e-5_4/checkpoint_1_3000.pt
2022-04-25 10:42:54 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./fairseq_checkpoints/mnli/5_1e-5_4/checkpoint_1_3000.pt (epoch 1 @ 3000 updates, score 0.6793) (writing took 37.47264939220622 seconds)
2022-04-25 10:43:02 - progress_bar.py[line:272] - INFO: epoch 001:   3023 / 6136 loss=1.788, loss_v1=0, loss_v2=0, nll_loss=0.786, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=2.1, ups=0.03, wpb=64, bsz=64, num_updates=3010, lr=9.59431e-06, gnorm=3.213, loss_scale=0.0156, train_wall=8, gb_free=13.5, wall=3656
2022-04-25 10:43:10 - progress_bar.py[line:272] - INFO: epoch 001:   3033 / 6136 loss=1.802, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=80.3, ups=1.25, wpb=64, bsz=64, num_updates=3020, lr=9.59085e-06, gnorm=4.128, loss_scale=0.0156, train_wall=8, gb_free=13.4, wall=3664
2022-04-25 10:43:18 - progress_bar.py[line:272] - INFO: epoch 001:   3043 / 6136 loss=1.787, loss_v1=0, loss_v2=0, nll_loss=0.786, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=80, ups=1.25, wpb=64, bsz=64, num_updates=3030, lr=9.58738e-06, gnorm=3.678, loss_scale=0.0156, train_wall=8, gb_free=13.3, wall=3672
2022-04-25 10:43:26 - progress_bar.py[line:272] - INFO: epoch 001:   3053 / 6136 loss=1.758, loss_v1=0, loss_v2=0, nll_loss=0.757, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=80.1, ups=1.25, wpb=64, bsz=64, num_updates=3040, lr=9.58391e-06, gnorm=3.268, loss_scale=0.0156, train_wall=8, gb_free=13.7, wall=3680
2022-04-25 10:43:35 - progress_bar.py[line:272] - INFO: epoch 001:   3063 / 6136 loss=1.78, loss_v1=0, loss_v2=0, nll_loss=0.778, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=76.7, ups=1.2, wpb=64, bsz=64, num_updates=3050, lr=9.58044e-06, gnorm=3.321, loss_scale=0.0156, train_wall=8, gb_free=13.7, wall=3688
2022-04-25 10:43:43 - progress_bar.py[line:272] - INFO: epoch 001:   3073 / 6136 loss=1.777, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=78.9, ups=1.23, wpb=64, bsz=64, num_updates=3060, lr=9.57698e-06, gnorm=3.339, loss_scale=0.0156, train_wall=8, gb_free=11.9, wall=3697
2022-04-25 10:43:52 - progress_bar.py[line:272] - INFO: epoch 001:   3083 / 6136 loss=1.813, loss_v1=0, loss_v2=0, nll_loss=0.811, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=70.4, ups=1.1, wpb=64, bsz=64, num_updates=3070, lr=9.57351e-06, gnorm=3.581, loss_scale=0.0156, train_wall=9, gb_free=8.6, wall=3706
2022-04-25 10:44:00 - progress_bar.py[line:272] - INFO: epoch 001:   3093 / 6136 loss=1.783, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=80.8, ups=1.26, wpb=64, bsz=64, num_updates=3080, lr=9.57004e-06, gnorm=2.699, loss_scale=0.0156, train_wall=8, gb_free=13.6, wall=3714
2022-04-25 10:44:08 - progress_bar.py[line:272] - INFO: epoch 001:   3103 / 6136 loss=1.835, loss_v1=0, loss_v2=0, nll_loss=0.834, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=78.1, ups=1.22, wpb=64, bsz=64, num_updates=3090, lr=9.56657e-06, gnorm=2.968, loss_scale=0.0156, train_wall=8, gb_free=13.6, wall=3722
2022-04-25 10:44:16 - progress_bar.py[line:272] - INFO: epoch 001:   3113 / 6136 loss=1.78, loss_v1=0, loss_v2=0, nll_loss=0.778, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=77, ups=1.2, wpb=64, bsz=64, num_updates=3100, lr=9.56311e-06, gnorm=3.363, loss_scale=0.0156, train_wall=8, gb_free=13.1, wall=3730
2022-04-25 10:44:25 - progress_bar.py[line:272] - INFO: epoch 001:   3123 / 6136 loss=1.755, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=73.4, ups=1.15, wpb=64, bsz=64, num_updates=3110, lr=9.55964e-06, gnorm=3.14, loss_scale=0.0156, train_wall=9, gb_free=13.9, wall=3739
2022-04-25 10:44:33 - progress_bar.py[line:272] - INFO: epoch 001:   3133 / 6136 loss=1.761, loss_v1=0, loss_v2=0, nll_loss=0.76, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=77.4, ups=1.21, wpb=64, bsz=64, num_updates=3120, lr=9.55617e-06, gnorm=3.043, loss_scale=0.0156, train_wall=8, gb_free=13.8, wall=3747
2022-04-25 10:44:41 - progress_bar.py[line:272] - INFO: epoch 001:   3143 / 6136 loss=1.79, loss_v1=0, loss_v2=0, nll_loss=0.788, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=79.1, ups=1.24, wpb=64, bsz=64, num_updates=3130, lr=9.5527e-06, gnorm=3.225, loss_scale=0.0156, train_wall=8, gb_free=13.9, wall=3755
2022-04-25 10:44:52 - progress_bar.py[line:272] - INFO: epoch 001:   3153 / 6136 loss=1.767, loss_v1=0, loss_v2=0, nll_loss=0.765, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=63.2, ups=0.99, wpb=64, bsz=64, num_updates=3140, lr=9.54924e-06, gnorm=3.705, loss_scale=0.0156, train_wall=10, gb_free=13.1, wall=3765
2022-04-25 10:45:00 - progress_bar.py[line:272] - INFO: epoch 001:   3163 / 6136 loss=1.749, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=80.6, ups=1.26, wpb=64, bsz=64, num_updates=3150, lr=9.54577e-06, gnorm=3.457, loss_scale=0.0156, train_wall=8, gb_free=13.1, wall=3773
2022-04-25 10:45:09 - progress_bar.py[line:272] - INFO: epoch 001:   3173 / 6136 loss=1.709, loss_v1=0, loss_v2=0, nll_loss=0.707, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=71.3, ups=1.11, wpb=64, bsz=64, num_updates=3160, lr=9.5423e-06, gnorm=3.813, loss_scale=0.0156, train_wall=9, gb_free=13.8, wall=3782
2022-04-25 10:45:17 - progress_bar.py[line:272] - INFO: epoch 001:   3183 / 6136 loss=1.815, loss_v1=0, loss_v2=0, nll_loss=0.814, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=76.7, ups=1.2, wpb=64, bsz=64, num_updates=3170, lr=9.53883e-06, gnorm=3.27, loss_scale=0.0156, train_wall=8, gb_free=12.6, wall=3791
2022-04-25 10:45:25 - progress_bar.py[line:272] - INFO: epoch 001:   3193 / 6136 loss=1.761, loss_v1=0, loss_v2=0, nll_loss=0.759, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=78.1, ups=1.22, wpb=64, bsz=64, num_updates=3180, lr=9.53537e-06, gnorm=3.647, loss_scale=0.0156, train_wall=8, gb_free=13.4, wall=3799
2022-04-25 10:45:33 - progress_bar.py[line:272] - INFO: epoch 001:   3203 / 6136 loss=1.796, loss_v1=0, loss_v2=0, nll_loss=0.795, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=77.5, ups=1.21, wpb=64, bsz=64, num_updates=3190, lr=9.5319e-06, gnorm=3.201, loss_scale=0.0156, train_wall=8, gb_free=13.3, wall=3807
2022-04-25 10:45:41 - progress_bar.py[line:272] - INFO: epoch 001:   3213 / 6136 loss=1.849, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=78.1, ups=1.22, wpb=64, bsz=64, num_updates=3200, lr=9.52843e-06, gnorm=3.67, loss_scale=0.0156, train_wall=8, gb_free=12.2, wall=3815
2022-04-25 10:45:50 - progress_bar.py[line:272] - INFO: epoch 001:   3223 / 6136 loss=1.809, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=79.1, ups=1.24, wpb=64, bsz=64, num_updates=3210, lr=9.52497e-06, gnorm=3.362, loss_scale=0.0156, train_wall=8, gb_free=11.9, wall=3823
2022-04-25 10:45:58 - progress_bar.py[line:272] - INFO: epoch 001:   3233 / 6136 loss=1.761, loss_v1=0, loss_v2=0, nll_loss=0.759, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=80.9, ups=1.26, wpb=64, bsz=64, num_updates=3220, lr=9.5215e-06, gnorm=2.711, loss_scale=0.0156, train_wall=8, gb_free=13.8, wall=3831
2022-04-25 10:46:06 - progress_bar.py[line:272] - INFO: epoch 001:   3243 / 6136 loss=1.808, loss_v1=0, loss_v2=0, nll_loss=0.807, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=79.9, ups=1.25, wpb=64, bsz=64, num_updates=3230, lr=9.51803e-06, gnorm=3.157, loss_scale=0.0156, train_wall=8, gb_free=13.7, wall=3839
2022-04-25 10:46:12 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0078125
2022-04-25 10:46:15 - progress_bar.py[line:272] - INFO: epoch 001:   3254 / 6136 loss=1.782, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=67.2, ups=1.05, wpb=64, bsz=64, num_updates=3240, lr=9.51456e-06, gnorm=3.163, loss_scale=0.0078, train_wall=9, gb_free=14.1, wall=3849
2022-04-25 10:46:23 - progress_bar.py[line:272] - INFO: epoch 001:   3264 / 6136 loss=1.755, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=80, ups=1.25, wpb=64, bsz=64, num_updates=3250, lr=9.5111e-06, gnorm=3.341, loss_scale=0.0078, train_wall=8, gb_free=13.1, wall=3857
2022-04-25 10:46:32 - progress_bar.py[line:272] - INFO: epoch 001:   3274 / 6136 loss=1.836, loss_v1=0, loss_v2=0, nll_loss=0.834, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=74.4, ups=1.16, wpb=64, bsz=64, num_updates=3260, lr=9.50763e-06, gnorm=3.435, loss_scale=0.0078, train_wall=9, gb_free=13.2, wall=3865
2022-04-25 10:46:40 - progress_bar.py[line:272] - INFO: epoch 001:   3284 / 6136 loss=1.742, loss_v1=0, loss_v2=0, nll_loss=0.74, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=79.6, ups=1.24, wpb=64, bsz=64, num_updates=3270, lr=9.50416e-06, gnorm=3.135, loss_scale=0.0078, train_wall=8, gb_free=13.7, wall=3873
2022-04-25 10:46:48 - progress_bar.py[line:272] - INFO: epoch 001:   3294 / 6136 loss=1.763, loss_v1=0, loss_v2=0, nll_loss=0.761, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=79.9, ups=1.25, wpb=64, bsz=64, num_updates=3280, lr=9.50069e-06, gnorm=3.203, loss_scale=0.0078, train_wall=8, gb_free=13.9, wall=3881
2022-04-25 10:46:56 - progress_bar.py[line:272] - INFO: epoch 001:   3304 / 6136 loss=1.758, loss_v1=0, loss_v2=0, nll_loss=0.756, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=79.8, ups=1.25, wpb=64, bsz=64, num_updates=3290, lr=9.49723e-06, gnorm=3.031, loss_scale=0.0078, train_wall=8, gb_free=12.8, wall=3889
2022-04-25 10:47:04 - progress_bar.py[line:272] - INFO: epoch 001:   3314 / 6136 loss=1.815, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=80.9, ups=1.26, wpb=64, bsz=64, num_updates=3300, lr=9.49376e-06, gnorm=3.325, loss_scale=0.0078, train_wall=8, gb_free=13.7, wall=3897
2022-04-25 10:47:12 - progress_bar.py[line:272] - INFO: epoch 001:   3324 / 6136 loss=1.798, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=79.5, ups=1.24, wpb=64, bsz=64, num_updates=3310, lr=9.49029e-06, gnorm=3.47, loss_scale=0.0078, train_wall=8, gb_free=14, wall=3905
2022-04-25 10:47:20 - progress_bar.py[line:272] - INFO: epoch 001:   3334 / 6136 loss=1.746, loss_v1=0, loss_v2=0, nll_loss=0.744, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=75.5, ups=1.18, wpb=64, bsz=64, num_updates=3320, lr=9.48682e-06, gnorm=3.2, loss_scale=0.0078, train_wall=8, gb_free=13.5, wall=3914
2022-04-25 10:47:28 - progress_bar.py[line:272] - INFO: epoch 001:   3344 / 6136 loss=1.753, loss_v1=0, loss_v2=0, nll_loss=0.751, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=77.6, ups=1.21, wpb=64, bsz=64, num_updates=3330, lr=9.48336e-06, gnorm=2.879, loss_scale=0.0078, train_wall=8, gb_free=13.8, wall=3922
2022-04-25 10:47:37 - progress_bar.py[line:272] - INFO: epoch 001:   3354 / 6136 loss=1.764, loss_v1=0, loss_v2=0, nll_loss=0.762, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=77.1, ups=1.2, wpb=64, bsz=64, num_updates=3340, lr=9.47989e-06, gnorm=2.842, loss_scale=0.0078, train_wall=8, gb_free=13.6, wall=3930
2022-04-25 10:47:45 - progress_bar.py[line:272] - INFO: epoch 001:   3364 / 6136 loss=1.737, loss_v1=0, loss_v2=0, nll_loss=0.736, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=77.4, ups=1.21, wpb=64, bsz=64, num_updates=3350, lr=9.47642e-06, gnorm=3.144, loss_scale=0.0078, train_wall=8, gb_free=14, wall=3939
2022-04-25 10:47:53 - progress_bar.py[line:272] - INFO: epoch 001:   3374 / 6136 loss=1.747, loss_v1=0, loss_v2=0, nll_loss=0.746, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=76.2, ups=1.19, wpb=64, bsz=64, num_updates=3360, lr=9.47295e-06, gnorm=3.503, loss_scale=0.0078, train_wall=8, gb_free=12.3, wall=3947
2022-04-25 10:48:01 - progress_bar.py[line:272] - INFO: epoch 001:   3384 / 6136 loss=1.757, loss_v1=0, loss_v2=0, nll_loss=0.756, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=79, ups=1.23, wpb=64, bsz=64, num_updates=3370, lr=9.46949e-06, gnorm=3.363, loss_scale=0.0078, train_wall=8, gb_free=13.4, wall=3955
2022-04-25 10:48:09 - progress_bar.py[line:272] - INFO: epoch 001:   3394 / 6136 loss=1.755, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=81.5, ups=1.27, wpb=64, bsz=64, num_updates=3380, lr=9.46602e-06, gnorm=3.257, loss_scale=0.0078, train_wall=8, gb_free=14, wall=3963
2022-04-25 10:48:17 - progress_bar.py[line:272] - INFO: epoch 001:   3404 / 6136 loss=1.78, loss_v1=0, loss_v2=0, nll_loss=0.778, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=78.5, ups=1.23, wpb=64, bsz=64, num_updates=3390, lr=9.46255e-06, gnorm=3.16, loss_scale=0.0078, train_wall=8, gb_free=14.1, wall=3971
2022-04-25 10:48:27 - progress_bar.py[line:272] - INFO: epoch 001:   3414 / 6136 loss=1.754, loss_v1=0, loss_v2=0, nll_loss=0.752, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=69.8, ups=1.09, wpb=64, bsz=64, num_updates=3400, lr=9.45908e-06, gnorm=3.056, loss_scale=0.0078, train_wall=9, gb_free=13.8, wall=3980
2022-04-25 10:48:35 - progress_bar.py[line:272] - INFO: epoch 001:   3424 / 6136 loss=1.752, loss_v1=0, loss_v2=0, nll_loss=0.751, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=77.8, ups=1.22, wpb=64, bsz=64, num_updates=3410, lr=9.45562e-06, gnorm=3.116, loss_scale=0.0078, train_wall=8, gb_free=12.9, wall=3989
2022-04-25 10:48:43 - progress_bar.py[line:272] - INFO: epoch 001:   3434 / 6136 loss=1.767, loss_v1=0, loss_v2=0, nll_loss=0.766, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=80.3, ups=1.25, wpb=64, bsz=64, num_updates=3420, lr=9.45215e-06, gnorm=3.118, loss_scale=0.0078, train_wall=8, gb_free=12.8, wall=3997
2022-04-25 10:48:51 - progress_bar.py[line:272] - INFO: epoch 001:   3444 / 6136 loss=1.789, loss_v1=0, loss_v2=0, nll_loss=0.787, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=81.7, ups=1.28, wpb=64, bsz=64, num_updates=3430, lr=9.44868e-06, gnorm=2.924, loss_scale=0.0078, train_wall=8, gb_free=13.7, wall=4004
2022-04-25 10:48:59 - progress_bar.py[line:272] - INFO: epoch 001:   3454 / 6136 loss=1.754, loss_v1=0, loss_v2=0, nll_loss=0.752, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=79.2, ups=1.24, wpb=64, bsz=64, num_updates=3440, lr=9.44521e-06, gnorm=3.184, loss_scale=0.0078, train_wall=8, gb_free=13.4, wall=4013
2022-04-25 10:49:07 - progress_bar.py[line:272] - INFO: epoch 001:   3464 / 6136 loss=1.718, loss_v1=0, loss_v2=0, nll_loss=0.717, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=79.3, ups=1.24, wpb=64, bsz=64, num_updates=3450, lr=9.44175e-06, gnorm=2.83, loss_scale=0.0078, train_wall=8, gb_free=13.5, wall=4021
2022-04-25 10:49:15 - progress_bar.py[line:272] - INFO: epoch 001:   3474 / 6136 loss=1.752, loss_v1=0, loss_v2=0, nll_loss=0.75, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=78.7, ups=1.23, wpb=64, bsz=64, num_updates=3460, lr=9.43828e-06, gnorm=3.576, loss_scale=0.0078, train_wall=8, gb_free=12.6, wall=4029
2022-04-25 10:49:23 - progress_bar.py[line:272] - INFO: epoch 001:   3484 / 6136 loss=1.767, loss_v1=0, loss_v2=0, nll_loss=0.765, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=80, ups=1.25, wpb=64, bsz=64, num_updates=3470, lr=9.43481e-06, gnorm=3.153, loss_scale=0.0078, train_wall=8, gb_free=13.7, wall=4037
2022-04-25 10:49:31 - progress_bar.py[line:272] - INFO: epoch 001:   3494 / 6136 loss=1.751, loss_v1=0, loss_v2=0, nll_loss=0.749, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=80.3, ups=1.25, wpb=64, bsz=64, num_updates=3480, lr=9.43135e-06, gnorm=3.184, loss_scale=0.0078, train_wall=8, gb_free=13, wall=4045
2022-04-25 10:49:39 - progress_bar.py[line:272] - INFO: epoch 001:   3504 / 6136 loss=1.788, loss_v1=0, loss_v2=0, nll_loss=0.787, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=78.6, ups=1.23, wpb=64, bsz=64, num_updates=3490, lr=9.42788e-06, gnorm=3.733, loss_scale=0.0078, train_wall=8, gb_free=13.4, wall=4053
2022-04-25 10:49:43 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.00390625
2022-04-25 10:49:49 - progress_bar.py[line:272] - INFO: epoch 001:   3515 / 6136 loss=1.75, loss_v1=0, loss_v2=0, nll_loss=0.748, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=64.5, ups=1.01, wpb=64, bsz=64, num_updates=3500, lr=9.42441e-06, gnorm=3.596, loss_scale=0.0039, train_wall=10, gb_free=13.3, wall=4063
2022-04-25 10:49:57 - progress_bar.py[line:272] - INFO: epoch 001:   3525 / 6136 loss=1.699, loss_v1=0, loss_v2=0, nll_loss=0.697, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=76.3, ups=1.19, wpb=64, bsz=64, num_updates=3510, lr=9.42094e-06, gnorm=3.394, loss_scale=0.0039, train_wall=8, gb_free=13.2, wall=4071
2022-04-25 10:50:05 - progress_bar.py[line:272] - INFO: epoch 001:   3535 / 6136 loss=1.749, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=80.1, ups=1.25, wpb=64, bsz=64, num_updates=3520, lr=9.41748e-06, gnorm=3.216, loss_scale=0.0039, train_wall=8, gb_free=11.2, wall=4079
2022-04-25 10:50:14 - progress_bar.py[line:272] - INFO: epoch 001:   3545 / 6136 loss=1.816, loss_v1=0, loss_v2=0, nll_loss=0.814, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=77.7, ups=1.21, wpb=64, bsz=64, num_updates=3530, lr=9.41401e-06, gnorm=3.413, loss_scale=0.0039, train_wall=8, gb_free=13.1, wall=4087
2022-04-25 10:50:22 - progress_bar.py[line:272] - INFO: epoch 001:   3555 / 6136 loss=1.753, loss_v1=0, loss_v2=0, nll_loss=0.751, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=75.2, ups=1.17, wpb=64, bsz=64, num_updates=3540, lr=9.41054e-06, gnorm=2.914, loss_scale=0.0039, train_wall=8, gb_free=14.3, wall=4096
2022-04-25 10:50:30 - progress_bar.py[line:272] - INFO: epoch 001:   3565 / 6136 loss=1.775, loss_v1=0, loss_v2=0, nll_loss=0.773, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=80.4, ups=1.26, wpb=64, bsz=64, num_updates=3550, lr=9.40707e-06, gnorm=2.969, loss_scale=0.0039, train_wall=8, gb_free=13, wall=4104
2022-04-25 10:50:38 - progress_bar.py[line:272] - INFO: epoch 001:   3575 / 6136 loss=1.794, loss_v1=0, loss_v2=0, nll_loss=0.792, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=82.3, ups=1.29, wpb=64, bsz=64, num_updates=3560, lr=9.40361e-06, gnorm=2.821, loss_scale=0.0039, train_wall=8, gb_free=13.8, wall=4112
2022-04-25 10:50:46 - progress_bar.py[line:272] - INFO: epoch 001:   3585 / 6136 loss=1.738, loss_v1=0, loss_v2=0, nll_loss=0.736, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=78.6, ups=1.23, wpb=64, bsz=64, num_updates=3570, lr=9.40014e-06, gnorm=2.691, loss_scale=0.0039, train_wall=8, gb_free=13.5, wall=4120
2022-04-25 10:50:54 - progress_bar.py[line:272] - INFO: epoch 001:   3595 / 6136 loss=1.722, loss_v1=0, loss_v2=0, nll_loss=0.72, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=79, ups=1.23, wpb=64, bsz=64, num_updates=3580, lr=9.39667e-06, gnorm=3.128, loss_scale=0.0039, train_wall=8, gb_free=13.2, wall=4128
2022-04-25 10:51:02 - progress_bar.py[line:272] - INFO: epoch 001:   3605 / 6136 loss=1.82, loss_v1=0, loss_v2=0, nll_loss=0.819, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=79.8, ups=1.25, wpb=64, bsz=64, num_updates=3590, lr=9.3932e-06, gnorm=3.705, loss_scale=0.0039, train_wall=8, gb_free=14, wall=4136
2022-04-25 10:51:10 - progress_bar.py[line:272] - INFO: epoch 001:   3615 / 6136 loss=1.711, loss_v1=0, loss_v2=0, nll_loss=0.71, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=81.2, ups=1.27, wpb=64, bsz=64, num_updates=3600, lr=9.38974e-06, gnorm=2.8, loss_scale=0.0039, train_wall=8, gb_free=13.6, wall=4144
2022-04-25 10:51:18 - progress_bar.py[line:272] - INFO: epoch 001:   3625 / 6136 loss=1.739, loss_v1=0, loss_v2=0, nll_loss=0.737, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=79.5, ups=1.24, wpb=64, bsz=64, num_updates=3610, lr=9.38627e-06, gnorm=2.95, loss_scale=0.0039, train_wall=8, gb_free=13.7, wall=4152
2022-04-25 10:51:26 - progress_bar.py[line:272] - INFO: epoch 001:   3635 / 6136 loss=1.744, loss_v1=0, loss_v2=0, nll_loss=0.743, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=79.9, ups=1.25, wpb=64, bsz=64, num_updates=3620, lr=9.3828e-06, gnorm=3.196, loss_scale=0.0039, train_wall=8, gb_free=13.6, wall=4160
2022-04-25 10:51:34 - progress_bar.py[line:272] - INFO: epoch 001:   3645 / 6136 loss=1.763, loss_v1=0, loss_v2=0, nll_loss=0.761, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=80.1, ups=1.25, wpb=64, bsz=64, num_updates=3630, lr=9.37933e-06, gnorm=3.259, loss_scale=0.0039, train_wall=8, gb_free=13.1, wall=4168
2022-04-25 10:51:37 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.001953125
2022-04-25 10:51:44 - progress_bar.py[line:272] - INFO: epoch 001:   3656 / 6136 loss=1.763, loss_v1=0, loss_v2=0, nll_loss=0.762, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=66.2, ups=1.03, wpb=64, bsz=64, num_updates=3640, lr=9.37587e-06, gnorm=3.23, loss_scale=0.002, train_wall=10, gb_free=12.5, wall=4177
2022-04-25 10:51:52 - progress_bar.py[line:272] - INFO: epoch 001:   3666 / 6136 loss=1.7, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=78.8, ups=1.23, wpb=64, bsz=64, num_updates=3650, lr=9.3724e-06, gnorm=3.071, loss_scale=0.002, train_wall=8, gb_free=12.6, wall=4186
2022-04-25 10:52:00 - progress_bar.py[line:272] - INFO: epoch 001:   3676 / 6136 loss=1.782, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=79.6, ups=1.24, wpb=64, bsz=64, num_updates=3660, lr=9.36893e-06, gnorm=3.23, loss_scale=0.002, train_wall=8, gb_free=12.8, wall=4194
2022-04-25 10:52:08 - progress_bar.py[line:272] - INFO: epoch 001:   3686 / 6136 loss=1.759, loss_v1=0, loss_v2=0, nll_loss=0.757, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=79.2, ups=1.24, wpb=64, bsz=64, num_updates=3670, lr=9.36546e-06, gnorm=3.361, loss_scale=0.002, train_wall=8, gb_free=13.4, wall=4202
2022-04-25 10:52:16 - progress_bar.py[line:272] - INFO: epoch 001:   3696 / 6136 loss=1.79, loss_v1=0, loss_v2=0, nll_loss=0.788, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=79, ups=1.23, wpb=64, bsz=64, num_updates=3680, lr=9.362e-06, gnorm=3.193, loss_scale=0.002, train_wall=8, gb_free=13.4, wall=4210
2022-04-25 10:52:24 - progress_bar.py[line:272] - INFO: epoch 001:   3706 / 6136 loss=1.764, loss_v1=0, loss_v2=0, nll_loss=0.762, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=78.3, ups=1.22, wpb=64, bsz=64, num_updates=3690, lr=9.35853e-06, gnorm=3.149, loss_scale=0.002, train_wall=8, gb_free=13.8, wall=4218
2022-04-25 10:52:32 - progress_bar.py[line:272] - INFO: epoch 001:   3716 / 6136 loss=1.742, loss_v1=0, loss_v2=0, nll_loss=0.741, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=79.9, ups=1.25, wpb=64, bsz=64, num_updates=3700, lr=9.35506e-06, gnorm=3.176, loss_scale=0.002, train_wall=8, gb_free=13.3, wall=4226
2022-04-25 10:52:40 - progress_bar.py[line:272] - INFO: epoch 001:   3726 / 6136 loss=1.747, loss_v1=0, loss_v2=0, nll_loss=0.746, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=80, ups=1.25, wpb=64, bsz=64, num_updates=3710, lr=9.3516e-06, gnorm=2.758, loss_scale=0.002, train_wall=8, gb_free=13.9, wall=4234
2022-04-25 10:52:48 - progress_bar.py[line:272] - INFO: epoch 001:   3736 / 6136 loss=1.811, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=78.6, ups=1.23, wpb=64, bsz=64, num_updates=3720, lr=9.34813e-06, gnorm=3.059, loss_scale=0.002, train_wall=8, gb_free=13.9, wall=4242
2022-04-25 10:52:57 - progress_bar.py[line:272] - INFO: epoch 001:   3746 / 6136 loss=1.782, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=76.8, ups=1.2, wpb=64, bsz=64, num_updates=3730, lr=9.34466e-06, gnorm=2.942, loss_scale=0.002, train_wall=8, gb_free=13.7, wall=4250
2022-04-25 10:53:05 - progress_bar.py[line:272] - INFO: epoch 001:   3756 / 6136 loss=1.768, loss_v1=0, loss_v2=0, nll_loss=0.766, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=77.5, ups=1.21, wpb=64, bsz=64, num_updates=3740, lr=9.34119e-06, gnorm=2.937, loss_scale=0.002, train_wall=8, gb_free=13.9, wall=4259
2022-04-25 10:53:13 - progress_bar.py[line:272] - INFO: epoch 001:   3766 / 6136 loss=1.768, loss_v1=0, loss_v2=0, nll_loss=0.766, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=80.1, ups=1.25, wpb=64, bsz=64, num_updates=3750, lr=9.33773e-06, gnorm=3.641, loss_scale=0.002, train_wall=8, gb_free=13.7, wall=4267
2022-04-25 10:53:21 - progress_bar.py[line:272] - INFO: epoch 001:   3776 / 6136 loss=1.784, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=81, ups=1.27, wpb=64, bsz=64, num_updates=3760, lr=9.33426e-06, gnorm=3.309, loss_scale=0.002, train_wall=8, gb_free=14, wall=4275
2022-04-25 10:53:29 - progress_bar.py[line:272] - INFO: epoch 001:   3786 / 6136 loss=1.733, loss_v1=0, loss_v2=0, nll_loss=0.731, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=80, ups=1.25, wpb=64, bsz=64, num_updates=3770, lr=9.33079e-06, gnorm=2.71, loss_scale=0.002, train_wall=8, gb_free=12.2, wall=4283
2022-04-25 10:53:37 - progress_bar.py[line:272] - INFO: epoch 001:   3796 / 6136 loss=1.735, loss_v1=0, loss_v2=0, nll_loss=0.733, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=79.3, ups=1.24, wpb=64, bsz=64, num_updates=3780, lr=9.32732e-06, gnorm=3.12, loss_scale=0.002, train_wall=8, gb_free=13.4, wall=4291
2022-04-25 10:53:45 - progress_bar.py[line:272] - INFO: epoch 001:   3806 / 6136 loss=1.805, loss_v1=0, loss_v2=0, nll_loss=0.803, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=80.4, ups=1.26, wpb=64, bsz=64, num_updates=3790, lr=9.32386e-06, gnorm=3.504, loss_scale=0.002, train_wall=8, gb_free=13.8, wall=4299
2022-04-25 10:53:54 - progress_bar.py[line:272] - INFO: epoch 001:   3816 / 6136 loss=1.753, loss_v1=0, loss_v2=0, nll_loss=0.751, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=72.1, ups=1.13, wpb=64, bsz=64, num_updates=3800, lr=9.32039e-06, gnorm=3.261, loss_scale=0.002, train_wall=9, gb_free=13.4, wall=4308
2022-04-25 10:54:02 - progress_bar.py[line:272] - INFO: epoch 001:   3826 / 6136 loss=1.748, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=78.7, ups=1.23, wpb=64, bsz=64, num_updates=3810, lr=9.31692e-06, gnorm=3.391, loss_scale=0.002, train_wall=8, gb_free=12.5, wall=4316
2022-04-25 10:54:10 - progress_bar.py[line:272] - INFO: epoch 001:   3836 / 6136 loss=1.734, loss_v1=0, loss_v2=0, nll_loss=0.732, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=77.7, ups=1.21, wpb=64, bsz=64, num_updates=3820, lr=9.31345e-06, gnorm=3.169, loss_scale=0.002, train_wall=8, gb_free=11.3, wall=4324
2022-04-25 10:54:18 - progress_bar.py[line:272] - INFO: epoch 001:   3846 / 6136 loss=1.742, loss_v1=0, loss_v2=0, nll_loss=0.741, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=79.3, ups=1.24, wpb=64, bsz=64, num_updates=3830, lr=9.30999e-06, gnorm=3.104, loss_scale=0.002, train_wall=8, gb_free=12.9, wall=4332
2022-04-25 10:54:26 - progress_bar.py[line:272] - INFO: epoch 001:   3856 / 6136 loss=1.719, loss_v1=0, loss_v2=0, nll_loss=0.718, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=78.9, ups=1.23, wpb=64, bsz=64, num_updates=3840, lr=9.30652e-06, gnorm=2.771, loss_scale=0.002, train_wall=8, gb_free=11.6, wall=4340
2022-04-25 10:54:35 - progress_bar.py[line:272] - INFO: epoch 001:   3866 / 6136 loss=1.728, loss_v1=0, loss_v2=0, nll_loss=0.727, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=78, ups=1.22, wpb=64, bsz=64, num_updates=3850, lr=9.30305e-06, gnorm=3.08, loss_scale=0.002, train_wall=8, gb_free=13.6, wall=4348
2022-04-25 10:54:43 - progress_bar.py[line:272] - INFO: epoch 001:   3876 / 6136 loss=1.738, loss_v1=0, loss_v2=0, nll_loss=0.737, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=79.6, ups=1.24, wpb=64, bsz=64, num_updates=3860, lr=9.29958e-06, gnorm=3.214, loss_scale=0.002, train_wall=8, gb_free=13.6, wall=4356
2022-04-25 10:54:51 - progress_bar.py[line:272] - INFO: epoch 001:   3886 / 6136 loss=1.776, loss_v1=0, loss_v2=0, nll_loss=0.774, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=74.6, ups=1.16, wpb=64, bsz=64, num_updates=3870, lr=9.29612e-06, gnorm=2.877, loss_scale=0.002, train_wall=9, gb_free=12.8, wall=4365
2022-04-25 10:55:00 - progress_bar.py[line:272] - INFO: epoch 001:   3896 / 6136 loss=1.769, loss_v1=0, loss_v2=0, nll_loss=0.768, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=76.7, ups=1.2, wpb=64, bsz=64, num_updates=3880, lr=9.29265e-06, gnorm=2.885, loss_scale=0.002, train_wall=8, gb_free=13.5, wall=4373
2022-04-25 10:55:07 - progress_bar.py[line:272] - INFO: epoch 001:   3906 / 6136 loss=1.784, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=80.7, ups=1.26, wpb=64, bsz=64, num_updates=3890, lr=9.28918e-06, gnorm=3.205, loss_scale=0.002, train_wall=8, gb_free=13.9, wall=4381
2022-04-25 10:55:17 - progress_bar.py[line:272] - INFO: epoch 001:   3916 / 6136 loss=1.702, loss_v1=0, loss_v2=0, nll_loss=0.701, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=69.4, ups=1.08, wpb=64, bsz=64, num_updates=3900, lr=9.28571e-06, gnorm=3.124, loss_scale=0.002, train_wall=9, gb_free=12.6, wall=4390
2022-04-25 10:55:25 - progress_bar.py[line:272] - INFO: epoch 001:   3926 / 6136 loss=1.753, loss_v1=0, loss_v2=0, nll_loss=0.751, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=77.6, ups=1.21, wpb=64, bsz=64, num_updates=3910, lr=9.28225e-06, gnorm=3.24, loss_scale=0.002, train_wall=8, gb_free=12.8, wall=4399
2022-04-25 10:55:33 - progress_bar.py[line:272] - INFO: epoch 001:   3936 / 6136 loss=1.721, loss_v1=0, loss_v2=0, nll_loss=0.719, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=78.3, ups=1.22, wpb=64, bsz=64, num_updates=3920, lr=9.27878e-06, gnorm=2.96, loss_scale=0.002, train_wall=8, gb_free=13.8, wall=4407
2022-04-25 10:55:41 - progress_bar.py[line:272] - INFO: epoch 001:   3946 / 6136 loss=1.751, loss_v1=0, loss_v2=0, nll_loss=0.75, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=80.3, ups=1.25, wpb=64, bsz=64, num_updates=3930, lr=9.27531e-06, gnorm=3.029, loss_scale=0.002, train_wall=8, gb_free=13.3, wall=4415
2022-04-25 10:55:49 - progress_bar.py[line:272] - INFO: epoch 001:   3956 / 6136 loss=1.708, loss_v1=0, loss_v2=0, nll_loss=0.706, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=79.1, ups=1.24, wpb=64, bsz=64, num_updates=3940, lr=9.27184e-06, gnorm=2.888, loss_scale=0.002, train_wall=8, gb_free=13.6, wall=4423
2022-04-25 10:55:57 - progress_bar.py[line:272] - INFO: epoch 001:   3966 / 6136 loss=1.753, loss_v1=0, loss_v2=0, nll_loss=0.751, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=79.1, ups=1.24, wpb=64, bsz=64, num_updates=3950, lr=9.26838e-06, gnorm=3.13, loss_scale=0.002, train_wall=8, gb_free=12.8, wall=4431
2022-04-25 10:56:06 - progress_bar.py[line:272] - INFO: epoch 001:   3976 / 6136 loss=1.761, loss_v1=0, loss_v2=0, nll_loss=0.759, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=75.7, ups=1.18, wpb=64, bsz=64, num_updates=3960, lr=9.26491e-06, gnorm=2.979, loss_scale=0.002, train_wall=8, gb_free=12.8, wall=4439
2022-04-25 10:56:14 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0009765625
2022-04-25 10:56:15 - progress_bar.py[line:272] - INFO: epoch 001:   3987 / 6136 loss=1.745, loss_v1=0, loss_v2=0, nll_loss=0.743, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=72.8, ups=1.14, wpb=64, bsz=64, num_updates=3970, lr=9.26144e-06, gnorm=2.993, loss_scale=0.001, train_wall=9, gb_free=10.4, wall=4448
2022-04-25 10:56:22 - progress_bar.py[line:272] - INFO: epoch 001:   3997 / 6136 loss=1.745, loss_v1=0, loss_v2=0, nll_loss=0.744, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=81.6, ups=1.28, wpb=64, bsz=64, num_updates=3980, lr=9.25798e-06, gnorm=3.414, loss_scale=0.001, train_wall=8, gb_free=13.1, wall=4456
2022-04-25 10:56:32 - progress_bar.py[line:272] - INFO: epoch 001:   4007 / 6136 loss=1.769, loss_v1=0, loss_v2=0, nll_loss=0.768, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=69.4, ups=1.08, wpb=64, bsz=64, num_updates=3990, lr=9.25451e-06, gnorm=3.119, loss_scale=0.001, train_wall=9, gb_free=9.4, wall=4465
2022-04-25 10:56:40 - progress_bar.py[line:272] - INFO: epoch 001:   4017 / 6136 loss=1.758, loss_v1=0, loss_v2=0, nll_loss=0.756, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=78.4, ups=1.22, wpb=64, bsz=64, num_updates=4000, lr=9.25104e-06, gnorm=3.412, loss_scale=0.001, train_wall=8, gb_free=13.1, wall=4473
2022-04-25 10:56:40 - train.py[line:435] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - moe_layer.py[line:118] - WARNING: padding batch with unexpected size 15 (expected: 16)
2022-04-25 11:00:50 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 1.706 | loss_v1 0 | loss_v2 0 | nll_loss 0.704 | ntokens 15.999 | nsentences 15.999 | sample_size 15.999 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.63 | acc 0.7042 | wps 78.5 | wpb 16 | bsz 16 | num_updates 4000 | best_acc 0.7042
2022-04-25 11:00:50 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 4000 updates
2022-04-25 11:00:50 - trainer.py[line:432] - INFO: Saving checkpoint to ./fairseq_checkpoints/mnli/5_1e-5_4/checkpoint_1_4000.pt
2022-04-25 11:01:07 - trainer.py[line:442] - INFO: Finished saving checkpoint to ./fairseq_checkpoints/mnli/5_1e-5_4/checkpoint_1_4000.pt
2022-04-25 11:01:29 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./fairseq_checkpoints/mnli/5_1e-5_4/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 0.7042) (writing took 38.9219827032648 seconds)
2022-04-25 11:01:38 - progress_bar.py[line:272] - INFO: epoch 001:   4027 / 6136 loss=1.724, loss_v1=0, loss_v2=0, nll_loss=0.722, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=2.1, ups=0.03, wpb=64, bsz=64, num_updates=4010, lr=9.24757e-06, gnorm=3.245, loss_scale=0.001, train_wall=8, gb_free=12.3, wall=4771
2022-04-25 11:01:46 - progress_bar.py[line:272] - INFO: epoch 001:   4037 / 6136 loss=1.763, loss_v1=0, loss_v2=0, nll_loss=0.761, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=77.2, ups=1.21, wpb=64, bsz=64, num_updates=4020, lr=9.24411e-06, gnorm=3.317, loss_scale=0.001, train_wall=8, gb_free=12.9, wall=4780
2022-04-25 11:01:54 - progress_bar.py[line:272] - INFO: epoch 001:   4047 / 6136 loss=1.729, loss_v1=0, loss_v2=0, nll_loss=0.727, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=80.4, ups=1.26, wpb=64, bsz=64, num_updates=4030, lr=9.24064e-06, gnorm=2.619, loss_scale=0.001, train_wall=8, gb_free=12.3, wall=4788
2022-04-25 11:02:02 - progress_bar.py[line:272] - INFO: epoch 001:   4057 / 6136 loss=1.771, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=81.2, ups=1.27, wpb=64, bsz=64, num_updates=4040, lr=9.23717e-06, gnorm=3.712, loss_scale=0.001, train_wall=8, gb_free=12.8, wall=4796
2022-04-25 11:02:10 - progress_bar.py[line:272] - INFO: epoch 001:   4067 / 6136 loss=1.724, loss_v1=0, loss_v2=0, nll_loss=0.722, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=80.8, ups=1.26, wpb=64, bsz=64, num_updates=4050, lr=9.2337e-06, gnorm=3.101, loss_scale=0.001, train_wall=8, gb_free=13.2, wall=4803
2022-04-25 11:02:18 - progress_bar.py[line:272] - INFO: epoch 001:   4077 / 6136 loss=1.72, loss_v1=0, loss_v2=0, nll_loss=0.719, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=81.4, ups=1.27, wpb=64, bsz=64, num_updates=4060, lr=9.23024e-06, gnorm=3.166, loss_scale=0.001, train_wall=8, gb_free=14.1, wall=4811
2022-04-25 11:02:25 - progress_bar.py[line:272] - INFO: epoch 001:   4087 / 6136 loss=1.749, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=82, ups=1.28, wpb=64, bsz=64, num_updates=4070, lr=9.22677e-06, gnorm=3.242, loss_scale=0.001, train_wall=8, gb_free=13.5, wall=4819
2022-04-25 11:02:33 - progress_bar.py[line:272] - INFO: epoch 001:   4097 / 6136 loss=1.757, loss_v1=0, loss_v2=0, nll_loss=0.755, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=80.3, ups=1.25, wpb=64, bsz=64, num_updates=4080, lr=9.2233e-06, gnorm=3.072, loss_scale=0.001, train_wall=8, gb_free=10.1, wall=4827
2022-04-25 11:02:41 - progress_bar.py[line:272] - INFO: epoch 001:   4107 / 6136 loss=1.76, loss_v1=0, loss_v2=0, nll_loss=0.758, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=80.7, ups=1.26, wpb=64, bsz=64, num_updates=4090, lr=9.21983e-06, gnorm=3.122, loss_scale=0.001, train_wall=8, gb_free=13.8, wall=4835
2022-04-25 11:02:49 - progress_bar.py[line:272] - INFO: epoch 001:   4117 / 6136 loss=1.745, loss_v1=0, loss_v2=0, nll_loss=0.744, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=80.9, ups=1.26, wpb=64, bsz=64, num_updates=4100, lr=9.21637e-06, gnorm=3.506, loss_scale=0.001, train_wall=8, gb_free=12.2, wall=4843
2022-04-25 11:02:57 - progress_bar.py[line:272] - INFO: epoch 001:   4127 / 6136 loss=1.776, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=78.2, ups=1.22, wpb=64, bsz=64, num_updates=4110, lr=9.2129e-06, gnorm=3.045, loss_scale=0.001, train_wall=8, gb_free=12.1, wall=4851
2022-04-25 11:03:06 - progress_bar.py[line:272] - INFO: epoch 001:   4137 / 6136 loss=1.765, loss_v1=0, loss_v2=0, nll_loss=0.764, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=71.8, ups=1.12, wpb=64, bsz=64, num_updates=4120, lr=9.20943e-06, gnorm=2.869, loss_scale=0.001, train_wall=9, gb_free=11.6, wall=4860
2022-04-25 11:03:14 - progress_bar.py[line:272] - INFO: epoch 001:   4147 / 6136 loss=1.728, loss_v1=0, loss_v2=0, nll_loss=0.726, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=78.6, ups=1.23, wpb=64, bsz=64, num_updates=4130, lr=9.20596e-06, gnorm=3.348, loss_scale=0.001, train_wall=8, gb_free=13.9, wall=4868
2022-04-25 11:03:23 - progress_bar.py[line:272] - INFO: epoch 001:   4157 / 6136 loss=1.74, loss_v1=0, loss_v2=0, nll_loss=0.738, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=79, ups=1.24, wpb=64, bsz=64, num_updates=4140, lr=9.2025e-06, gnorm=2.84, loss_scale=0.001, train_wall=8, gb_free=12.9, wall=4876
2022-04-25 11:03:31 - progress_bar.py[line:272] - INFO: epoch 001:   4167 / 6136 loss=1.722, loss_v1=0, loss_v2=0, nll_loss=0.72, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=78.8, ups=1.23, wpb=64, bsz=64, num_updates=4150, lr=9.19903e-06, gnorm=2.976, loss_scale=0.001, train_wall=8, gb_free=13.9, wall=4884
2022-04-25 11:03:39 - progress_bar.py[line:272] - INFO: epoch 001:   4177 / 6136 loss=1.772, loss_v1=0, loss_v2=0, nll_loss=0.77, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=79.9, ups=1.25, wpb=64, bsz=64, num_updates=4160, lr=9.19556e-06, gnorm=3.296, loss_scale=0.001, train_wall=8, gb_free=14.1, wall=4892
2022-04-25 11:03:44 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.00048828125
2022-04-25 11:03:48 - progress_bar.py[line:272] - INFO: epoch 001:   4188 / 6136 loss=1.788, loss_v1=0, loss_v2=0, nll_loss=0.785, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=65.8, ups=1.03, wpb=64, bsz=64, num_updates=4170, lr=9.19209e-06, gnorm=3.202, loss_scale=0.0005, train_wall=10, gb_free=13.3, wall=4902
2022-04-25 11:03:56 - progress_bar.py[line:272] - INFO: epoch 001:   4198 / 6136 loss=1.729, loss_v1=0, loss_v2=0, nll_loss=0.727, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=81.2, ups=1.27, wpb=64, bsz=64, num_updates=4180, lr=9.18863e-06, gnorm=3.048, loss_scale=0.0005, train_wall=8, gb_free=13, wall=4910
2022-04-25 11:04:05 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.000244140625
2022-04-25 11:04:06 - progress_bar.py[line:272] - INFO: epoch 001:   4209 / 6136 loss=1.763, loss_v1=0, loss_v2=0, nll_loss=0.761, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=66.8, ups=1.04, wpb=64, bsz=64, num_updates=4190, lr=9.18516e-06, gnorm=3.415, loss_scale=0.0002, train_wall=10, gb_free=8, wall=4920
2022-04-25 11:04:14 - progress_bar.py[line:272] - INFO: epoch 001:   4219 / 6136 loss=1.707, loss_v1=0, loss_v2=0, nll_loss=0.706, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=81.7, ups=1.28, wpb=64, bsz=64, num_updates=4200, lr=9.18169e-06, gnorm=2.604, loss_scale=0.0002, train_wall=8, gb_free=13.7, wall=4927
2022-04-25 11:04:22 - progress_bar.py[line:272] - INFO: epoch 001:   4229 / 6136 loss=1.696, loss_v1=0, loss_v2=0, nll_loss=0.695, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=81, ups=1.27, wpb=64, bsz=64, num_updates=4210, lr=9.17822e-06, gnorm=2.617, loss_scale=0.0002, train_wall=8, gb_free=13.3, wall=4935
2022-04-25 11:04:29 - progress_bar.py[line:272] - INFO: epoch 001:   4239 / 6136 loss=1.8, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=81.6, ups=1.28, wpb=64, bsz=64, num_updates=4220, lr=9.17476e-06, gnorm=3.121, loss_scale=0.0002, train_wall=8, gb_free=13.9, wall=4943
2022-04-25 11:04:37 - progress_bar.py[line:272] - INFO: epoch 001:   4249 / 6136 loss=1.758, loss_v1=0, loss_v2=0, nll_loss=0.755, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=81.7, ups=1.28, wpb=64, bsz=64, num_updates=4230, lr=9.17129e-06, gnorm=3.244, loss_scale=0.0002, train_wall=8, gb_free=13.8, wall=4951
2022-04-25 11:04:45 - progress_bar.py[line:272] - INFO: epoch 001:   4259 / 6136 loss=1.75, loss_v1=0, loss_v2=0, nll_loss=0.748, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=78.4, ups=1.22, wpb=64, bsz=64, num_updates=4240, lr=9.16782e-06, gnorm=2.575, loss_scale=0.0002, train_wall=8, gb_free=12.5, wall=4959
2022-04-25 11:04:54 - progress_bar.py[line:272] - INFO: epoch 001:   4269 / 6136 loss=1.722, loss_v1=0, loss_v2=0, nll_loss=0.72, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=79.9, ups=1.25, wpb=64, bsz=64, num_updates=4250, lr=9.16436e-06, gnorm=2.798, loss_scale=0.0002, train_wall=8, gb_free=13.9, wall=4967
2022-04-25 11:05:01 - progress_bar.py[line:272] - INFO: epoch 001:   4279 / 6136 loss=1.735, loss_v1=0, loss_v2=0, nll_loss=0.734, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=80.3, ups=1.26, wpb=64, bsz=64, num_updates=4260, lr=9.16089e-06, gnorm=2.606, loss_scale=0.0002, train_wall=8, gb_free=13.5, wall=4975
2022-04-25 11:05:10 - progress_bar.py[line:272] - INFO: epoch 001:   4289 / 6136 loss=1.75, loss_v1=0, loss_v2=0, nll_loss=0.748, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=79.1, ups=1.24, wpb=64, bsz=64, num_updates=4270, lr=9.15742e-06, gnorm=3.069, loss_scale=0.0002, train_wall=8, gb_free=13.6, wall=4983
2022-04-25 11:05:18 - progress_bar.py[line:272] - INFO: epoch 001:   4299 / 6136 loss=1.715, loss_v1=0, loss_v2=0, nll_loss=0.713, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=80, ups=1.25, wpb=64, bsz=64, num_updates=4280, lr=9.15395e-06, gnorm=2.914, loss_scale=0.0002, train_wall=8, gb_free=13.2, wall=4991
2022-04-25 11:05:26 - progress_bar.py[line:272] - INFO: epoch 001:   4309 / 6136 loss=1.741, loss_v1=0, loss_v2=0, nll_loss=0.739, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=80.6, ups=1.26, wpb=64, bsz=64, num_updates=4290, lr=9.15049e-06, gnorm=2.803, loss_scale=0.0002, train_wall=8, gb_free=12.1, wall=4999
2022-04-25 11:05:33 - progress_bar.py[line:272] - INFO: epoch 001:   4319 / 6136 loss=1.713, loss_v1=0, loss_v2=0, nll_loss=0.711, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=81.8, ups=1.28, wpb=64, bsz=64, num_updates=4300, lr=9.14702e-06, gnorm=3.189, loss_scale=0.0002, train_wall=8, gb_free=13.7, wall=5007
2022-04-25 11:05:41 - progress_bar.py[line:272] - INFO: epoch 001:   4329 / 6136 loss=1.737, loss_v1=0, loss_v2=0, nll_loss=0.735, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=80.6, ups=1.26, wpb=64, bsz=64, num_updates=4310, lr=9.14355e-06, gnorm=2.749, loss_scale=0.0002, train_wall=8, gb_free=13.8, wall=5015
2022-04-25 11:05:44 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0001220703125
2022-04-25 11:05:50 - progress_bar.py[line:272] - INFO: epoch 001:   4340 / 6136 loss=1.784, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=72.5, ups=1.13, wpb=64, bsz=64, num_updates=4320, lr=9.14008e-06, gnorm=2.911, loss_scale=0.0001, train_wall=9, gb_free=12.4, wall=5024
2022-04-25 11:05:58 - progress_bar.py[line:272] - INFO: epoch 001:   4350 / 6136 loss=1.741, loss_v1=0, loss_v2=0, nll_loss=0.739, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=79.6, ups=1.24, wpb=64, bsz=64, num_updates=4330, lr=9.13662e-06, gnorm=2.644, loss_scale=0.0001, train_wall=8, gb_free=13.5, wall=5032
2022-04-25 11:06:06 - progress_bar.py[line:272] - INFO: epoch 001:   4360 / 6136 loss=1.746, loss_v1=0, loss_v2=0, nll_loss=0.745, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=80.4, ups=1.26, wpb=64, bsz=64, num_updates=4340, lr=9.13315e-06, gnorm=2.907, loss_scale=0.0001, train_wall=8, gb_free=13.7, wall=5040
2022-04-25 11:06:14 - progress_bar.py[line:272] - INFO: epoch 001:   4370 / 6136 loss=1.748, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=76.7, ups=1.2, wpb=64, bsz=64, num_updates=4350, lr=9.12968e-06, gnorm=3.13, loss_scale=0.0001, train_wall=8, gb_free=13.8, wall=5048
2022-04-25 11:06:22 - progress_bar.py[line:272] - INFO: epoch 001:   4380 / 6136 loss=1.759, loss_v1=0, loss_v2=0, nll_loss=0.757, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=79.5, ups=1.24, wpb=64, bsz=64, num_updates=4360, lr=9.12621e-06, gnorm=2.795, loss_scale=0.0001, train_wall=8, gb_free=13.4, wall=5056
2022-04-25 11:06:31 - progress_bar.py[line:272] - INFO: epoch 001:   4390 / 6136 loss=1.779, loss_v1=0, loss_v2=0, nll_loss=0.777, ntokens=64, nsentences=64, sample_size=64, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=79.7, ups=1.25, wpb=64, bsz=64, num_updates=4370, lr=9.12275e-06, gnorm=2.312, loss_scale=0.0001, train_wall=8, gb_free=10.3, wall=5064
/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:787: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:752: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using non-full backward hooks on a Module that does not return a "
/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:777: UserWarning: Using a non-full backward hook when outputs are generated by different autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_output. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when outputs are generated by different autograd Nodes "
Traceback (most recent call last):
  File "/workspace/OFA/trainer.py", line 871, in train_step
    grad_norm = self.clip_grad_norm(self.cfg.optimization.clip_norm)
  File "/workspace/OFA/trainer.py", line 1208, in clip_grad_norm
    return self.optimizer.clip_grad_norm(
  File "/workspace/OFA/fairseq/fairseq/optim/fp16_optimizer.py", line 200, in clip_grad_norm
    self.scaler.check_overflow(grad_norm)
  File "/workspace/OFA/fairseq/fairseq/optim/dynamic_loss_scaler.py", line 61, in check_overflow
    raise FloatingPointError(
FloatingPointError: Minimum loss scale reached (0.0001). Your loss is probably exploding. Try lowering the learning rate, using gradient clipping or increasing the batch size.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../../train.py", line 527, in <module>
    cli_main()
  File "../../train.py", line 520, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/workspace/OFA/fairseq/fairseq/distributed/utils.py", line 379, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/workspace/OFA/fairseq/fairseq/distributed/utils.py", line 353, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 189, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/opt/conda/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "../../train.py", line 300, in train
    log_output = trainer.train_step(samples)
  File "/opt/conda/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/workspace/OFA/trainer.py", line 910, in train_step
    self.task.train_step(
  File "/workspace/OFA/tasks/ofa_task.py", line 319, in train_step
    loss, sample_size, logging_output = criterion(model, sample, update_num=update_num)
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 881, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/workspace/OFA/criterions/label_smoothed_cross_entropy.py", line 243, in forward
    net_output = model(**sample["net_input"])
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 881, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/workspace/OFA/models/ofa/ofa.py", line 89, in forward
    encoder_out = self.encoder(
  File "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py", line 897, in _call_impl
    var = next((v for v in var.values() if isinstance(v, torch.Tensor)))
StopIteration
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/opt/conda/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/opt/conda/bin/python3', '-u', '../../train.py', '--local_rank=0', '../../dataset/glue_data/mnli_train.tsv,../../dataset/glue_data/mnli_dev.tsv', '--selected-cols=0,1,2', '--bpe-dir=../../utils/BPE', '--user-dir=../../ofa_module', '--restore-file=../../checkpoints/ofa_base.pt', '--reset-optimizer', '--reset-dataloader', '--reset-meters', '--save-dir=./fairseq_checkpoints/mnli/5_1e-5_4', '--task=mnli', '--arch=ofa_resmo', '--criterion=adjust_label_smoothed_cross_entropy', '--label-smoothing=0.0', '--batch-size=16', '--update-freq=4', '--encoder-normalize-before', '--decoder-normalize-before', '--share-decoder-input-output-embed', '--share-all-embeddings', '--layernorm-embedding', '--patch-layernorm-embedding', '--code-layernorm-embedding', '--resnet-drop-path-rate=0.0', '--encoder-drop-path-rate=0.1', '--decoder-drop-path-rate=0.1', '--dropout=0.1', '--attention-dropout=0.0', '--weight-decay=0.01', '--optimizer=adam', '--adam-betas=(0.9,0.999)', '--adam-eps=1e-08', '--clip-norm=0.0', '--lr-scheduler=polynomial_decay', '--lr=1e-5', '--max-epoch=5', '--warmup-ratio=0.06', '--log-format=simple', '--log-interval=10', '--fixed-validation-seed=7', '--keep-best-checkpoints=1', '--save-interval=1000', '--validate-interval=1', '--save-interval-updates=1000', '--validate-interval-updates=1000', '--best-checkpoint-metric=acc', '--maximize-best-checkpoint-metric', '--max-src-length=512', '--max-tgt-length=30', '--find-unused-parameters', '--add-type-embedding', '--scale-attn', '--scale-fc', '--scale-heads', '--disable-entangle', '--num-bins=1000', '--prompt-type=src', '--fp16', '--fp16-init-scale=16', '--fp16-scale-window=512', '--num-workers=0']' returned non-zero exit status 1.
Killing subprocess 28241
