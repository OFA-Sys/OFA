/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-09-20 13:39:37 - utils.py[line:255] - INFO: distributed init (rank 0): env://
2023-09-20 13:39:37 - utils.py[line:261] - INFO: Start init
2023-09-20 13:39:37 - utils.py[line:255] - INFO: distributed init (rank 1): env://
2023-09-20 13:39:37 - utils.py[line:261] - INFO: Start init
2023-09-20 13:39:37 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-09-20 13:39:37 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-09-20 13:39:37 - distributed_c10d.py[line:262] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
2023-09-20 13:39:37 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 1
single-machine distributed training is initialized.
2023-09-20 13:39:37 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
2023-09-20 13:39:37 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 0
single-machine distributed training is initialized.
2023-09-20 13:39:38 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './tensorboard/adapter_all_cand_20_3e-5_512', 'wandb_project': 'OFA-VG', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 2097152, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 8, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 3, 'validate_interval_updates': 1, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 8, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 20, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [4], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/data/hulab/zcai75/checkpoints/OFA/scene_graph_checkpoints/adapter_all_cand_20_3e-5_512_sgcls', 'restore_file': '/data/hulab/zcai75/checkpoints/OFA/scene_graph_checkpoints/adapter_all_cand_20_3e-5_512_sgcls/checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=2097152, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=8, batch_size_valid=8, best_checkpoint_metric='loss', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/hulab/zcai75/OFA_data/vg/vg_train_full.tsv,/data/hulab/zcai75/OFA_data/vg/vg_val_toy.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"max_len_a":0,"max_len_b":999,"no_repeat_ngram_size":5}', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder=True, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=20, max_source_positions=1024, max_src_length=200, max_target_positions=1024, max_tgt_length=200, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=512, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/hulab/zcai75/checkpoints/OFA/scene_graph_checkpoints/adapter_all_cand_20_3e-5_512_sgcls/checkpoint_last.pt', sample_patch_num=196, save_dir='/data/hulab/zcai75/checkpoints/OFA/scene_graph_checkpoints/adapter_all_cand_20_3e-5_512_sgcls', save_interval=1, save_interval_updates=0, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols=None, sentence_avg=False, sg_mode='sgcls', shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='scene_graph', tensorboard_logdir='./tensorboard/adapter_all_cand_20_3e-5_512', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[4], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', valid_subset='valid', validate_after_updates=0, validate_interval=3, validate_interval_updates=1, vg_json_dir=None, wandb_project='OFA-VG', warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'scene_graph', 'data': '/data/hulab/zcai75/OFA_data/vg/vg_train_full.tsv,/data/hulab/zcai75/OFA_data/vg/vg_val_toy.tsv', 'selected_cols': None, 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 200, 'max_tgt_length': 200, 'code_dict_size': 8192, 'patch_image_size': 512, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_args': '{"beam":5,"max_len_a":0,"max_len_b":999,"no_repeat_ngram_size":5}', 'eval_print_samples': False, 'vg_json_dir': None, 'sg_mode': 'sgcls'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-09-20 13:39:38 - scene_graph.py[line:111] - INFO: sg setup: source dictionary: 59460 types
2023-09-20 13:39:38 - scene_graph.py[line:112] - INFO: sg setup: target dictionary: 59460 types
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-09-20 13:39:41 - train.py[line:110] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59460, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59460, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59460, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-09-20 13:39:41 - train.py[line:111] - INFO: task: SceneGraphTask
2023-09-20 13:39:41 - train.py[line:112] - INFO: model: OFAModel
2023-09-20 13:39:41 - train.py[line:113] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-09-20 13:39:41 - train.py[line:114] - INFO: num. shared model params: 182,240,840 (num. trained: 61,812,648)
2023-09-20 13:39:41 - train.py[line:121] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile /data/hulab/zcai75/OFA_data/vg/vg_val_toy.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile /data/hulab/zcai75/OFA_data/vg/vg_val_toy.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file /data/hulab/zcai75/OFA_data/vg/vg_val_toy.tsv slice_id 0 row count 50 total row count 100
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2023-09-20 13:39:41 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
local datafile /data/hulab/zcai75/OFA_data/vg/vg_val_toy.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile /data/hulab/zcai75/OFA_data/vg/vg_val_toy.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file /data/hulab/zcai75/OFA_data/vg/vg_val_toy.tsv slice_id 1 row count 50 total row count 100
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2023-09-20 13:39:41 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-09-20 13:39:41 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-09-20 13:39:41 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2023-09-20 13:39:41 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.679 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-09-20 13:39:41 - utils.py[line:761] - INFO: rank   1: capabilities =  8.6  ; total memory = 23.679 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-09-20 13:39:41 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2023-09-20 13:39:41 - train.py[line:152] - INFO: training on 2 devices (GPUs/TPUs)
2023-09-20 13:39:41 - train.py[line:157] - INFO: max tokens per device = None and max sentences per device = 8
2023-09-20 13:39:41 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/hulab/zcai75/checkpoints/OFA/scene_graph_checkpoints/adapter_all_cand_20_3e-5_512_sgcls/checkpoint_last.pt
2023-09-20 13:39:43 - trainer.py[line:617] - INFO: Loaded checkpoint /data/hulab/zcai75/checkpoints/OFA/scene_graph_checkpoints/adapter_all_cand_20_3e-5_512_sgcls/checkpoint_last.pt (epoch 3 @ 1955 updates)
local datafile /data/hulab/zcai75/OFA_data/vg/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-09-20 13:39:43 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile /data/hulab/zcai75/OFA_data/vg/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile /data/hulab/zcai75/OFA_data/vg/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file /data/hulab/zcai75/OFA_data/vg/vg_train_full.tsv slice_id 1 row count 31361 total row count 62723
local datafile /data/hulab/zcai75/OFA_data/vg/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file /data/hulab/zcai75/OFA_data/vg/vg_train_full.tsv slice_id 0 row count 31362 total row count 62723
slice_id 1 seek offset 31362
slice_id 1 seek offset 31362
Total steps 19620, warmup steps 1177, warmup_factor 1.0
slice_id 0 seek offset 0
slice_id 0 seek offset 0
Total steps 19620, warmup steps 1177, warmup_factor 1.0
wandb: Currently logged in as: jackcai1206. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/zcai75/Github/OFA_forked/run_scripts/scene_graph/wandb/run-20230920_133945-7b8tcrv6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run adapter_all_cand_20_3e-5_512_sgcls
wandb:  View project at https://wandb.ai/jackcai1206/OFA-VG
wandb:  View run at https://wandb.ai/jackcai1206/OFA-VG/runs/7b8tcrv6
2023-09-20 13:39:51 - trainer.py[line:703] - INFO: begin training epoch 3
2023-09-20 13:39:51 - train.py[line:305] - INFO: Start iterating over samples
2023-09-20 13:39:54 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 1 seek offset 50
slice_id 0 seek offset 0
slice_id 1 seek offset 50
slice_id 0 seek offset 0
/home/zcai75/Github/OFA/fairseq/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  beams_buf = indices_buf // vocab_size
/home/zcai75/Github/OFA/fairseq/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  beams_buf = indices_buf // vocab_size
/home/zcai75/Github/OFA_forked/models/sequence_generator.py:705: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  unfin_idx = bbsz_idx // beam_size
/home/zcai75/Github/OFA_forked/models/sequence_generator.py:705: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  unfin_idx = bbsz_idx // beam_size
['<sub> train<bin_129><bin_75><bin_162><bin_691><pred> has<obj> windshield<bin_482><bin_216><bin_545><bin_415><sub> windshield<bin_482><bin_216><bin_545><bin_414><pred> on<obj> train<bin_129><bin_75><bin_162><bin_689><sub> windshield<bin_482><bin_215><bin_545><bin_415><pred> on<obj> train<bin_131><bin_75><bin_162><bin_691><sub> windshield<bin_482><bin_214><bin_545><bin_414><pred> of<obj> train<bin_129><bin_75><bin_164><bin_691><sub> windshield<bin_480><bin_216><bin_545><bin_415><pred> of<obj> train<bin_131><bin_75><bin_164><bin_691><sub> train<bin_129><bin_75><bin_163><bin_691><pred> has<obj> window<bin_482><bin_216><bin_545><bin_415>', '<sub> train<bin_129><bin_75><bin_162><bin_691><pred> has<obj> windshield<bin_482><bin_216><bin_545><bin_415><sub> windshield<bin_482><bin_216><bin_545><bin_414><pred> on<obj> train<bin_129><bin_75><bin_162><bin_689><sub> windshield<bin_482><bin_215><bin_545><bin_415><pred> on<obj> train<bin_131><bin_75><bin_162><bin_691><sub> windshield<bin_482><bin_214><bin_545><bin_414><pred> of<obj> train<bin_129><bin_75><bin_164><bin_691><sub> windshield<bin_480><bin_216><bin_545><bin_415><pred> of<obj> train<bin_131><bin_75><bin_164><bin_691>', '<sub> train<bin_129><bin_75><bin_162><bin_691><pred> has<obj> windshield<bin_482><bin_216><bin_545><bin_415><sub> windshield<bin_482><bin_216><bin_545><bin_414><pred> on<obj> train<bin_129><bin_75><bin_162><bin_689><sub> windshield<bin_482><bin_215><bin_545><bin_415><pred> on<obj> train<bin_131><bin_75><bin_162><bin_691><sub> windshield<bin_482><bin_214><bin_545><bin_414><pred> of<obj> train<bin_129><bin_75><bin_164><bin_691>', '<sub> train<bin_129><bin_75><bin_162><bin_691><pred> has<obj> windshield<bin_482><bin_216><bin_545><bin_415><sub> windshield<bin_482><bin_216><bin_545><bin_414><pred> on<obj> train<bin_129><bin_75><bin_162><bin_689><sub> windshield<bin_482><bin_215><bin_545><bin_415><pred> on<obj> train<bin_131><bin_75><bin_162><bin_691><sub> windshield<bin_482><bin_214><bin_545><bin_414><pred> of<obj> train<bin_129><bin_75><bin_164><bin_691><sub> windshield<bin_480><bin_216><bin_545><bin_415><pred> of<obj> train<bin_131><bin_75><bin_164><bin_691><sub> train<bin_129><bin_75><bin_163><bin_691><pred> has<obj> window<bin_482><bin_216><bin_545><bin_414><sub> windshield<bin_482><bin_216><bin_543><bin_414><pred> on<obj> car<bin_224><bin_999>ibliography', '<sub> train<bin_129><bin_75><bin_162><bin_691><pred> has<obj> windshield<bin_482><bin_216><bin_545><bin_415><sub> windshield<bin_482><bin_216><bin_545><bin_414><pred> on<obj> train<bin_129><bin_75><bin_162><bin_689><sub> windshield<bin_482><bin_215><bin_545><bin_415><pred> on<obj> train<bin_131><bin_75><bin_162><bin_691><sub> windshield<bin_482><bin_214><bin_545><bin_414><pred> of<obj> train<bin_129><bin_75><bin_164><bin_691><sub> windshield<bin_480><bin_216><bin_545><bin_415><pred> of<obj> train<bin_131><bin_75><bin_164><bin_691><sub> train<bin_129><bin_75><bin_163><bin_691><pred> has<obj> window<bin_482><bin_216><bin_545><bin_414><sub> windshield<bin_482><bin_216><bin_543><bin_415><pred> on<obj> car<bin_224><bin_999>ibliography']
<sub> 4512 <bin_129> <bin_75> <bin_162> <bin_691> <pred> 468 <obj> 38866 <bin_482> <bin_216> <bin_545> <bin_415> <sub> 38866 <bin_482> <bin_216> <bin_545> <bin_414> <pred> 319 <obj> 4512 <bin_129> <bin_75> <bin_162> <bin_689> <sub> 38866 <bin_482> <bin_215> <bin_545> <bin_415> <pred> 319 <obj> 4512 <bin_131> <bin_75> <bin_162> <bin_691> <sub> 38866 <bin_482> <bin_214> <bin_545> <bin_414> <pred> 286 <obj> 4512 <bin_129> <bin_75> <bin_164> <bin_691> <sub> 38866 <bin_480> <bin_216> <bin_545> <bin_415> <pred> 286 <obj> 4512 <bin_131> <bin_75> <bin_164> <bin_691> <sub> 4512 <bin_129> <bin_75> <bin_163> <bin_691> <pred> 468 <obj> 4324 <bin_482> <bin_216> <bin_545> <bin_415>
Box too short, this should not happen: bus<bin_193><bin_743><bin_242> A
Triplet too short, this should not happen: ['fence<bin_0><bin_533><bin_996><bin_997>']
Triplet too long, this should not happen: ['window<bin_183><bin_260><bin_636><bin_622>', 'on', 'car<bin_18><bin_84><bin_991><bin_996>', 'on']
['<sub> building<bin_0><bin_180><bin_995><bin_997><pred> has<obj> clock<bin_191><bin_35> S<bin_695><sub> clock<bin_191><bin_35> S<bin_697><pred> has<obj> hand<bin_460><bin_298><bin_622><bin_385><sub> clock<bin_191><bin_35> seeded<bin_695><pred> has<obj> hand<bin_458><bin_298><bin_622><bin_385><sub> hand<bin_460><bin_298><bin_622><bin_384><pred> on<obj> clock<bin_191><bin_35> seeded<bin_697><sub> clock<bin_189><bin_35> seeded<bin_697><pred> on<obj> building<bin_0><bin_182><bin_995><bin_997><sub> hand<bin_460><bin_298><bin_624><bin_385><pred> on<obj> clock<bin_189><bin_35> seeded<bin_695><sub> clock<bin_191><bin_37> seeded<bin_695><pred> on<obj> tower<bin_0><bin_180><bin_995><bin_997><sub> clock<bin_189><bin_37> seeded<bin_692><pred> on<obj> building<bin_2><bin_180><bin_995><bin_997>', '<sub> building<bin_0><bin_180><bin_995><bin_997><pred> has<obj> clock<bin_191><bin_35> S<bin_695><sub> clock<bin_191><bin_35> S<bin_697><pred> has<obj> hand<bin_460><bin_298><bin_622><bin_385><sub> clock<bin_191><bin_35> seeded<bin_695><pred> has<obj> hand<bin_458><bin_298><bin_622><bin_385><sub> hand<bin_460><bin_298><bin_622><bin_384><pred> on<obj> clock<bin_191><bin_35> seeded<bin_697><sub> clock<bin_189><bin_35> seeded<bin_697><pred> on<obj> building<bin_0><bin_182><bin_995><bin_997><sub> hand<bin_460><bin_298><bin_624><bin_385><pred> on<obj> clock<bin_189><bin_35> seeded<bin_695><sub> clock<bin_191><bin_37> seeded<bin_695><pred> on<obj> tower<bin_0><bin_180><bin_995><bin_997>', '<sub> building<bin_0><bin_180><bin_995><bin_997><pred> has<obj> clock<bin_191><bin_35> S<bin_695><sub> clock<bin_191><bin_35> S<bin_697><pred> has<obj> hand<bin_460><bin_298><bin_622><bin_385><sub> clock<bin_191><bin_35> seeded<bin_695><pred> has<obj> hand<bin_458><bin_298><bin_622><bin_385><sub> hand<bin_460><bin_298><bin_622><bin_384><pred> on<obj> clock<bin_191><bin_35> seeded<bin_697><sub> clock<bin_189><bin_35> seeded<bin_697><pred> on<obj> building<bin_0><bin_182><bin_995><bin_997><sub> hand<bin_460><bin_298><bin_624><bin_385><pred> on<obj> clock<bin_189><bin_35> seeded<bin_695><sub> clock<bin_191><bin_37> seeded<bin_695><pred> on<obj> tower<bin_0><bin_182><bin_995><bin_997>', '<sub> building<bin_0><bin_180><bin_995><bin_997><pred> has<obj> clock<bin_191><bin_35> S<bin_695><sub> clock<bin_191><bin_35> S<bin_697><pred> has<obj> hand<bin_460><bin_298><bin_622><bin_385><sub> clock<bin_191><bin_35> seeded<bin_695><pred> has<obj> hand<bin_458><bin_298><bin_622><bin_385><sub> hand<bin_460><bin_298><bin_622><bin_384><pred> on<obj> clock<bin_191><bin_35> seeded<bin_697><sub> clock<bin_189><bin_35> seeded<bin_697><pred> on<obj> building<bin_0><bin_182><bin_995><bin_997>', '<sub> building<bin_0><bin_180><bin_995><bin_997><pred> has<obj> clock<bin_191><bin_35> S<bin_695><sub> clock<bin_191><bin_35> S<bin_697><pred> has<obj> hand<bin_460><bin_298><bin_622><bin_385><sub> clock<bin_191><bin_35> seeded<bin_695><pred> has<obj> hand<bin_458><bin_298><bin_622><bin_385><sub> hand<bin_460><bin_298><bin_622><bin_384><pred> on<obj> clock<bin_191><bin_35> seeded<bin_697><sub> clock<bin_189><bin_35> seeded<bin_695><pred> on<obj> building<bin_0><bin_182><bin_995><bin_997>']
<sub> 2615 <bin_0> <bin_180> <bin_995> <bin_997> <pred> 468 <obj> 8801 <bin_191> <bin_35> 311 <bin_695> <sub> 8801 <bin_191> <bin_35> 311 <bin_697> <pred> 468 <obj> 1021 <bin_460> <bin_298> <bin_622> <bin_385> <sub> 8801 <bin_191> <bin_35> 48453 <bin_695> <pred> 468 <obj> 1021 <bin_458> <bin_298> <bin_622> <bin_385> <sub> 1021 <bin_460> <bin_298> <bin_622> <bin_384> <pred> 319 <obj> 8801 <bin_191> <bin_35> 48453 <bin_697> <sub> 8801 <bin_189> <bin_35> 48453 <bin_697> <pred> 319 <obj> 2615 <bin_0> <bin_182> <bin_995> <bin_997> <sub> 1021 <bin_460> <bin_298> <bin_624> <bin_385> <pred> 319 <obj> 8801 <bin_189> <bin_35> 48453 <bin_695> <sub> 8801 <bin_191> <bin_37> 48453 <bin_695> <pred> 319 <obj> 10580 <bin_0> <bin_180> <bin_995> <bin_997> <sub> 8801 <bin_189> <bin_37> 48453 <bin_692> <pred> 319 <obj> 2615 <bin_2> <bin_180> <bin_995> <bin_997>
Box too short, this should not happen: clock<bin_191><bin_35> S<bin_695>
Box too short, this should not happen: clock<bin_191><bin_35> S<bin_697>
Box too short, this should not happen: clock<bin_191><bin_35> seeded<bin_695>
Box too short, this should not happen: clock<bin_191><bin_35> seeded<bin_697>
Box too short, this should not happen: clock<bin_189><bin_35> seeded<bin_697>
Box too short, this should not happen: clock<bin_189><bin_35> seeded<bin_695>
Box too short, this should not happen: clock<bin_191><bin_37> seeded<bin_695>
Box too short, this should not happen: clock<bin_189><bin_37> seeded<bin_692>
no prediction
Triplet too short, this should not happen: ['man<bin_90><bin_146><bin_597><bin_996>']
Triplet too short, this should not happen: ['woman<bin_392><bin_145><bin_597><bin_996>']
Triplet too short, this should not happen: ['man<bin_0><bin_148><bin_597><bin_996>']
Box too short, this should not happen: man<bin_0><bin_45>atell<bin_996>
Triplet too short, this should not happen: ['man<bin_0><bin_47><bin_991><bin_996>']
Triplet too short, this should not happen: ['man<bin_0><bin_43><bin_991><bin_996>']
Triplet too short, this should not happen: ['man<bin_0><bin_46><bin_991><bin_996>']
Triplet too short, this should not happen: ['man<bin_0><bin_48><bin_991><bin_996>']
Box too short, this should not happen: hat<bin_118><bin_0>acular<bin_222>
Triplet too long, this should not happen: ['car<bin_0><bin_460><bin_133><bin_996>', 'behind', 'man<bin_0><bin_457><bin_131><bin_996>', 'behind']
Triplet too short, this should not happen: ['window<bin_79><bin_599><bin_153><bin_679>']
Triplet too short, this should not happen: ['building<bin_6><bin_396><bin_991><bin_996>']
Box too short, this should not happen: tie<bin_315> A<bin_378><bin_997>
Box too short, this should not happen: sock<bin_556><bin_491> A<bin_738>
Triplet too long, this should not happen: ['chair<bin_29><bin_116><bin_571><bin_738>', 'near', 'chair<bin_30><bin_116><bin_566><bin_738>', 'near']
Triplet too long, this should not happen: ['train<bin_103><bin_161><bin_917><bin_996>', 'on', 'track<bin_0><bin_628><bin_997><bin_996>', 'on']
label not found train tracks on
Triplet too short, this should not happen: ['woman<bin_713><bin_281><bin_993><bin_993>']
Box too short, this should not happen: woman<bin_240><bin_47> A<bin_996>
Triplet too long, this should not happen: ['hand<bin_548><bin_396><bin_658><bin_658>', 'of', 'woman<bin_240><bin_47> D<bin_996>', 'of']
Box too short, this should not happen: woman<bin_240><bin_47> D<bin_996>
Box too short, this should not happen: door<bin_0><bin_18> glob<bin_997>
Box too short, this should not happen: building<code_8190><bin_0><bin_999><bin_999>
Box too short, this should not happen: building<bin_0><bin_0>iu<bin_999>
Box too short, this should not happen: bus<bin_41><bin_263><bin_736> A
Triplet too long, this should not happen: ['door<bin_626><bin_441>457<bin_739>', 'of', 'bus<bin_42><bin_263><bin_736><bin_996>', 'of']
Box too short, this should not happen: door<bin_626><bin_441>457<bin_739>
Triplet too short, this should not happen: ['door<bin_626><bin_439>457<bin_739>']
Triplet too short, this should not happen: ['window<bin_0><bin_5><bin_123><bin_137>']
Triplet too long, this should not happen: ['plate<bin_16><bin_277><bin_995><bin_996>', 'on', 'plate<bin_16><bin_277><bin_991><bin_994>', 'on']
Triplet too short, this should not happen: ['tree<bin_0><bin_701><bin_999><bin_997>']
Triplet too short, this should not happen: ['window<bin_298><bin_429><bin_454><bin_533>']
Box too short, this should not happen: bus<bin_56><bin_31><bin_991> A
Box too short, this should not happen: man<bin_704><bin_322> emptied<bin_996>
Box too short, this should not happen: man<bin_704><bin_322> A<bin_486>
Triplet too long, this should not happen: ['man<bin_704><bin_322><bin_936><bin_488>', 'wearing', 'shirt<bin_702><bin_322><bin_991><bin_486>', 'wearing']
Box too short, this should not happen: man<bin_0><bin_0><bin_468>udo
Triplet too short, this should not happen: ['surfboard<bin_63><bin_183><bin_632><bin_696>']
Triplet too short, this should not happen: ['surfboard<bin_63><bin_185><bin_630><bin_696>']
Triplet too short, this should not happen: ['face<bin_191><bin_175><bin_173><bin_254>']
Box too short, this should not happen: window<bin_632><bin_117> alleg<bin_191>
Box too short, this should not happen: window<bin_632><bin_117> supervised<bin_185>
Triplet too short, this should not happen: ['tree<bin_0><bin_260><bin_57><bin_501>']
Triplet too short, this should not happen: ['tree<bin_0><bin_260><bin_55><bin_501>']
Box too short, this should not happen: man<bin_0><bin_0> blue<bin_999>
Box too short, this should not happen: man<bin_653><bin_459>ochemical<bin_996>
Triplet too short, this should not happen: ['man<bin_643><bin_459><bin_997><bin_996>']
Box too short, this should not happen: window<bin_0><bin_0>fox<bin_329>
label not found window wall on
Triplet too long, this should not happen: ['book<bin_141><bin_516><bin_995><bin_996>', 'on', 'table<bin_0><bin_270><bin_997><bin_996>', 'on']
Triplet too short, this should not happen: ['woman<bin_281><bin_316><bin_455><bin_666>']
Triplet too long, this should not happen: ['wheel<bin_50><bin_680><bin_269><bin_996>', 'on', 'motorcycle<bin_20><bin_29><bin_991><bin_996>', 'on']
Box too short, this should not happen: chair<bin_62><bin_349> D<bin_997>
Box too short, this should not happen: chair<bin_60><bin_349> D<bin_997>
Box too short, this should not happen: chair<bin_62><bin_349> D<bin_999>
Box too short, this should not happen: pole<bin_100><bin_159> A<bin_997>
Box too short, this should not happen: pole<bin_98><bin_159> A<bin_997>
Triplet too short, this should not happen: ['window<bin_613><bin_135><bin_991><bin_240>']
Box too short, this should not happen: pole<bin_101><bin_159>icip<bin_997>
Triplet too short, this should not happen: ['window<bin_613><bin_137><bin_765><bin_240>']
Box too short, this should not happen: pole<bin_100><bin_159>icip<bin_997>
Triplet too short, this should not happen: ['eye<bin_687><bin_321><bin_706><bin_371>']
Box too short, this should not happen: man<bin_505><bin_59>sect<bin_701>
Triplet too short, this should not happen: ['skateboard<bin_468><bin_713><bin_718><bin_718>']
Box too short, this should not happen: man<bin_510><bin_59>sect<bin_703>
Triplet too short, this should not happen: ['giraffe<bin_73><bin_16><bin_641><bin_996>']
Triplet too short, this should not happen: ['giraffe<bin_73><bin_14><bin_641><bin_996>']
Triplet too short, this should not happen: ['giraffe<bin_75><bin_14><bin_641><bin_996>']
Triplet too short, this should not happen: ['giraffe<bin_77><bin_16><bin_641><bin_996>']
No box, this should not happen: gir
label not found giraffee tail has
Box too short, this should not happen: man<bin_0><bin_0> A<bin_997>
Box too short, this should not happen: man<bin_0><bin_0> brazen<bin_997>
Triplet too short, this should not happen: ['zebra<bin_33><bin_593><bin_166><bin_996>']
Triplet too short, this should not happen: ['woman<bin_471><bin_45><bin_995><bin_996>']
Box too short, this should not happen: paper<bin_0><bin_720><bin_995>oka
Triplet too short, this should not happen: ['snow<bin_0><bin_206><bin_997><bin_996>']
Triplet too long, this should not happen: ['chair<bin_669><bin_497><bin_995><bin_996>', 'near', 'bed<bin_664><bin_497><bin_995><bin_996>', 'near']
Box too short, this should not happen: bird<bin_170><bin_122> D<bin_741>
Box too short, this should not happen: bench<bin_167><bin_122> D<bin_741>
Triplet too short, this should not happen: ['tree<bin_537><bin_474><bin_691><bin_691>']
Triplet too short, this should not happen: ['glass<bin_527><bin_732><bin_687><bin_996>']
Triplet too short, this should not happen: ['glass<bin_527><bin_730><bin_687><bin_996>']
Box too short, this should not happen: window<bin_687><bin_673> T<bin_741>
Box too short, this should not happen: window<bin_687><bin_673> A<bin_741>
Triplet too short, this should not happen: ['bag<bin_743><bin_649><bin_993><bin_730>']
Triplet too short, this should not happen: ['man<bin_695><bin_412><bin_702><bin_996>']
Box too short, this should not happen: tree<bin_0><bin_0> nesting<bin_999>
Triplet too short, this should not happen: ['fence<bin_0><bin_997><bin_995><bin_994>']
Triplet too short, this should not happen: ['man<bin_315><bin_124><bin_614><bin_997>']
Box too short, this should not happen: helmet<bin_568><bin_103> vacancies<bin_224>
Box too short, this should not happen: jacket<bin_568><bin_103> vacancies<bin_224>
no prediction
Triplet too short, this should not happen: ['cat<bin_0><bin_176><bin_524><bin_738>']
Triplet too short, this should not happen: ['cat<bin_0><bin_180><bin_524><bin_738>']
Triplet too short, this should not happen: ['zebra<bin_43><bin_5><bin_995><bin_999>']
100 50
100 50
SGG eval:     R @ 20: 0.0138;     R @ 50: 0.0138;     R @ 100: 0.0138;  for mode=sgcls, type=Recall(Main).
SGG eval:    mR @ 20: 0.0046;    mR @ 50: 0.0046;    mR @ 100: 0.0046;  for mode=sgcls, type=Mean Recall.

SGG eval:     R @ 20: 0.0314;     R @ 50: 0.0314;     R @ 100: 0.0314;  for mode=sgcls, type=Recall(Main).
SGG eval:    mR @ 20: 0.0027;    mR @ 50: 0.0027;    mR @ 100: 0.0027;  for mode=sgcls, type=Mean Recall.

2023-09-20 13:41:29 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 4.343 | loss_v1 0 | loss_v2 0 | nll_loss 3.094 | ntokens 1166.43 | nsentences 14.286 | sample_size 1166.43 | sample_size_v1 0 | sample_size_v2 0 | ppl 8.54 | wps 80.5 | wpb 1166.4 | bsz 14.3 | num_updates 1956
slice_id 1 seek offset 50
2023-09-20 13:41:30 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0slice_id 1 seek offset 50

['<sub> train<bin_129><bin_75><bin_162><bin_701><pred> has<obj> windshield<bin_482><bin_213><bin_545><bin_415><sub> windshield<bin_482><bin_213><bin_545><bin_414><pred> on<obj> train<bin_129><bin_75><bin_162><bin_696><sub> windshield<bin_482><bin_211><bin_545><bin_415><pred> on<obj> train<bin_131><bin_75><bin_162><bin_696><sub> window<bin_482><bin_213><bin_545><bin_415><pred> of<obj> train<bin_129><bin_75><bin_164><bin_696><sub> window<bin_480><bin_213><bin_545><bin_415><pred> on davidjl train<bin_129><bin_75><bin_162><bin_698><sub> window<bin_482><bin_211><bin_545><bin_416><pred> on<obj> train<bin_130><bin_75><bin_162><bin_696><sub> train<bin_129><bin_75><bin_164><bin_698><pred> has<obj> windshield<bin_480><bin_213><bin_545><bin_415><sub> window<bin_482><bin_213><bin_543><bin_415><pred> on<obj> car<bin_224><bin_999><bin_995><bin_996><sub> windshield<bin_482><bin_213><bin_543><bin_414><pred> on<obj> car<bin_226><bin_999><bin_995><bin_996>', '<sub> train<bin_129><bin_75><bin_162><bin_701><pred> has<obj> windshield<bin_482><bin_213><bin_545><bin_415><sub> windshield<bin_482><bin_213><bin_545><bin_414><pred> on<obj> train<bin_129><bin_75><bin_162><bin_696><sub> windshield<bin_482><bin_211><bin_545><bin_415><pred> on<obj> train<bin_131><bin_75><bin_162><bin_696><sub> window<bin_482><bin_213><bin_545><bin_415><pred> of<obj> train<bin_129><bin_75><bin_164><bin_696><sub> window<bin_480><bin_213><bin_545><bin_415><pred> on davidjl train<bin_129><bin_75><bin_162><bin_698><sub> window<bin_482><bin_211><bin_545><bin_416><pred> on<obj> train<bin_130><bin_75><bin_162><bin_696><sub> train<bin_129><bin_75><bin_164><bin_698><pred> has<obj> windshield<bin_480><bin_213><bin_545><bin_415><sub> window<bin_482><bin_213><bin_543><bin_415><pred> on<obj> car<bin_224><bin_999><bin_995><bin_996><sub> windshield<bin_482><bin_213><bin_543><bin_414><pred> on<obj> car<bin_227><bin_999><bin_995><bin_996>', '<sub> train<bin_129><bin_75><bin_162><bin_701><pred> has<obj> windshield<bin_482><bin_213><bin_545><bin_415><sub> windshield<bin_482><bin_213><bin_545><bin_414><pred> on<obj> train<bin_129><bin_75><bin_162><bin_696><sub> windshield<bin_482><bin_211><bin_545><bin_415><pred> on<obj> train<bin_131><bin_75><bin_162><bin_696><sub> window<bin_482><bin_213><bin_545><bin_415><pred> of<obj> train<bin_129><bin_75><bin_164><bin_696><sub> window<bin_480><bin_213><bin_545><bin_415><pred> on davidjl train<bin_129><bin_75><bin_162><bin_698><sub> window<bin_482><bin_211><bin_545><bin_416><pred> on<obj> train<bin_127><bin_75><bin_162><bin_696><sub> train<bin_129><bin_75><bin_164><bin_698><pred> has<obj> windshield<bin_480><bin_213><bin_545><bin_415><sub> window<bin_482><bin_213><bin_543><bin_415><pred> on<obj> car<bin_224><bin_999>ibliography', '<sub> train<bin_129><bin_75><bin_162><bin_701><pred> has<obj> windshield<bin_482><bin_213><bin_545><bin_415><sub> windshield<bin_482><bin_213><bin_545><bin_414><pred> on<obj> train<bin_129><bin_75><bin_162><bin_696><sub> windshield<bin_482><bin_211><bin_545><bin_415><pred> on<obj> train<bin_131><bin_75><bin_162><bin_696><sub> window<bin_482><bin_213><bin_545><bin_415><pred> of<obj> train<bin_129><bin_75><bin_164><bin_696><sub> window<bin_480><bin_213><bin_545><bin_415><pred> on davidjl train<bin_129><bin_75><bin_162><bin_698><sub> window<bin_482><bin_211><bin_545><bin_416><pred> on<obj> train<bin_130><bin_75><bin_162><bin_696><sub> train<bin_129><bin_75><bin_164><bin_698><pred> has<obj> windshield<bin_480><bin_213><bin_545><bin_415><sub> window<bin_482><bin_213><bin_543><bin_415><pred> on<obj> car<bin_224><bin_999>ibliography', '<sub> train<bin_129><bin_75><bin_162><bin_701><pred> has<obj> windshield<bin_482><bin_213><bin_545><bin_415><sub> windshield<bin_482><bin_213><bin_545><bin_414><pred> on<obj> train<bin_129><bin_75><bin_162><bin_696><sub> windshield<bin_482><bin_211><bin_545><bin_415><pred> on<obj> train<bin_131><bin_75><bin_162><bin_696><sub> window<bin_482><bin_213><bin_545><bin_415><pred> of<obj> train<bin_129><bin_75><bin_164><bin_696><sub> window<bin_480><bin_213><bin_545><bin_415><pred> on davidjl train<bin_129><bin_75><bin_162><bin_698><sub> window<bin_482><bin_211><bin_545><bin_416><pred> on<obj> train<bin_130><bin_75><bin_162><bin_696><sub> train<bin_129><bin_75><bin_164><bin_698><pred> has<obj> windshield<bin_480><bin_213><bin_545><bin_415><sub> window<bin_482><bin_213><bin_543><bin_415><pred> on<obj> car<bin_224><bin_999><bin_995><bin_996>']
<sub> 4512 <bin_129> <bin_75> <bin_162> <bin_701> <pred> 468 <obj> 38866 <bin_482> <bin_213> <bin_545> <bin_415> <sub> 38866 <bin_482> <bin_213> <bin_545> <bin_414> <pred> 319 <obj> 4512 <bin_129> <bin_75> <bin_162> <bin_696> <sub> 38866 <bin_482> <bin_211> <bin_545> <bin_415> <pred> 319 <obj> 4512 <bin_131> <bin_75> <bin_162> <bin_696> <sub> 4324 <bin_482> <bin_213> <bin_545> <bin_415> <pred> 286 <obj> 4512 <bin_129> <bin_75> <bin_164> <bin_696> <sub> 4324 <bin_480> <bin_213> <bin_545> <bin_415> <pred> 319 23282 4512 <bin_129> <bin_75> <bin_162> <bin_698> <sub> 4324 <bin_482> <bin_211> <bin_545> <bin_416> <pred> 319 <obj> 4512 <bin_130> <bin_75> <bin_162> <bin_696> <sub> 4512 <bin_129> <bin_75> <bin_164> <bin_698> <pred> 468 <obj> 38866 <bin_480> <bin_213> <bin_545> <bin_415> <sub> 4324 <bin_482> <bin_213> <bin_543> <bin_415> <pred> 319 <obj> 1097 <bin_224> <bin_999> <bin_995> <bin_996> <sub> 38866 <bin_482> <bin_213> <bin_543> <bin_414> <pred> 319 <obj> 1097 <bin_226> <bin_999> <bin_995> <bin_996>
Triplet too short, this should not happen: ['window<bin_480><bin_213><bin_545><bin_415>']
label not found cow tent in
Triplet too short, this should not happen: ['window<bin_185><bin_258><bin_636><bin_622>']
Box too short, this should not happen: car<bin_16><bin_86><bin_991>ao
['<sub> building<bin_0><bin_180><bin_995><bin_996><pred> has<obj> clock<bin_191><bin_35> S<bin_695><sub> clock<bin_191><bin_35> S<bin_697><pred> has<obj> hand<bin_460><bin_298><bin_622><bin_380><sub> clock<bin_191><bin_35> seeded<bin_695><pred> has<obj> hand<bin_458><bin_298><bin_622><bin_380><sub> hand<bin_460><bin_298><bin_622><bin_381><pred> on<obj> clock<bin_191><bin_35> seeded<bin_697><sub> clock<bin_189><bin_35> seeded<bin_697><pred> on<obj> building<bin_0><bin_182><bin_995><bin_996><sub> hand<bin_460><bin_298><bin_624><bin_380><pred> on<obj> clock<bin_189><bin_35> seeded<bin_695><sub> clock<bin_191><bin_37> seeded<bin_695><pred> on<obj> tower<bin_0><bin_180><bin_995><bin_996><sub> hand<bin_458><bin_298><bin_622><bin_379><pred> on<obj> clock<bin_193><bin_35> seeded<bin_697><sub> hand<bin_460><bin_298><bin_617><bin_380><pred> on<obj> building<bin_5><bin_180><bin_995><bin_996><sub> clock<bin_191><bin_35> broadcast<bin_695><pred> on<obj> building<bin_2><bin_180><bin_995><bin_996><sub> building<bin_3><bin_180><bin_995><bin_996><pred> near<obj> clock<bin_189><bin_35> broadcast<bin_695>', '<sub> building<bin_0><bin_180><bin_995><bin_996><pred> has<obj> clock<bin_191><bin_35> S<bin_695><sub> clock<bin_191><bin_35> S<bin_697><pred> has<obj> hand<bin_460><bin_298><bin_622><bin_380><sub> clock<bin_191><bin_35> seeded<bin_695><pred> has<obj> hand<bin_458><bin_298><bin_622><bin_380><sub> hand<bin_460><bin_298><bin_622><bin_381><pred> on<obj> clock<bin_191><bin_35> seeded<bin_697><sub> clock<bin_189><bin_35> seeded<bin_697><pred> on<obj> building<bin_0><bin_182><bin_995><bin_996><sub> hand<bin_460><bin_298><bin_624><bin_380><pred> on<obj> clock<bin_189><bin_35> seeded<bin_695><sub> clock<bin_191><bin_37> seeded<bin_695><pred> on<obj> tower<bin_0><bin_180><bin_995><bin_996><sub> hand<bin_458><bin_298><bin_622><bin_379><pred> on<obj> clock<bin_193><bin_35> seeded<bin_697><sub> hand<bin_460><bin_298><bin_617><bin_380><pred> on<obj> building<bin_2><bin_180><bin_995><bin_996>', '<sub> building<bin_0><bin_180><bin_995><bin_996><pred> has<obj> clock<bin_191><bin_35> S<bin_695><sub> clock<bin_191><bin_35> S<bin_697><pred> has<obj> hand<bin_460><bin_298><bin_622><bin_380><sub> clock<bin_191><bin_35> seeded<bin_695><pred> has<obj> hand<bin_458><bin_298><bin_622><bin_380><sub> hand<bin_460><bin_298><bin_622><bin_381><pred> on<obj> clock<bin_191><bin_35> seeded<bin_697><sub> clock<bin_189><bin_35> seeded<bin_697><pred> on<obj> building<bin_0><bin_182><bin_995><bin_996><sub> hand<bin_460><bin_298><bin_624><bin_380><pred> on<obj> clock<bin_189><bin_35> seeded<bin_695><sub> clock<bin_191><bin_37> seeded<bin_695><pred> on<obj> tower<bin_0><bin_180><bin_995><bin_996>', '<sub> building<bin_0><bin_180><bin_995><bin_996><pred> has<obj> clock<bin_191><bin_35> S<bin_695><sub> clock<bin_191><bin_35> S<bin_697><pred> has<obj> hand<bin_460><bin_298><bin_622><bin_380><sub> clock<bin_191><bin_35> seeded<bin_695><pred> has<obj> hand<bin_458><bin_298><bin_622><bin_380><sub> hand<bin_460><bin_298><bin_622><bin_381><pred> on<obj> clock<bin_191><bin_35> seeded<bin_697><sub> clock<bin_189><bin_35> seeded<bin_697><pred> on<obj> building<bin_0><bin_182><bin_995><bin_996><sub> hand<bin_460><bin_298><bin_624><bin_380><pred> on<obj> clock<bin_189><bin_35> seeded<bin_695><sub> clock<bin_191><bin_37> seeded<bin_695><pred> on<obj> tower<bin_0><bin_182><bin_995><bin_996>', '<sub> building<bin_0><bin_180><bin_995><bin_996><pred> has<obj> clock<bin_191><bin_35> S<bin_695><sub> clock<bin_191><bin_35> S<bin_697><pred> has<obj> hand<bin_460><bin_298><bin_622><bin_380><sub> clock<bin_191><bin_35> seeded<bin_695><pred> has<obj> hand<bin_458><bin_298><bin_622><bin_380><sub> hand<bin_460><bin_298><bin_622><bin_381><pred> on<obj> clock<bin_191><bin_35> seeded<bin_697><sub> clock<bin_189><bin_35> seeded<bin_697><pred> on<obj> building<bin_0><bin_182><bin_995><bin_996>']
<sub> 2615 <bin_0> <bin_180> <bin_995> <bin_996> <pred> 468 <obj> 8801 <bin_191> <bin_35> 311 <bin_695> <sub> 8801 <bin_191> <bin_35> 311 <bin_697> <pred> 468 <obj> 1021 <bin_460> <bin_298> <bin_622> <bin_380> <sub> 8801 <bin_191> <bin_35> 48453 <bin_695> <pred> 468 <obj> 1021 <bin_458> <bin_298> <bin_622> <bin_380> <sub> 1021 <bin_460> <bin_298> <bin_622> <bin_381> <pred> 319 <obj> 8801 <bin_191> <bin_35> 48453 <bin_697> <sub> 8801 <bin_189> <bin_35> 48453 <bin_697> <pred> 319 <obj> 2615 <bin_0> <bin_182> <bin_995> <bin_996> <sub> 1021 <bin_460> <bin_298> <bin_624> <bin_380> <pred> 319 <obj> 8801 <bin_189> <bin_35> 48453 <bin_695> <sub> 8801 <bin_191> <bin_37> 48453 <bin_695> <pred> 319 <obj> 10580 <bin_0> <bin_180> <bin_995> <bin_996> <sub> 1021 <bin_458> <bin_298> <bin_622> <bin_379> <pred> 319 <obj> 8801 <bin_193> <bin_35> 48453 <bin_697> <sub> 1021 <bin_460> <bin_298> <bin_617> <bin_380> <pred> 319 <obj> 2615 <bin_5> <bin_180> <bin_995> <bin_996> <sub> 8801 <bin_191> <bin_35> 7025 <bin_695> <pred> 319 <obj> 2615 <bin_2> <bin_180> <bin_995> <bin_996> <sub> 2615 <bin_3> <bin_180> <bin_995> <bin_996> <pred> 1474 <obj> 8801 <bin_189> <bin_35> 7025 <bin_695>
Box too short, this should not happen: clock<bin_191><bin_35> S<bin_695>
Box too short, this should not happen: clock<bin_191><bin_35> S<bin_697>
Box too short, this should not happen: clock<bin_191><bin_35> seeded<bin_695>
Box too short, this should not happen: clock<bin_191><bin_35> seeded<bin_697>
Box too short, this should not happen: clock<bin_189><bin_35> seeded<bin_697>
Box too short, this should not happen: clock<bin_189><bin_35> seeded<bin_695>
Box too short, this should not happen: clock<bin_191><bin_37> seeded<bin_695>
Box too short, this should not happen: clock<bin_193><bin_35> seeded<bin_697>
Box too short, this should not happen: clock<bin_191><bin_35> broadcast<bin_695>
Box too short, this should not happen: clock<bin_189><bin_35> broadcast<bin_695>
Triplet too short, this should not happen: ['woman<bin_392><bin_145><bin_597><bin_997>']
Box too short, this should not happen: glass<bin_513><bin_478><code_2367><bin_544>
Triplet too short, this should not happen: ['man<bin_399><bin_147><bin_597><bin_997>']
Box too short, this should not happen: glass<bin_513><bin_478><code_2131><bin_544>
Triplet too short, this should not happen: ['man<bin_399><bin_148><bin_597><bin_997>']
Triplet too short, this should not happen: ['man<bin_399><bin_148><bin_602><bin_997>']
Triplet too short, this should not happen: ['woman<bin_399><bin_146><bin_597><bin_997>']
Box too short, this should not happen: tie<bin_493><bin_459>ports<bin_701>
Box too short, this should not happen: man<bin_0><bin_45>atell<bin_996>
Box too short, this should not happen: shoe<bin_0> T<bin_150><bin_996>
Triplet too short, this should not happen: ['man<bin_0><bin_47><bin_991><bin_996>']
Triplet too short, this should not happen: ['man<bin_0><bin_43><bin_991><bin_996>']
Box too short, this should not happen: man<bin_0><bin_45><bin_991>r
Triplet too short, this should not happen: ['window<bin_79><bin_599><bin_153><bin_679>']
Triplet too short, this should not happen: ['building<bin_8><bin_394><bin_995><bin_996>']
Traceback (most recent call last):
  File "../../train.py", line 537, in <module>
    cli_main()
  File "../../train.py", line 530, in cli_main
    distributed_utils.call_main(cfg, main)WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers

  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 348, in distributed_main
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1539341 closing signal SIGINT
Error in sys.excepthook:
    WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1539342 closing signal SIGINT
main(cfg, **kwargs)
  File "../../train.py", line 199, in main
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "../../train.py", line 324, in train
    valid_losses, should_stop = validate_and_save(
  File "../../train.py", line 411, in validate_and_save
Traceback (most recent call last):
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 481, in validate
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/linecache.py", line 47, in getlines
    trainer.valid_step(sample)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
        return func(*args, **kwds)
  File "/home/zcai75/Github/OFA_forked/trainer.py", line 1058, in valid_step
return updatecache(filename, module_globals)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/linecache.py", line 137, in updatecache
    _loss, sample_size, logging_output = self.task.valid_step(
  File "/home/zcai75/Github/OFA_forked/tasks/mm_tasks/scene_graph.py", line 160, in valid_step
        out = self.inference_step(self.sequence_generator, [model], sample)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/tasks/fairseq_task.py", line 517, in inference_step
lines = fp.readlines()
    return generator.generate(
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/codecs.py", line 319, in decode
    return func(*args, **kwargs)
  File "/home/zcai75/Github/OFA_forked/models/sequence_generator.py", line 207, in generate
    return self._generate(models, sample, **kwargs)
  File "/home/zcai75/Github/OFA_forked/models/sequence_generator.py", line 436, in _generate
        lprobs = self.repeat_ngram_blocker(tokens, lprobs, bsz, beam_size, step)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
def decode(self, input, final=False):
KeyboardInterrupt    
return forward_call(*input, **kwargs)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/ngram_repeat_block.py", line 88, in forward

Original exception was:
    return self._no_repeat_ngram(
  File "/home/zcai75/Github/OFA/fairseq/fairseq/ngram_repeat_block.py", line 109, in _no_repeat_ngram
Traceback (most recent call last):
    gen_ngrams[bbsz_idx][key] = gen_ngrams[bbsz_idx].get(
KeyboardInterrupt
  File "../../train.py", line 537, in <module>
    cli_main()
  File "../../train.py", line 530, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 199, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "../../train.py", line 324, in train
    valid_losses, should_stop = validate_and_save(
  File "../../train.py", line 411, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 481, in validate
    trainer.valid_step(sample)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/home/zcai75/Github/OFA_forked/trainer.py", line 1058, in valid_step
    _loss, sample_size, logging_output = self.task.valid_step(
  File "/home/zcai75/Github/OFA_forked/tasks/mm_tasks/scene_graph.py", line 160, in valid_step
    out = self.inference_step(self.sequence_generator, [model], sample)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/tasks/fairseq_task.py", line 517, in inference_step
    return generator.generate(
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/zcai75/Github/OFA_forked/models/sequence_generator.py", line 207, in generate
    return self._generate(models, sample, **kwargs)
  File "/home/zcai75/Github/OFA_forked/models/sequence_generator.py", line 436, in _generate
    lprobs = self.repeat_ngram_blocker(tokens, lprobs, bsz, beam_size, step)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/ngram_repeat_block.py", line 88, in forward
    return self._no_repeat_ngram(
  File "/home/zcai75/Github/OFA/fairseq/fairseq/ngram_repeat_block.py", line 109, in _no_repeat_ngram
    gen_ngrams[bbsz_idx][key] = gen_ngrams[bbsz_idx].get(
KeyboardInterrupt
wandb: Waiting for W&B process to finish... (failed 255). Press Control-C to abort syncing.
wandb: - 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: \ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: | 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: / 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:            valid/bsz 
wandb:           valid/loss 
wandb:        valid/loss_v1 
wandb:        valid/loss_v2 
wandb:       valid/nll_loss 
wandb:     valid/nsentences 
wandb:        valid/ntokens 
wandb:            valid/ppl 
wandb:    valid/sample_size 
wandb: valid/sample_size_v1 
wandb: valid/sample_size_v2 
wandb:            valid/wpb 
wandb:            valid/wps 
wandb: 
wandb: Run summary:
wandb:            valid/bsz 14.3
wandb:           valid/loss 4.343
wandb:        valid/loss_v1 0.0
wandb:        valid/loss_v2 0.0
wandb:       valid/nll_loss 3.094
wandb:     valid/nsentences 14.286
wandb:        valid/ntokens 1166.429
wandb:            valid/ppl 8.54
wandb:    valid/sample_size 1166.429
wandb: valid/sample_size_v1 0.0
wandb: valid/sample_size_v2 0.0
wandb:            valid/wpb 1166.4
wandb:            valid/wps 80.5
wandb: 
wandb:  View run adapter_all_cand_20_3e-5_512_sgcls at: https://wandb.ai/jackcai1206/OFA-VG/runs/7b8tcrv6
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230920_133945-7b8tcrv6/logs
Traceback (most recent call last):
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 236, in launch_agent
    result = agent.run()
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/elastic/metrics/api.py", line 125, in wrapper
    result = f(*args, **kwargs)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 850, in _invoke_run
    time.sleep(monitor_interval)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 60, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 1539306 got signal: 2
